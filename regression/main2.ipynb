{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61504a36e2851576",
   "metadata": {},
   "source": [
    "### **1) REQUIREMENTS SETUP**### **1) REQUIREMENTS SETUP**# **Regression data preparation and modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44496c0061df41f5",
   "metadata": {},
   "source": [
    "### **1) REQUIREMENTS SETUP**"
   ]
  },
  {
   "cell_type": "code",
   "id": "43fef67b9d502783",
   "metadata": {},
   "source": [
    "# !pip install -r requirements.txt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9cf220addcc024f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:18:40.968665Z",
     "start_time": "2025-11-08T12:18:38.924258Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from linearmodels.panel import PanelOLS\n",
    "from scipy.optimize import minimize"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "339d8fa8bee2b4f7",
   "metadata": {},
   "source": [
    "### **2) MODULES IMPORT**"
   ]
  },
  {
   "cell_type": "code",
   "id": "ebc963da9885ca8",
   "metadata": {},
   "source": [
    "# None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "469c6becfd846866",
   "metadata": {},
   "source": [
    "### **3) DATA Prep**"
   ]
  },
  {
   "cell_type": "code",
   "id": "3fee59366384e1e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:18:42.852243Z",
     "start_time": "2025-11-08T12:18:42.658258Z"
    }
   },
   "source": [
    "# Normalization of all the data used in the regression over comparable timeframe / format\n",
    "data_fetcher_path = Path.cwd().parent / \"data_fetcher\"\n",
    "dep_IPI = pd.read_csv(data_fetcher_path/\"aggregate_df/EURO_indprod_dependent_df.csv\")\n",
    "dep_Stocks = pd.read_csv(data_fetcher_path/\"aggregate_df/EURO_stock_dependent_df.csv\")\n",
    "\n",
    "#Other (!!! I change the path to trade openness 1 from EURO_trade... to trade_openness_ ...)\n",
    "exposure_df = pd.read_csv(data_fetcher_path / \"country_tariff_exposure.csv\")\n",
    "openness_df = pd.read_csv(data_fetcher_path/\"aggregate_df/trade_openness_annual_regime_df.csv\")\n",
    "controls_df = pd.read_csv(data_fetcher_path/\"aggregate_df/country_specific_test_df.csv\")\n",
    "wb_openness_df = pd.read_csv(data_fetcher_path/\"aggregate_df/wb_trade_openness_annual_regime_df.csv\")\n",
    "transition_df = pd.read_csv(data_fetcher_path/\"aggregate_df/Export_Intra_EU.csv\")\n",
    "\n",
    "\n",
    "# === OFFICIAL EU COUNTRIES ONLY ===\n",
    "eu_country_map = {\n",
    "    \"Austria\": \"AT\", \"Belgium\": \"BE\", \"Bulgaria\": \"BG\", \"Croatia\": \"HR\",\n",
    "    \"Cyprus\": \"CY\", \"Czechia (Czech Republic)\": \"CZ\", \"Czechia\": \"CZ\",\n",
    "    \"Denmark\": \"DK\", \"Estonia\": \"EE\", \"Finland\": \"FI\", \"France\": \"FR\",\n",
    "    \"Germany\": \"DE\", \"Greece\": \"GR\", \"Hungary\": \"HU\", \"Ireland\": \"IE\",\n",
    "    \"Italy\": \"IT\", \"Latvia\": \"LV\", \"Lithuania\": \"LT\", \"Luxembourg\": \"LU\",\n",
    "    \"Malta\": \"MT\", \"Netherlands\": \"NL\", \"Poland\": \"PL\", \"Portugal\": \"PT\",\n",
    "    \"Romania\": \"RO\", \"Slovakia\": \"SK\", \"Slovenia\": \"SI\", \"Spain\": \"ES\",\n",
    "    \"Sweden\": \"SE\"\n",
    "}\n",
    "EU_ISO_CODES = set(eu_country_map.values())\n",
    "\n",
    "def keep_only_eu(df, country_col='Country'):\n",
    "    if country_col not in df.columns:\n",
    "        return df\n",
    "    before = len(df)\n",
    "    df = df[df[country_col].isin(EU_ISO_CODES)].copy()\n",
    "    after = len(df)\n",
    "    dropped = before - after\n",
    "    if dropped:\n",
    "        print(f\"Dropped {dropped:,} non-EU rows → {after:,} EU rows kept\")\n",
    "    return df\n",
    "\n",
    "# APPLY: Keep only EU countries\n",
    "dep_IPI = keep_only_eu(dep_IPI)\n",
    "dep_Stocks = keep_only_eu(dep_Stocks)\n",
    "exposure_df = keep_only_eu(exposure_df)\n",
    "openness_df = keep_only_eu(openness_df)\n",
    "controls_df = keep_only_eu(controls_df)\n",
    "transition_df = keep_only_eu(transition_df)\n",
    "wb_openness_df = keep_only_eu(wb_openness_df)\n",
    "\n",
    "\n",
    "print(f\"\\nKept only 27 EU countries: {sorted(EU_ISO_CODES)}\\n\")\n",
    "\n",
    "\n",
    "start_date = '2024-11'\n",
    "end_date = '2025-08'\n",
    "\n",
    "# ================================\n",
    "# IPI: Full Lagged First Difference (MAXIMUM COVERAGE)\n",
    "# ================================\n",
    "\n",
    "# 1. Start with FULL data (no date filter yet)\n",
    "cols = ['Country', 'Level 1 Index', 'Time', 'Indprod Index Value (I21)']\n",
    "dep_IPI_full = dep_IPI[cols].copy()\n",
    "\n",
    "# 2. Ensure numeric\n",
    "dep_IPI_full['Indprod Index Value (I21)'] = pd.to_numeric(\n",
    "    dep_IPI_full['Indprod Index Value (I21)'], errors='coerce'\n",
    ")\n",
    "\n",
    "# 3. Collapse B/C → \"B+C\", drop D\n",
    "dep_IPI_full['Level 1 Index'] = (\n",
    "    dep_IPI_full['Level 1 Index']\n",
    "    .astype(str).str.strip()\n",
    "    .replace({'B': 'B+C', 'C': 'B+C', 'D': np.nan})\n",
    ")\n",
    "dep_IPI_full = dep_IPI_full.dropna(subset=['Level 1 Index'])\n",
    "\n",
    "# 4. Aggregate (sum) over Country, Time, Level 1 Index\n",
    "dep_IPI_agg = (\n",
    "    dep_IPI_full\n",
    "    .groupby(['Country', 'Time', 'Level 1 Index'], as_index=False)\n",
    "    ['Indprod Index Value (I21)']\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# 5. Convert Time to Period and sort\n",
    "dep_IPI_agg['Time_period'] = pd.to_datetime(dep_IPI_agg['Time']).dt.to_period('M')\n",
    "dep_IPI_agg = dep_IPI_agg.sort_values(['Country', 'Level 1 Index', 'Time_period'])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. COMPUTE DIFF + LAG ON FULL DATA (KEY STEP!)\n",
    "# ------------------------------------------------------------------\n",
    "dep_IPI_agg['diff_IPI'] = (\n",
    "    dep_IPI_agg\n",
    "    .groupby(['Country', 'Level 1 Index'])['Indprod Index Value (I21)']\n",
    "    .diff()\n",
    ")\n",
    "\n",
    "dep_IPI_agg['lagged_diff_IPI'] = (\n",
    "    dep_IPI_agg\n",
    "    .groupby(['Country', 'Level 1 Index'])['diff_IPI']\n",
    "    .shift(1)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7. NOW FILTER TO YOUR ANALYSIS WINDOW\n",
    "# ------------------------------------------------------------------\n",
    "mask = (\n",
    "    (dep_IPI_agg['Time_period'] >= pd.Period(start_date, 'M')) &\n",
    "    (dep_IPI_agg['Time_period'] <= pd.Period(end_date, 'M'))\n",
    ")\n",
    "dep_IPI_final = dep_IPI_agg.loc[mask].copy()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 8. Final cleanup & save\n",
    "# ------------------------------------------------------------------\n",
    "final_cols = [\n",
    "    'Country', 'Level 1 Index', 'Time',\n",
    "    'Indprod Index Value (I21)',  # current level\n",
    "    'diff_IPI',                   # ΔIPI_t\n",
    "    'lagged_diff_IPI'             # ΔIPI_{t-1} ← FULLY POPULATED\n",
    "]\n",
    "dep_IPI_final = dep_IPI_final[final_cols]\n",
    "\n",
    "Path('data/dependent_variable').mkdir(parents=True, exist_ok=True)\n",
    "dep_IPI_final.to_csv(\n",
    "    'data/dependent_variable/IndustrialProductionIndex_df.csv',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Saved: IndustrialProductionIndex_df.csv\")\n",
    "print(f\"  → Analysis window: {start_date} to {end_date}\")\n",
    "print(f\"  → Valid lagged differences: {dep_IPI_final['lagged_diff_IPI'].notna().sum():,}\")\n",
    "print(f\"  → First month in window has lag: {dep_IPI_final.iloc[0]['lagged_diff_IPI'] is not pd.NA}\")\n",
    "\n",
    "# Stocks Dependent\n",
    "stock_period = pd.to_datetime(dep_Stocks['Time'], errors='coerce').dt.to_period('M')\n",
    "stock_mask = (stock_period >= pd.Period(start_date, 'M')) & (stock_period <= pd.Period(end_date, 'M'))\n",
    "stock_cols = ['Country', 'Stock Index', 'Time', 'Log Monthly Return', 'Volume']\n",
    "dep_Stocks_filtered = dep_Stocks.loc[stock_mask, stock_cols].copy()\n",
    "dep_Stocks_filtered = dep_Stocks_filtered.sort_values(['Country', 'Stock Index', 'Time']).reset_index(drop=True)\n",
    "dep_Stocks_filtered.to_csv('data/dependent_variable/StockIndex_df.csv', index=False)\n",
    "\n",
    "# Tariff(i,t) Independent\n",
    "\n",
    "# 1. Round publication dates to month (same as before)\n",
    "dt = pd.to_datetime(exposure_df['Publication_Date'], errors='coerce')\n",
    "month_start = dt.dt.to_period('M').dt.start_time\n",
    "next_month_start = (dt.dt.to_period('M') + 1).dt.start_time\n",
    "delta_to_start = (dt - month_start).dt.days\n",
    "delta_to_next = (next_month_start - dt).dt.days\n",
    "rounded_month_start = pd.to_datetime(\n",
    "    np.where(delta_to_start <= delta_to_next, month_start, next_month_start)\n",
    ")\n",
    "\n",
    "exposure_out = exposure_df.copy()\n",
    "exposure_out['Time_dt'] = rounded_month_start\n",
    "exposure_out['Time'] = exposure_out['Time_dt'].dt.strftime('%Y-%m')\n",
    "exposure_out = exposure_out[['Country', 'Time', 'Exposure']].copy()\n",
    "\n",
    "# 2. Define full panel: all countries × all months (2024-10 to 2025-08)\n",
    "#     → 2024-10 needed for lag of 2024-11\n",
    "all_countries = sorted(exposure_out['Country'].unique())\n",
    "all_months = pd.date_range('2024-10', '2025-08', freq='MS').strftime('%Y-%m').tolist()\n",
    "\n",
    "full_index = pd.MultiIndex.from_product([all_countries, all_months], names=['Country', 'Time'])\n",
    "full_panel = pd.DataFrame(index=full_index).reset_index()\n",
    "\n",
    "# 3. Merge observed shocks, fill missing with 0\n",
    "exposure_full = full_panel.merge(exposure_out, on=['Country', 'Time'], how='left')\n",
    "exposure_full['Exposure'] = exposure_full['Exposure'].fillna(0)\n",
    "\n",
    "# 4. Sort and save\n",
    "exposure_full = exposure_full.sort_values(['Country', 'Time']).reset_index(drop=True)\n",
    "Path('data/independent_variable').mkdir(parents=True, exist_ok=True)\n",
    "exposure_full.to_csv('data/independent_variable/CountryTariffExposure_df.csv', index=False)\n",
    "\n",
    "# Openess(i,t) Independent\n",
    "time_raw = openness_df['Time'].astype(str).str.strip()\n",
    "year_num = pd.to_numeric(time_raw, errors='coerce')\n",
    "year_dt = pd.to_datetime(time_raw, errors='coerce').dt.year\n",
    "year = year_num.fillna(year_dt)\n",
    "mask = year.isin([2024, 2025])\n",
    "openness_out = openness_df.loc[mask].copy()\n",
    "openness_out['Time'] = year.loc[mask].astype('Int64').astype(str)\n",
    "openness_out = openness_out.sort_values(['Country', 'Time']).reset_index(drop=True)\n",
    "openness_out.to_csv('data/transition_variable/TradeOpennessAnnual_df.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# wb_openess(i,t)\n",
    "# Step 1: Clean and convert Time to numeric year\n",
    "wb_time_raw = wb_openness_df['Time'].astype(str).str.strip()\n",
    "wb_year_num = pd.to_numeric(wb_time_raw, errors='coerce')\n",
    "wb_year_dt = pd.to_datetime(wb_time_raw, errors='coerce').dt.year\n",
    "wb_year = wb_year_num.fillna(wb_year_dt)\n",
    "# Assign cleaned year back\n",
    "wb_openness_df['Time'] = wb_year\n",
    "# Step 2: Create 2025 entries with 0 openness for all countries\n",
    "countries = wb_openness_df['Country'].unique()\n",
    "year_2025_df = pd.DataFrame({\n",
    "    'Country': countries,\n",
    "    'Time': 2025,\n",
    "    'Global Trade Openness (%GDP)': 0,\n",
    "    'Global Trade Openness-Lag1': pd.NA  # Will be filled after lagging\n",
    "})\n",
    "# Append 2025 data\n",
    "wb_openness_extended = pd.concat([wb_openness_df, year_2025_df], ignore_index=True)\n",
    "# Step 3: Sort by Country and Time to prepare for lagging\n",
    "wb_openness_extended = wb_openness_extended.sort_values(['Country', 'Time']).reset_index(drop=True)\n",
    "# Step 4: Create lag (Global Trade Openness-Lag1) — shift within each country\n",
    "wb_openness_extended['Global Trade Openness-Lag1'] = (\n",
    "    wb_openness_extended.groupby('Country')['Global Trade Openness (%GDP)']\n",
    "    .shift(1)\n",
    ")\n",
    "# Step 5: Filter only 2023 and 2024\n",
    "wb_mask = wb_openness_extended['Time'].isin([2024, 2025])\n",
    "wb_openness_out = wb_openness_extended.loc[wb_mask].copy()\n",
    "# Step 6: Format Time as string (Int64 -> str)\n",
    "wb_openness_out['Time'] = wb_openness_out['Time'].astype('Int64').astype(str)\n",
    "# Step 7: Final sort and save\n",
    "wb_openness_out = wb_openness_out.sort_values(['Country', 'Time']).reset_index(drop=True)\n",
    "wb_openness_out.to_csv('data/transition_variable/WBTradeOpennessAnnual_df.csv', index=False)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Transition Variable + LAG (CORRECT & WORKING)\n",
    "# ================================\n",
    "cols = [\n",
    "    'STRUCTURE','STRUCTURE_ID','STRUCTURE_NAME','freq','Frequency',\n",
    "    'Country','REPORTER','partner','PARTNER','product','PRODUCT',\n",
    "    'flow','FLOW','indicators','INDICATORS','Time','TIME_PERIOD',\n",
    "    'OBS_VALUE','Observation Value'\n",
    "]\n",
    "\n",
    "df_full = transition_df[cols].copy()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Prepare time & numeric columns\n",
    "# ------------------------------------------------------------------\n",
    "df_full['Time_period'] = pd.to_datetime(\n",
    "    df_full['Time'], errors='coerce'\n",
    ").dt.to_period('M')\n",
    "\n",
    "df_full['OBS_VALUE'] = pd.to_numeric(df_full['OBS_VALUE'], errors='coerce')\n",
    "\n",
    "df_full = df_full.sort_values(['Country', 'Time_period']).reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. LAG (on original level)\n",
    "# ------------------------------------------------------------------\n",
    "df_full['OBS_VALUE_Lagged1'] = df_full.groupby('Country')['OBS_VALUE'].shift(1)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Filter by date window\n",
    "# ------------------------------------------------------------------\n",
    "mask = (\n",
    "    (df_full['Time_period'] >= pd.Period(start_date, 'M')) &\n",
    "    (df_full['Time_period'] <= pd.Period(end_date, 'M'))\n",
    ")\n",
    "transition_df_filtered = df_full.loc[mask].copy()\n",
    "transition_df_filtered = transition_df_filtered.drop(columns=['Time_period'])\n",
    "transition_df_filtered = transition_df_filtered.sort_values(['Country', 'Time']).reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. ---- BOTH CURRENT & LAGGED VALUES AS PROPORTIONS (FIXED) ----\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Step 1: Compute total export PER MONTH (one value per month)\n",
    "monthly_totals = transition_df_filtered.groupby('Time')['OBS_VALUE'].sum()\n",
    "\n",
    "# Step 2: Map current month total to each row\n",
    "transition_df_filtered['monthly_total_current'] = transition_df_filtered['Time'].map(monthly_totals)\n",
    "\n",
    "# Step 3: Create a shifted version of monthly totals (previous month total)\n",
    "monthly_totals_lagged = monthly_totals.shift(1)\n",
    "\n",
    "# Step 4: Map lagged month total to each row\n",
    "transition_df_filtered['monthly_total_lagged'] = transition_df_filtered['Time'].map(monthly_totals_lagged)\n",
    "\n",
    "# Step 5: Convert to proportions\n",
    "transition_df_filtered['OBS_VALUE'] = (\n",
    "    transition_df_filtered['OBS_VALUE'] / transition_df_filtered['monthly_total_current']\n",
    ")\n",
    "\n",
    "# Lagged proportion: lagged level / previous month's total\n",
    "transition_df_filtered['OBS_VALUE_Lagged1'] = (\n",
    "    transition_df_filtered['OBS_VALUE_Lagged1'] / transition_df_filtered['monthly_total_lagged']\n",
    ")\n",
    "\n",
    "# OPTIONAL: Clean up helper columns\n",
    "transition_df_filtered = transition_df_filtered.drop(columns=['monthly_total_current', 'monthly_total_lagged'])\n",
    "\n",
    "# OPTIONAL: Convert to percentages (0–100%)\n",
    "# transition_df_filtered['OBS_VALUE'] *= 100\n",
    "# transition_df_filtered['OBS_VALUE_Lagged1'] *= 100\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Save\n",
    "# ------------------------------------------------------------------\n",
    "Path('data/transition_variable').mkdir(parents=True, exist_ok=True)\n",
    "transition_df_filtered.to_csv(\n",
    "    'data/transition_variable/EU_partner_index_df.csv', index=False\n",
    ")\n",
    "\n",
    "print(f\"Lag added using pre-period data!\")\n",
    "print(f\"Valid lags: {transition_df_filtered['OBS_VALUE_Lagged1'].notna().sum():,}\")\n",
    "print(\"File saved: EU_partner_index_df.csv  (both OBS_VALUE and OBS_VALUE_Lagged1 are **proportions** of their respective month's total)\")\n",
    "\n",
    "# ================================\n",
    "# Controls (i,t) – LAGGED HICP & LAGGED ΔUnemployment\n",
    "# ================================\n",
    "\n",
    "controls_cols = [\n",
    "    'Country',\n",
    "    'Time',\n",
    "    'GDP (Million USD)',\n",
    "    'HICP (%, annual rate of change)',\n",
    "    'Unemployment Rate (%pop in LF)'\n",
    "]\n",
    "\n",
    "controls_full = controls_df[controls_cols].copy()\n",
    "\n",
    "# 1. Convert Time to datetime (same as before)\n",
    "controls_full['Time_dt'] = pd.to_datetime(controls_full['Time'], errors='coerce')\n",
    "controls_full = controls_full.sort_values(['Country', 'Time_dt'])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. FIRST DIFFERENCE UNEMPLOYMENT (still needed for the lag)\n",
    "# ------------------------------------------------------------------\n",
    "controls_full['ΔUnemployment'] = (\n",
    "    controls_full.groupby('Country')['Unemployment Rate (%pop in LF)'].diff()\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. CREATE LAG-1 FOR BOTH VARIABLES (within country)\n",
    "# ------------------------------------------------------------------\n",
    "controls_full['HICP_lag1'] = (\n",
    "    controls_full.groupby('Country')['HICP (%, annual rate of change)'].shift(1)\n",
    ")\n",
    "\n",
    "controls_full['Unemployment_lag1'] = (\n",
    "    controls_full.groupby('Country')['ΔUnemployment'].shift(1)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. FILTER TO ANALYSIS WINDOW (2024-11 → 2025-08)\n",
    "# ------------------------------------------------------------------\n",
    "controls_period = controls_full['Time_dt'].dt.to_period('M')\n",
    "controls_mask = (\n",
    "    (controls_period >= pd.Period(start_date, 'M')) &\n",
    "    (controls_period <= pd.Period(end_date, 'M'))\n",
    ")\n",
    "\n",
    "controls_out = controls_full.loc[controls_mask, [\n",
    "    'Country',\n",
    "    'Time_dt',\n",
    "    'GDP (Million USD)',\n",
    "    'HICP_lag1',               # <-- lagged HICP\n",
    "    'Unemployment_lag1'       # <-- lagged ΔUnemployment\n",
    "]].copy()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. FORMAT TIME COLUMN AND CLEAN UP\n",
    "# ------------------------------------------------------------------\n",
    "controls_out['Time'] = controls_out['Time_dt'].dt.strftime('%Y-%m')\n",
    "controls_out = controls_out.drop(columns=['Time_dt'])\n",
    "\n",
    "# final column order for the CSV\n",
    "controls_out = controls_out[[\n",
    "    'Country',\n",
    "    'Time',\n",
    "    'GDP (Million USD)',\n",
    "    'HICP_lag1',\n",
    "    'Unemployment_lag1'\n",
    "]]\n",
    "\n",
    "controls_out = controls_out.sort_values(['Country', 'Time']).reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. SAVE\n",
    "# ------------------------------------------------------------------\n",
    "Path('data/control_variable').mkdir(parents=True, exist_ok=True)\n",
    "controls_out.to_csv('data/control_variable/CountryControls_df.csv', index=False)\n",
    "\n",
    "print(\"\\nControls saved with:\")\n",
    "print(\"  • HICP_lag1  = HICP(t-1)\")\n",
    "print(\"  • ΔUnemployment_lag1 = ΔUnemployment(t-1)\")\n",
    "print(f\"  • Window: {start_date} → {end_date}\")\n",
    "print(f\"  • Valid HICP lags: {controls_out['HICP_lag1'].notna().sum():,}\")\n",
    "print(f\"  • Valid ΔUnemp lags: {controls_out['Unemployment_lag1'].notna().sum():,}\\n\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 924 non-EU rows → 25,870 EU rows kept\n",
      "Dropped 6 non-EU rows → 156 EU rows kept\n",
      "Dropped 1,707 non-EU rows → 11,035 EU rows kept\n",
      "Dropped 316 non-EU rows → 521 EU rows kept\n",
      "\n",
      "Kept only 27 EU countries: ['AT', 'BE', 'BG', 'CY', 'CZ', 'DE', 'DK', 'EE', 'ES', 'FI', 'FR', 'GR', 'HR', 'HU', 'IE', 'IT', 'LT', 'LU', 'LV', 'MT', 'NL', 'PL', 'PT', 'RO', 'SE', 'SI', 'SK']\n",
      "\n",
      "Saved: IndustrialProductionIndex_df.csv\n",
      "  → Analysis window: 2024-11 to 2025-08\n",
      "  → Valid lagged differences: 260\n",
      "  → First month in window has lag: True\n",
      "Lag added using pre-period data!\n",
      "Valid lags: 224\n",
      "File saved: EU_partner_index_df.csv  (both OBS_VALUE and OBS_VALUE_Lagged1 are **proportions** of their respective month's total)\n",
      "\n",
      "Controls saved with:\n",
      "  • HICP_lag1  = HICP(t-1)\n",
      "  • ΔUnemployment_lag1 = ΔUnemployment(t-1)\n",
      "  • Window: 2024-11 → 2025-08\n",
      "  • Valid HICP lags: 260\n",
      "  • Valid ΔUnemp lags: 260\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "f07007353f08b543",
   "metadata": {},
   "source": [
    "## 4) Baseline Simple OLS regressions\n",
    "\n",
    "We estimate the **short-run effect** of U.S. tariff exposure on monthly macroeconomic outcomes (Industrial Production Index (B+C), Stocks Index Return, FX change).\n",
    "The model includes **country** and **month fixed effects** to control for unobserved, time-invariant country characteristics and global shocks.\n",
    "\n",
    "$$\n",
    "y_{i,t} = \\mu_i + \\lambda_t\n",
    "+ \\alpha_0\\,\\text{Exposure}_{i,t}\n",
    "+ \\alpha_1\\,\\text{Exposure}_{i,t-1}\n",
    "+ \\Gamma' Z_{i,t}\n",
    "+ \\varepsilon_{i,t}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $y_{i,t}$ — Outcome variable (Industrial Production Index (B+C) YoY for country *i* in month *t*, Stocks Index for country *i* in month *t*\n",
    "- $\\text{Exposure}_{i,t}$ — Country *i*’s effective tariff exposure in month *t*\n",
    "- $\\text{Exposure}_{i,t-1}$ — One-month lag of tariff exposure (captures delayed reaction)\n",
    "- $Z_{i,t}$ — Vector of monthly country-specific control variables (HICP YoY%, Δ unemployment)\n",
    "- $\\mu_i$ — Country fixed effects (absorbing structural country heterogeneity)\n",
    "- $\\lambda_t$ — Month fixed effects (absorbing global macro shocks)\n",
    "- $\\varepsilon_{i,t}$ — Idiosyncratic error term, clustered at the country level\n",
    "\n",
    "---\n",
    "\n",
    "### **Estimation Details**\n",
    "\n",
    "- **Estimator:** OLS with two-way (country and month) fixed effects\n",
    "- **Frequency:** Monthly (2024-10 → 2025-08)\n",
    "- **Standard Errors:** Clustered by country\n",
    "- **Sample:** EU countries only, using *effective* tariff exposure measure\n",
    "- **Controls:** Domestic macro variables (HICP YoY%, Δ unemployment)\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters of Interest**\n",
    "\n",
    "- $\\alpha_0$ — Contemporaneous effect of tariff exposure\n",
    "- $\\alpha_1$ — One-month-lagged effect\n",
    "- $\\alpha_0 + \\alpha_1$ — Cumulative 0–1-month effect (interpreted as the total short-run impact)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9274b65bc773f87b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:18:56.271168Z",
     "start_time": "2025-11-08T12:18:55.998879Z"
    }
   },
   "source": [
    "\n",
    "BASE = Path.cwd() / \"data\"\n",
    "\n",
    "ipi      = pd.read_csv(BASE / \"dependent_variable\" / \"IndustrialProductionIndex_df.csv\")\n",
    "stocks   = pd.read_csv(BASE / \"dependent_variable\" / \"StockIndex_df.csv\")\n",
    "exposure = pd.read_csv(BASE / \"independent_variable\" / \"CountryTariffExposure_df.csv\")\n",
    "controls = pd.read_csv(BASE / \"control_variable\" / \"CountryControls_df.csv\")\n",
    "\n",
    "\n",
    "# Convert Time → Period[M] (keeps month arithmetic)\n",
    "\n",
    "for df in (ipi, stocks, exposure, controls):\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\").dt.to_period(\"M\")\n",
    "\n",
    "# Choose Y\n",
    "# ---- Industrial Production (B+C) YoY ----\n",
    "df_dep = ipi.rename(columns={\"diff_IPI\": \"y\"})\n",
    "# ---- Uncomment to run on Stock log-returns instead ----\n",
    "#df_dep = stocks.rename(columns={\"Log Monthly Return\": \"y\"})\n",
    "#\n",
    "\n",
    "\n",
    "exp = exposure.rename(columns={\"Exposure\": \"Exposure_t\"})\n",
    "exp = exp.sort_values([\"Country\", \"Time\"])\n",
    "exp[\"Exposure_t1\"] = exp.groupby(\"Country\")[\"Exposure_t\"].shift(1)\n",
    "exp = exp.dropna(subset=[\"Exposure_t1\"])\n",
    "\n",
    "df = (\n",
    "    df_dep[[\"Country\", \"Time\", \"y\"]]\n",
    "    .merge(exp[[\"Country\", \"Time\", \"Exposure_t\", \"Exposure_t1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    "    .merge(controls[[\"Country\", \"Time\",\n",
    "                     \"HICP_lag1\",\n",
    "                     \"Unemployment_lag1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    ")\n",
    "\n",
    "df = df[(df[\"Time\"] >= pd.Period(\"2024-11\", \"M\")) &\n",
    "        (df[\"Time\"] <= pd.Period(\"2025-08\", \"M\"))]\n",
    "\n",
    "df[\"Time_dt\"] = df[\"Time\"].dt.start_time          # first day of month → datetime64\n",
    "df = df.set_index([\"Country\", \"Time_dt\"])\n",
    "df = df.drop(columns=[\"Time\"])                    # optional cleanup\n",
    "\n",
    "print(\"Months in final panel:\", sorted(df.index.get_level_values(1).unique()))\n",
    "print(\"Obs per country (min/avg/max):\",\n",
    "      df.groupby(level=0).size().min(),\n",
    "      df.groupby(level=0).size().mean().round(1),\n",
    "      df.groupby(level=0).size().max())\n",
    "\n",
    "\n",
    "# Run two-way FE regression (cluster by country)\n",
    "\n",
    "exog_vars = [\n",
    "    \"Exposure_t\",\n",
    "    \"Exposure_t1\",\n",
    "    \"HICP_lag1\",\n",
    "    \"Unemployment_lag1\"\n",
    "]\n",
    "\n",
    "mod = PanelOLS(\n",
    "    dependent=df[\"y\"],\n",
    "    exog=df[exog_vars],\n",
    "    entity_effects=True,   # μ_i\n",
    "    time_effects=True,     # λ_t\n",
    ")\n",
    "\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(res)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months in final panel: [Timestamp('2024-11-01 00:00:00'), Timestamp('2024-12-01 00:00:00'), Timestamp('2025-01-01 00:00:00'), Timestamp('2025-02-01 00:00:00'), Timestamp('2025-03-01 00:00:00'), Timestamp('2025-04-01 00:00:00'), Timestamp('2025-05-01 00:00:00'), Timestamp('2025-06-01 00:00:00'), Timestamp('2025-07-01 00:00:00'), Timestamp('2025-08-01 00:00:00')]\n",
      "Obs per country (min/avg/max): 10 10.0 10\n",
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                      y   R-squared:                        0.0369\n",
      "Estimator:                   PanelOLS   R-squared (Between):             -4.7928\n",
      "No. Observations:                 260   R-squared (Within):              -0.0113\n",
      "Date:                Sat, Nov 08 2025   R-squared (Overall):             -0.2654\n",
      "Time:                        13:18:56   Log-likelihood                   -1088.7\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      2.1185\n",
      "Entities:                          26   P-value                           0.0795\n",
      "Avg Obs:                      10.0000   Distribution:                   F(4,221)\n",
      "Min Obs:                      10.0000                                           \n",
      "Max Obs:                      10.0000   F-statistic (robust):             3.2894\n",
      "                                        P-value                           0.0121\n",
      "Time periods:                      10   Distribution:                   F(4,221)\n",
      "Avg Obs:                       26.000                                           \n",
      "Min Obs:                       26.000                                           \n",
      "Max Obs:                       26.000                                           \n",
      "                                                                                \n",
      "                                 Parameter Estimates                                 \n",
      "=====================================================================================\n",
      "                   Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------------\n",
      "Exposure_t           -0.2772     0.5828    -0.4755     0.6349     -1.4258      0.8715\n",
      "Exposure_t1          -1.9443     0.6701    -2.9015     0.0041     -3.2649     -0.6237\n",
      "HICP_lag1             3.0310     2.2995     1.3181     0.1888     -1.5007      7.5627\n",
      "Unemployment_lag1     0.8992     3.4552     0.2602     0.7949     -5.9102      7.7085\n",
      "=====================================================================================\n",
      "\n",
      "F-test for Poolability: 3.6278\n",
      "P-value: 0.0000\n",
      "Distribution: F(34,221)\n",
      "\n",
      "Included effects: Entity, Time\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "c04c7b31db23f8e1",
   "metadata": {},
   "source": [
    "## 5) Extended Specification — Linear Heterogeneity with Trade Openness Interaction\n",
    "\n",
    "To allow the impact of tariff exposure to vary across countries with different levels of trade openness,\n",
    "we extend the baseline specification by interacting exposure with lagged openness.\n",
    "This captures whether **more open economies** react differently to tariff shocks.\n",
    "\n",
    "$$\n",
    "y_{i,t} = \\mu_i + \\lambda_t\n",
    "+ \\alpha_0\\,\\text{Exposure}_{i,t}\n",
    "+ \\alpha_1\\,\\text{Exposure}_{i,t-1}\n",
    "+ \\beta_0\\,(\\text{Exposure}_{i,t} \\times \\text{Openness}_{i,t-1}^{US})\n",
    "+ \\beta_1\\,(\\text{Exposure}_{i,t-1} \\times \\text{Openness}_{i,t-1}^{US})\n",
    "+ \\Gamma' Z_{i,t}\n",
    "+ \\varepsilon_{i,t}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $y_{i,t}$ — Outcome variable (e.g. Industrial Production YoY for country *i* in month *t*)\n",
    "- $\\text{Exposure}_{i,t}$ — Effective tariff exposure in month *t*\n",
    "- $\\text{Exposure}_{i,t-1}$ — One-month lag of exposure\n",
    "- $\\text{Openness}_{i,t-1}^{US}$ — Lagged trade openness index relative to the US (annual, mapped to months)\n",
    "- $(\\text{Exposure}_{i,t} \\times \\text{Openness}_{i,t-1}^{US})$ — Interaction term capturing heterogeneous exposure effects\n",
    "- $Z_{i,t}$ — Monthly domestic controls (HICP YoY, Δ unemployment)\n",
    "- $\\mu_i$ — Country fixed effects\n",
    "- $\\lambda_t$ — Month fixed effects\n",
    "- $\\varepsilon_{i,t}$ — Error term clustered by country\n",
    "\n",
    "\n",
    "### **Interpretation**\n",
    "\n",
    "- $\\alpha_0$, $\\alpha_1$ — Baseline (average) effects of exposure at zero openness\n",
    "- $\\beta_0$, $\\beta_1$ — Marginal change in the exposure effect as openness increases\n",
    "- **Marginal effect of exposure:**\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t}}\n",
    "  = \\alpha_0 + \\beta_0\\,\\text{Openness}_{i,t-1}^{US}\n",
    "  $$\n",
    "  and\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t-1}}\n",
    "  = \\alpha_1 + \\beta_1\\,\\text{Openness}_{i,t-1}^{US}\n",
    "  $$\n",
    "- Report **cumulative marginal effect** $(\\alpha_0+\\alpha_1) + (\\beta_0+\\beta_1)\\text{Openness}_{i,t-1}^{US}$ evaluated at low, median, and high openness levels.\n",
    "\n",
    "---\n",
    "\n",
    "### **Estimation Details**\n",
    "\n",
    "- **Estimator:** OLS with two-way (country and month) fixed effects\n",
    "- **Frequency:** Monthly (2024-10 → 2025-09)\n",
    "- **Standard Errors:** Clustered by country\n",
    "- **Sample:** EU countries only\n",
    "- **Controls:** Domestic macro variables (HICP YoY, unemployment)\n",
    "\n",
    "---\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "This model tests whether the **sensitivity to U.S. tariff shocks** depends on how open a country's economy is to the US.\n",
    "A positive $\\beta_0$ or $\\beta_1$ implies that **more open economies are more affected** by tariff changes,\n",
    "while a negative coefficient indicates **buffering or diversification effects** from openness.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "85dc37f43bcfbf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:21:59.918073Z",
     "start_time": "2025-11-08T12:21:59.768134Z"
    }
   },
   "source": [
    "# Traditional Trade Openness\n",
    "BASE = Path.cwd() / \"data\"\n",
    "\n",
    "ipi        = pd.read_csv(BASE / \"dependent_variable\" / \"IndustrialProductionIndex_df.csv\")\n",
    "stocks     = pd.read_csv(BASE / \"dependent_variable\" / \"StockIndex_df.csv\")\n",
    "exposure   = pd.read_csv(BASE / \"independent_variable\" / \"CountryTariffExposure_df.csv\")\n",
    "controls   = pd.read_csv(BASE / \"control_variable\" / \"CountryControls_df.csv\")\n",
    "openness   = pd.read_csv(BASE / \"transition_variable\" / \"TradeOpennessAnnual_df.csv\")\n",
    "\n",
    "for df in (ipi, stocks, exposure, controls):\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\").dt.to_period(\"M\")\n",
    "\n",
    "openness = openness[[\"Country\", \"Time\", \"Trade_Openness_pct_GDP\"]].copy()\n",
    "openness.rename(columns={\"Trade_Openness_pct_GDP\": \"Openness_annual\"}, inplace=True)\n",
    "openness[\"Year\"] = pd.to_datetime(openness[\"Time\"].astype(str), errors=\"coerce\").dt.year\n",
    "openness = openness.drop(columns=[\"Time\"])\n",
    "\n",
    "monthly_open = []\n",
    "for year in [2024, 2025]:\n",
    "    months = pd.date_range(f\"{year}-01-01\", f\"{year}-12-31\", freq=\"MS\")\n",
    "    temp   = pd.DataFrame({\"Time_dt\": months})\n",
    "    temp[\"Time\"] = temp[\"Time_dt\"].dt.to_period(\"M\")\n",
    "    temp = temp.merge(openness[openness[\"Year\"] == year], how=\"cross\")\n",
    "    monthly_open.append(temp)\n",
    "\n",
    "openness_monthly = pd.concat(monthly_open, ignore_index=True)\n",
    "openness_monthly = openness_monthly[[\"Country\", \"Time\", \"Openness_annual\"]]\n",
    "openness_monthly = openness_monthly.rename(columns={\"Openness_annual\": \"Openness\"})\n",
    "\n",
    "#df_dep = stocks.rename(columns={\"Log Monthly Return\": \"y\"})\n",
    "df_dep = ipi.rename(columns={\"diff_IPI\": \"y\"})\n",
    "\n",
    "exp = exposure.rename(columns={\"Exposure\": \"Exposure_t\"})\n",
    "exp = exp.sort_values([\"Country\", \"Time\"])\n",
    "exp[\"Exposure_t1\"] = exp.groupby(\"Country\")[\"Exposure_t\"].shift(1)\n",
    "\n",
    "exp = exp.merge(openness_monthly, on=[\"Country\", \"Time\"], how=\"left\")\n",
    "exp[\"Openness_t1\"] = exp.groupby(\"Country\")[\"Openness\"].shift(1)\n",
    "\n",
    "exp = exp.dropna(subset=[\"Exposure_t1\", \"Openness_t1\"])\n",
    "\n",
    "exp[\"Exp_t_x_Open_t1\"]   = exp[\"Exposure_t\"]   * exp[\"Openness_t1\"]\n",
    "exp[\"Exp_t1_x_Open_t1\"]  = exp[\"Exposure_t1\"]  * exp[\"Openness_t1\"]\n",
    "\n",
    "df = (\n",
    "    df_dep[[\"Country\", \"Time\", \"y\"]]\n",
    "    .merge(exp[[\"Country\", \"Time\",\n",
    "                \"Exposure_t\", \"Exposure_t1\",\n",
    "                \"Exp_t_x_Open_t1\", \"Exp_t1_x_Open_t1\",\n",
    "                \"Openness_t1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    "    .merge(controls[[\"Country\", \"Time\",\n",
    "                     \"HICP_lag1\",\n",
    "                     \"Unemployment_lag1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    ")\n",
    "\n",
    "df = df[(df[\"Time\"] >= pd.Period(\"2024-11\", \"M\")) &\n",
    "        (df[\"Time\"] <= pd.Period(\"2025-08\", \"M\"))]\n",
    "\n",
    "df[\"Time_dt\"] = df[\"Time\"].dt.start_time\n",
    "df = df.set_index([\"Country\", \"Time_dt\"])\n",
    "df = df.drop(columns=[\"Time\"])\n",
    "\n",
    "exog_vars = [\n",
    "    \"Exposure_t\",\n",
    "    \"Exposure_t1\",\n",
    "    \"Exp_t_x_Open_t1\",\n",
    "    \"Exp_t1_x_Open_t1\",\n",
    "    \"Openness_t1\",\n",
    "    \"HICP_lag1\",\n",
    "    \"Unemployment_lag1\"\n",
    "]\n",
    "\n",
    "mod = PanelOLS(\n",
    "    dependent=df[\"y\"],\n",
    "    exog=df[exog_vars],\n",
    "    entity_effects=True,\n",
    "    time_effects=True,\n",
    ")\n",
    "\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(res)\n",
    "\n",
    "print(\"\\n=== MARGINAL EFFECTS OF TARIFF EXPOSURE ===\")\n",
    "open_levels = {\n",
    "    \"Low\":     df[\"Openness_t1\"].quantile(0.25),\n",
    "    \"Median\":  df[\"Openness_t1\"].median(),\n",
    "    \"High\":    df[\"Openness_t1\"].quantile(0.75)\n",
    "}\n",
    "\n",
    "for label, q in open_levels.items():\n",
    "    me_t = res.params[\"Exposure_t\"] + res.params[\"Exp_t_x_Open_t1\"] * q\n",
    "    var_t = (res.cov.loc[\"Exposure_t\", \"Exposure_t\"] +\n",
    "             2 * q * res.cov.loc[\"Exposure_t\", \"Exp_t_x_Open_t1\"] +\n",
    "             q**2 * res.cov.loc[\"Exp_t_x_Open_t1\", \"Exp_t_x_Open_t1\"])\n",
    "    se_t = np.sqrt(var_t)\n",
    "\n",
    "    me_t1 = res.params[\"Exposure_t1\"] + res.params[\"Exp_t1_x_Open_t1\"] * q\n",
    "    var_t1 = (res.cov.loc[\"Exposure_t1\", \"Exposure_t1\"] +\n",
    "              2 * q * res.cov.loc[\"Exposure_t1\", \"Exp_t1_x_Open_t1\"] +\n",
    "              q**2 * res.cov.loc[\"Exp_t1_x_Open_t1\", \"Exp_t1_x_Open_t1\"])\n",
    "    se_t1 = np.sqrt(var_t1)\n",
    "\n",
    "    cov_cross = (res.cov.loc[\"Exposure_t\", \"Exposure_t1\"] +\n",
    "                 q * (res.cov.loc[\"Exposure_t\", \"Exp_t1_x_Open_t1\"] +\n",
    "                      res.cov.loc[\"Exp_t_x_Open_t1\", \"Exposure_t1\"]) +\n",
    "                 q**2 * res.cov.loc[\"Exp_t_x_Open_t1\", \"Exp_t1_x_Open_t1\"])\n",
    "    var_cum = var_t + var_t1 + 2 * cov_cross\n",
    "    se_cum = np.sqrt(var_cum)\n",
    "    me_cum = me_t + me_t1\n",
    "\n",
    "    print(f\"\\n{label} Openness ({q:.4f}):\")\n",
    "    print(f\"  Contemporaneous : {me_t: .5f} (se = {se_t: .5f})\")\n",
    "    print(f\"  Lagged          : {me_t1:.5f} (se = {se_t1:.5f})\")\n",
    "    print(f\"  Cumulative      : {me_cum:.5f} (se = {se_cum:.5f})\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                      y   R-squared:                        0.0436\n",
      "Estimator:                   PanelOLS   R-squared (Between):             -3.7374\n",
      "No. Observations:                 260   R-squared (Within):              -0.0004\n",
      "Date:                Sat, Nov 08 2025   R-squared (Overall):             -0.1990\n",
      "Time:                        13:21:59   Log-likelihood                   -1087.8\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      1.4195\n",
      "Entities:                          26   P-value                           0.1986\n",
      "Avg Obs:                      10.0000   Distribution:                   F(7,218)\n",
      "Min Obs:                      10.0000                                           \n",
      "Max Obs:                      10.0000   F-statistic (robust):             4.3066\n",
      "                                        P-value                           0.0002\n",
      "Time periods:                      10   Distribution:                   F(7,218)\n",
      "Avg Obs:                       26.000                                           \n",
      "Min Obs:                       26.000                                           \n",
      "Max Obs:                       26.000                                           \n",
      "                                                                                \n",
      "                                 Parameter Estimates                                 \n",
      "=====================================================================================\n",
      "                   Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------------\n",
      "Exposure_t            1.2177     1.5086     0.8072     0.4204     -1.7555      4.1909\n",
      "Exposure_t1          -3.0583     2.3736    -1.2885     0.1989     -7.7363      1.6198\n",
      "Exp_t_x_Open_t1      -0.4127     0.3422    -1.2061     0.2291     -1.0871      0.2617\n",
      "Exp_t1_x_Open_t1      0.2618     0.4906     0.5337     0.5941     -0.7051      1.2286\n",
      "Openness_t1          -1.1643     0.5031    -2.3141     0.0216     -2.1559     -0.1727\n",
      "HICP_lag1             3.1848     2.2688     1.4037     0.1618     -1.2869      7.6565\n",
      "Unemployment_lag1     0.7036     3.5159     0.2001     0.8416     -6.2260      7.6332\n",
      "=====================================================================================\n",
      "\n",
      "F-test for Poolability: 3.4069\n",
      "P-value: 0.0000\n",
      "Distribution: F(34,218)\n",
      "\n",
      "Included effects: Entity, Time\n",
      "\n",
      "=== MARGINAL EFFECTS OF TARIFF EXPOSURE ===\n",
      "\n",
      "Low Openness (1.3166):\n",
      "  Contemporaneous :  0.67435 (se =  1.08664)\n",
      "  Lagged          : -2.71358 (se = 1.74634)\n",
      "  Cumulative      : -2.03923 (se = 2.19047)\n",
      "\n",
      "Median Openness (2.2212):\n",
      "  Contemporaneous :  0.30104 (se =  0.81468)\n",
      "  Lagged          : -2.47676 (se = 1.32583)\n",
      "  Cumulative      : -2.17572 (se = 1.66568)\n",
      "\n",
      "High Openness (2.9337):\n",
      "  Contemporaneous :  0.00701 (se =  0.62558)\n",
      "  Lagged          : -2.29024 (se = 1.00875)\n",
      "  Cumulative      : -2.28323 (se = 1.26693)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "28b5813d75cfd754",
   "metadata": {},
   "source": [
    "## 6) Extended Specification — PSTR Model with Smooth Transition by Trade Openness\n",
    "\n",
    "We now allow the effect of tariff exposure to vary **smoothly** with the level of trade openness with the US.\n",
    "Instead of assuming a linear interaction, we introduce a **logistic transition function** that captures gradual changes in the impact of exposure as openness increases.\n",
    "\n",
    "The logistic transition function is defined as:\n",
    "\n",
    "$$\n",
    "G\\!\\left(\\text{Openness}_{i,t-1}^{US};\\gamma,c\\right)\n",
    "= \\frac{1}{1 + \\exp\\!\\big[-\\gamma\\big(\\text{Openness}_{i,t-1}^{US} - c\\big)\\big]}.\n",
    "$$\n",
    "\n",
    "The corresponding PSTR regression is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{i,t} &= \\mu_i + \\lambda_t\n",
    "+ \\alpha_0\\,\\text{Exposure}_{i,t}\n",
    "+ \\alpha_1\\,\\text{Exposure}_{i,t-1} \\\\\n",
    "&\\quad + \\big(\\beta_0\\,\\text{Exposure}_{i,t} + \\beta_1\\,\\text{Exposure}_{i,t-1}\\big)\n",
    "\\,G\\!\\left(\\text{Openness}_{i,t-1}^{US};\\gamma,c\\right)\n",
    "+ \\Gamma' Z_{i,t}\n",
    "+ \\varepsilon_{i,t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $y_{i,t}$ — Outcome variable (e.g. Industrial Production YoY for country *i* in month *t*)\n",
    "- $\\text{Exposure}_{i,t}$ — Effective tariff exposure in month *t*\n",
    "- $\\text{Exposure}_{i,t-1}$ — One-month lag of exposure\n",
    "- $\\text{Openness}_{i,t-1}^{US}$ — Lagged trade openness index (annual, mapped to months)\n",
    "- $G(\\text{Openness}_{i,t-1}^{US};\\gamma,c)$ — Logistic transition function with:\n",
    "  - $c$: threshold (location) where $G=0.5$\n",
    "  - $\\gamma$: smoothness parameter controlling how sharp the transition is\n",
    "- $Z_{i,t}$ — Monthly domestic controls (HICP YoY, Δ unemployment)\n",
    "- $\\mu_i$ — Country fixed effects\n",
    "- $\\lambda_t$ — Month fixed effects\n",
    "- $\\varepsilon_{i,t}$ — Error term clustered by country\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation**\n",
    "\n",
    "- $\\alpha_0$, $\\alpha_1$ — Baseline exposure effects when openness is low ($G \\approx 0$)\n",
    "- $\\beta_0$, $\\beta_1$ — Incremental effects as openness increases ($G \\to 1$)\n",
    "- **Marginal effects of exposure:**\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t}}\n",
    "  = \\alpha_0 + \\beta_0\\,G(\\text{Openness}_{i,t-1}^{US};\\gamma,c),\n",
    "  $$\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t-1}}\n",
    "  = \\alpha_1 + \\beta_1\\,G(\\text{Openness}_{i,t-1}^{US};\\gamma,c).\n",
    "  $$\n",
    "- **Cumulative short-run effect (0–1 month):**\n",
    "  $$\n",
    "  (\\alpha_0 + \\alpha_1) + (\\beta_0 + \\beta_1)\\,G(\\text{Openness}_{i,t-1}^{US};\\gamma,c).\n",
    "  $$\n",
    "- When $\\gamma$ is large, $G(\\cdot)$ approximates a sharp threshold model; when small, the transition is smooth.\n",
    "\n",
    "---\n",
    "\n",
    "### **Estimation Details**\n",
    "\n",
    "- **Estimator:** Nonlinear least squares with two-way (country and month) fixed effects\n",
    "- **Frequency:** Monthly (2024-10 → 2025-09)\n",
    "- **Standard Errors:** Clustered by country\n",
    "- **Sample:** EU countries only\n",
    "- **Controls:** Domestic macro variables (HICP YoY, unemployment)\n",
    "- **Pre-processing:** Standardize openness before estimation; report the threshold $c$ in original units after transformation\n",
    "\n",
    "---\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "This model identifies whether the **effect of U.S. tariff shocks on economic outcomes** depends on how open each country is to trade with the US.\n",
    "The logistic transition function captures a **nonlinear response** — for example, more open economies may only become significantly affected **after** crossing a critical openness threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0bc38c25a7789a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:22:22.390015Z",
     "start_time": "2025-11-08T12:22:22.183072Z"
    }
   },
   "source": [
    "# Traditional Trade Openness \n",
    "BASE = Path.cwd() / \"data\"\n",
    "\n",
    "ipi        = pd.read_csv(BASE / \"dependent_variable\" / \"IndustrialProductionIndex_df.csv\")\n",
    "stocks     = pd.read_csv(BASE / \"dependent_variable\" / \"StockIndex_df.csv\")\n",
    "exposure   = pd.read_csv(BASE / \"independent_variable\" / \"CountryTariffExposure_df.csv\")\n",
    "controls   = pd.read_csv(BASE / \"control_variable\" / \"CountryControls_df.csv\")\n",
    "openness   = pd.read_csv(BASE / \"transition_variable\" / \"TradeOpennessAnnual_df.csv\")\n",
    "\n",
    "for df in (ipi, stocks, exposure, controls):\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\").dt.to_period(\"M\")\n",
    "\n",
    "openness = openness[[\"Country\", \"Time\", \"Openness_Lag1\"]].copy()\n",
    "openness.rename(columns={\"Openness_Lag1\": \"Openness_annual\"}, inplace=True)\n",
    "openness[\"Year\"] = pd.to_datetime(openness[\"Time\"].astype(str), errors=\"coerce\").dt.year\n",
    "openness = openness.drop(columns=[\"Time\"])\n",
    "\n",
    "monthly_open = []\n",
    "for year in [2024, 2025]:\n",
    "    months = pd.date_range(f\"{year}-01-01\", f\"{year}-12-31\", freq=\"MS\")\n",
    "    tmp = pd.DataFrame({\"Time_dt\": months})\n",
    "    tmp[\"Time\"] = tmp[\"Time_dt\"].dt.to_period(\"M\")\n",
    "    tmp = tmp.merge(openness[openness[\"Year\"] == year][[\"Country\", \"Openness_annual\"]], how=\"cross\")\n",
    "    monthly_open.append(tmp)\n",
    "\n",
    "openness_monthly = pd.concat(monthly_open, ignore_index=True)\n",
    "openness_monthly = openness_monthly[[\"Country\", \"Time\", \"Openness_annual\"]]\n",
    "openness_monthly = openness_monthly.rename(columns={\"Openness_annual\": \"Openness\"})\n",
    "\n",
    "#df_dep = stocks.rename(columns={\"Log Monthly Return\": \"y\"})\n",
    "df_dep = ipi.rename(columns={\"diff_IPI\": \"y\"})\n",
    "\n",
    "exp = exposure.rename(columns={\"Exposure\": \"Exposure_t\"}).sort_values([\"Country\", \"Time\"])\n",
    "exp[\"Exposure_t1\"] = exp.groupby(\"Country\")[\"Exposure_t\"].shift(1)\n",
    "\n",
    "exp = exp.merge(openness_monthly, on=[\"Country\", \"Time\"], how=\"left\")\n",
    "exp[\"Openness_t1\"] = exp.groupby(\"Country\")[\"Openness\"].shift(1)\n",
    "\n",
    "exp = exp.dropna(subset=[\"Exposure_t1\", \"Openness_t1\"])\n",
    "\n",
    "df = (\n",
    "    df_dep[[\"Country\", \"Time\", \"y\"]]\n",
    "    .merge(exp[[\"Country\", \"Time\", \"Exposure_t\", \"Exposure_t1\", \"Openness_t1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    "    .merge(controls[[\"Country\", \"Time\",\n",
    "                     \"HICP_lag1\",\n",
    "                     \"Unemployment_lag1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    ")\n",
    "\n",
    "df = df[(df[\"Time\"] >= pd.Period(\"2024-11\", \"M\")) &\n",
    "        (df[\"Time\"] <= pd.Period(\"2025-08\", \"M\"))].copy()\n",
    "\n",
    "df[\"Time_dt\"] = df[\"Time\"].dt.start_time\n",
    "df = df.set_index([\"Country\", \"Time_dt\"]).sort_index()\n",
    "df.drop(columns=[\"Time\"], inplace=True)\n",
    "\n",
    "open_mean = df[\"Openness_t1\"].mean()\n",
    "open_std  = df[\"Openness_t1\"].std(ddof=0)\n",
    "df[\"Open_std\"] = (df[\"Openness_t1\"] - open_mean) / open_std\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"HICP_lag1\": \"HICP\",\n",
    "    \"Unemployment_lag1\": \"Unemp\"\n",
    "})\n",
    "\n",
    "def twoway_within_transform(panel_df, cols):\n",
    "    \"\"\"\n",
    "    Double-demean columns (entity & time FE).\n",
    "    Returns a new DataFrame with *_wt (within-transformed) columns.\n",
    "    \"\"\"\n",
    "    out = panel_df.copy()\n",
    "    ent_means = out.groupby(level=0)[cols].transform(\"mean\")\n",
    "    time_means = out.groupby(level=1)[cols].transform(\"mean\")\n",
    "    overall_means = out[cols].mean()\n",
    "    wt = out[cols] - ent_means - time_means + overall_means\n",
    "    wt.columns = [c + \"_wt\" for c in cols]\n",
    "    return wt\n",
    "\n",
    "base_cols = [\"y\", \"Exposure_t\", \"Exposure_t1\", \"HICP\", \"Unemp\", \"Open_std\"]\n",
    "wt = twoway_within_transform(df, base_cols)\n",
    "for c in wt.columns:\n",
    "    df[c] = wt[c]\n",
    "\n",
    "def G_logistic(z, gamma, c):\n",
    "    return 1.0 / (1.0 + np.exp(-gamma * (z - c)))\n",
    "\n",
    "def build_X_within(gamma, c, work_df):\n",
    "    \"\"\"\n",
    "    Build within-transformed X for given (γ,c):\n",
    "      [ Exp_t_wt, Exp_t1_wt, (Exp_t*G)_wt, (Exp_t1*G)_wt, HICP_wt, Unemp_wt ]\n",
    "    \"\"\"\n",
    "    z = work_df[\"Open_std_wt\"].to_numpy()\n",
    "    G = G_logistic(z, gamma, c)\n",
    "    X = np.column_stack([\n",
    "        work_df[\"Exposure_t_wt\"].to_numpy(),\n",
    "        work_df[\"Exposure_t1_wt\"].to_numpy(),\n",
    "        work_df[\"Exposure_t_wt\"].to_numpy()  * G,\n",
    "        work_df[\"Exposure_t1_wt\"].to_numpy() * G,\n",
    "        work_df[\"HICP_wt\"].to_numpy(),\n",
    "        work_df[\"Unemp_wt\"].to_numpy(),\n",
    "    ])\n",
    "    return X\n",
    "\n",
    "y_wt = df[\"y_wt\"].to_numpy()\n",
    "\n",
    "def ssr_objective(theta):\n",
    "    gamma, c = theta\n",
    "    if gamma <= 0:\n",
    "        return 1e12 + (abs(gamma) + 1.0) * 1e12\n",
    "    X = build_X_within(gamma, c, df)\n",
    "    beta_hat, *_ = np.linalg.lstsq(X, y_wt, rcond=None)\n",
    "    resid = y_wt - X @ beta_hat\n",
    "    return float(resid @ resid)\n",
    "\n",
    "theta0 = np.array([1.0, 0.0])\n",
    "bounds = [(1e-3, 100.0), (-3.0, 3.0)]\n",
    "\n",
    "opt = minimize(ssr_objective, theta0, method=\"L-BFGS-B\", bounds=bounds)\n",
    "gamma_hat, c_hat_std = opt.x\n",
    "print(\"\\n=== PSTR (NLS) transition estimates ===\")\n",
    "print(f\"  gamma (smoothness): {gamma_hat: .4f}\")\n",
    "print(f\"  c (threshold, standardized): {c_hat_std: .4f}\")\n",
    "c_hat_orig = open_mean + open_std * c_hat_std\n",
    "print(f\"  c (threshold, ORIGINAL openness units): {c_hat_orig: .4f}\")\n",
    "\n",
    "G_hat = G_logistic(df[\"Open_std\"].to_numpy(), gamma_hat, c_hat_std)\n",
    "df[\"G_hat\"] = G_hat\n",
    "\n",
    "df[\"Exp_t_G\"]   = df[\"Exposure_t\"]  * df[\"G_hat\"]\n",
    "df[\"Exp_t1_G\"]  = df[\"Exposure_t1\"] * df[\"G_hat\"]\n",
    "\n",
    "exog_cols = [\"Exposure_t\", \"Exposure_t1\", \"Exp_t_G\", \"Exp_t1_G\", \"HICP\", \"Unemp\"]\n",
    "\n",
    "mod = PanelOLS(\n",
    "    dependent=df[\"y\"],\n",
    "    exog=df[exog_cols],\n",
    "    entity_effects=True,\n",
    "    time_effects=True,\n",
    ")\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(\"\\n=== PSTR Fixed-Effects (linear part) ===\")\n",
    "print(res)\n",
    "\n",
    "print(\"\\n=== MARGINAL EFFECTS OF TARIFF EXPOSURE (PSTR) ===\")\n",
    "open_levels = {\n",
    "    \"Low\":    df[\"Openness_t1\"].quantile(0.25),\n",
    "    \"Median\": df[\"Openness_t1\"].quantile(0.50),\n",
    "    \"High\":   df[\"Openness_t1\"].quantile(0.75),\n",
    "}\n",
    "\n",
    "alpha0 = res.params[\"Exposure_t\"]\n",
    "alpha1 = res.params[\"Exposure_t1\"]\n",
    "beta0  = res.params[\"Exp_t_G\"]\n",
    "beta1  = res.params[\"Exp_t1_G\"]\n",
    "V = res.cov\n",
    "\n",
    "for label, q_orig in open_levels.items():\n",
    "    z = (q_orig - open_mean) / open_std\n",
    "    Gq = G_logistic(z, gamma_hat, c_hat_std)\n",
    "\n",
    "    me_t = alpha0 + beta0 * Gq\n",
    "    var_t = (\n",
    "        V.loc[\"Exposure_t\", \"Exposure_t\"]\n",
    "        + 2*Gq*V.loc[\"Exposure_t\", \"Exp_t_G\"]\n",
    "        + (Gq**2)*V.loc[\"Exp_t_G\", \"Exp_t_G\"]\n",
    "    )\n",
    "    se_t = float(np.sqrt(var_t))\n",
    "\n",
    "    me_t1 = alpha1 + beta1 * Gq\n",
    "    var_t1 = (\n",
    "        V.loc[\"Exposure_t1\", \"Exposure_t1\"]\n",
    "        + 2*Gq*V.loc[\"Exposure_t1\", \"Exp_t1_G\"]\n",
    "        + (Gq**2)*V.loc[\"Exp_t1_G\", \"Exp_t1_G\"]\n",
    "    )\n",
    "    se_t1 = float(np.sqrt(var_t1))\n",
    "\n",
    "    cov_cross = (\n",
    "        V.loc[\"Exposure_t\", \"Exposure_t1\"]\n",
    "        + Gq*(V.loc[\"Exposure_t\", \"Exp_t1_G\"] + V.loc[\"Exp_t_G\", \"Exposure_t1\"])\n",
    "        + (Gq**2)*V.loc[\"Exp_t_G\", \"Exp_t1_G\"]\n",
    "    )\n",
    "    var_cum = var_t + var_t1 + 2*cov_cross\n",
    "    se_cum = float(np.sqrt(var_cum))\n",
    "    me_cum = me_t + me_t1\n",
    "\n",
    "    print(f\"\\n{label} Openness (orig={q_orig:.4f}, z={z:.3f}, G={Gq:.3f}):\")\n",
    "    print(f\"  ∂y/∂Exposure_t      : {me_t: .6f}  (se = {se_t: .6f})\")\n",
    "    print(f\"  ∂y/∂Exposure_(t-1)  : {me_t1:.6f}  (se = {se_t1:.6f})\")\n",
    "    print(f\"  Cumulative (0–1 mo) : {me_cum:.6f}  (se = {se_cum:.6f})\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PSTR (NLS) transition estimates ===\n",
      "  gamma (smoothness):  11.4330\n",
      "  c (threshold, standardized): -1.1080\n",
      "  c (threshold, ORIGINAL openness units): -0.1105\n",
      "\n",
      "=== PSTR Fixed-Effects (linear part) ===\n",
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                      y   R-squared:                        0.0393\n",
      "Estimator:                   PanelOLS   R-squared (Between):             -5.2395\n",
      "No. Observations:                 260   R-squared (Within):              -0.0053\n",
      "Date:                Sat, Nov 08 2025   R-squared (Overall):             -0.2835\n",
      "Time:                        13:22:22   Log-likelihood                   -1088.4\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      1.4926\n",
      "Entities:                          26   P-value                           0.1818\n",
      "Avg Obs:                      10.0000   Distribution:                   F(6,219)\n",
      "Min Obs:                      10.0000                                           \n",
      "Max Obs:                      10.0000   F-statistic (robust):             2.5440\n",
      "                                        P-value                           0.0211\n",
      "Time periods:                      10   Distribution:                   F(6,219)\n",
      "Avg Obs:                       26.000                                           \n",
      "Min Obs:                       26.000                                           \n",
      "Max Obs:                       26.000                                           \n",
      "                                                                                \n",
      "                              Parameter Estimates                              \n",
      "===============================================================================\n",
      "             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------\n",
      "Exposure_t     -0.6832     28.077    -0.0243     0.9806     -56.020      54.653\n",
      "Exposure_t1     45.513     42.409     1.0732     0.2844     -38.068      129.10\n",
      "Exp_t_G         0.4478     28.111     0.0159     0.9873     -54.955      55.850\n",
      "Exp_t1_G       -47.516     42.760    -1.1112     0.2677     -131.79      36.759\n",
      "HICP            3.1176     2.4019     1.2979     0.1957     -1.6163      7.8515\n",
      "Unemp           0.9219     3.4831     0.2647     0.7915     -5.9428      7.7866\n",
      "===============================================================================\n",
      "\n",
      "F-test for Poolability: 3.6119\n",
      "P-value: 0.0000\n",
      "Distribution: F(34,219)\n",
      "\n",
      "Included effects: Entity, Time\n",
      "\n",
      "=== MARGINAL EFFECTS OF TARIFF EXPOSURE (PSTR) ===\n",
      "\n",
      "Low Openness (orig=1.6912, z=-0.538, G=0.999):\n",
      "  ∂y/∂Exposure_t      : -0.236031  (se =  0.603074)\n",
      "  ∂y/∂Exposure_(t-1)  : -1.932556  (se = 0.685858)\n",
      "  Cumulative (0–1 mo) : -2.168588  (se = 0.687236)\n",
      "\n",
      "Median Openness (orig=2.5673, z=-0.261, G=1.000):\n",
      "  ∂y/∂Exposure_t      : -0.235399  (se =  0.604278)\n",
      "  ∂y/∂Exposure_(t-1)  : -1.999688  (se = 0.713756)\n",
      "  Cumulative (0–1 mo) : -2.235087  (se = 0.689273)\n",
      "\n",
      "High Openness (orig=3.6993, z=0.097, G=1.000):\n",
      "  ∂y/∂Exposure_t      : -0.235371  (se =  0.604389)\n",
      "  ∂y/∂Exposure_(t-1)  : -2.002589  (se = 0.715052)\n",
      "  Cumulative (0–1 mo) : -2.237960  (se = 0.689453)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7) Extended Specification — PSTR Model with Smooth Transition by Trade Openness\n",
    "\n",
    "We now allow the effect of tariff exposure to vary **smoothly** with the level of trade openness given by the World Bank representing the global openess of a country.\n",
    "Instead of assuming a linear interaction, we introduce a **logistic transition function** that captures gradual changes in the impact of exposure as openness increases.\n",
    "\n",
    "The logistic transition function is defined as:\n",
    "\n",
    "$$\n",
    "G\\!\\left(\\text{Openness}_{i,t-1}^{WB};\\gamma,c\\right)\n",
    "= \\frac{1}{1 + \\exp\\!\\big[-\\gamma\\big(\\text{Openness}_{i,t-1}^{WB} - c\\big)\\big]}.\n",
    "$$\n",
    "\n",
    "The corresponding PSTR regression is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{i,t} &= \\mu_i + \\lambda_t\n",
    "+ \\alpha_0\\,\\text{Exposure}_{i,t}\n",
    "+ \\alpha_1\\,\\text{Exposure}_{i,t-1} \\\\\n",
    "&\\quad + \\big(\\beta_0\\,\\text{Exposure}_{i,t} + \\beta_1\\,\\text{Exposure}_{i,t-1}\\big)\n",
    "\\,G\\!\\left(\\text{Openness}_{i,t-1}^{WB};\\gamma,c\\right)\n",
    "+ \\Gamma' Z_{i,t}\n",
    "+ \\varepsilon_{i,t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $y_{i,t}$ — Outcome variable (e.g. Industrial Production YoY for country *i* in month *t*)\n",
    "- $\\text{Exposure}_{i,t}$ — Effective tariff exposure in month *t*\n",
    "- $\\text{Exposure}_{i,t-1}$ — One-month lag of exposure\n",
    "- $\\text{Openness}_{i,t-1}^{WB}$ — Lagged trade openness index (annual, mapped to months)\n",
    "- $G(\\text{Openness}_{i,t-1}^{WB};\\gamma,c)$ — Logistic transition function with:\n",
    "  - $c$: threshold (location) where $G=0.5$\n",
    "  - $\\gamma$: smoothness parameter controlling how sharp the transition is\n",
    "- $Z_{i,t}$ — Monthly domestic controls (HICP YoY, Δ unemployment)\n",
    "- $\\mu_i$ — Country fixed effects\n",
    "- $\\lambda_t$ — Month fixed effects\n",
    "- $\\varepsilon_{i,t}$ — Error term clustered by country\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation**\n",
    "\n",
    "- $\\alpha_0$, $\\alpha_1$ — Baseline exposure effects when openness is low ($G \\approx 0$)\n",
    "- $\\beta_0$, $\\beta_1$ — Incremental effects as openness increases ($G \\to 1$)\n",
    "- **Marginal effects of exposure:**\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t}}\n",
    "  = \\alpha_0 + \\beta_0\\,G(\\text{Openness}_{i,t-1}^{WB};\\gamma,c),\n",
    "  $$\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t-1}}\n",
    "  = \\alpha_1 + \\beta_1\\,G(\\text{Openness}_{i,t-1}^{WB};\\gamma,c).\n",
    "  $$\n",
    "- **Cumulative short-run effect (0–1 month):**\n",
    "  $$\n",
    "  (\\alpha_0 + \\alpha_1) + (\\beta_0 + \\beta_1)\\,G(\\text{Openness}_{i,t-1}^{WB};\\gamma,c).\n",
    "  $$\n",
    "- When $\\gamma$ is large, $G(\\cdot)$ approximates a sharp threshold model; when small, the transition is smooth.\n",
    "\n",
    "---\n",
    "\n",
    "### **Estimation Details**\n",
    "\n",
    "- **Estimator:** Nonlinear least squares with two-way (country and month) fixed effects\n",
    "- **Frequency:** Monthly (2024-10 → 2025-09)\n",
    "- **Standard Errors:** Clustered by country\n",
    "- **Sample:** EU countries only\n",
    "- **Controls:** Domestic macro variables (HICP YoY, unemployment)\n",
    "- **Pre-processing:** Standardize openness before estimation; report the threshold $c$ in original units after transformation\n",
    "\n",
    "---\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "This model identifies whether the **effect of U.S. tariff shocks on economic outcomes** depends on how open each country is to international trade.\n",
    "The logistic transition function captures a **nonlinear response** — for example, more open economies may only become significantly affected **after** crossing a critical openness threshold.\n"
   ],
   "id": "b3cf359c3bd16b51"
  },
  {
   "cell_type": "code",
   "id": "f9c7f859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:24:48.966677Z",
     "start_time": "2025-11-08T12:24:48.771501Z"
    }
   },
   "source": [
    "# Traditional Trade Openness\n",
    "BASE = Path.cwd() / \"data\"\n",
    "\n",
    "ipi        = pd.read_csv(BASE / \"dependent_variable\" / \"IndustrialProductionIndex_df.csv\")\n",
    "stocks     = pd.read_csv(BASE / \"dependent_variable\" / \"StockIndex_df.csv\")\n",
    "exposure   = pd.read_csv(BASE / \"independent_variable\" / \"CountryTariffExposure_df.csv\")\n",
    "controls   = pd.read_csv(BASE / \"control_variable\" / \"CountryControls_df.csv\")\n",
    "openness   = pd.read_csv(BASE / \"transition_variable\" / \"WBTradeOpennessAnnual_df.csv\")\n",
    "\n",
    "for df in (ipi, stocks, exposure, controls):\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\").dt.to_period(\"M\")\n",
    "\n",
    "openness = openness[[\"Country\", \"Time\", \"Global Trade Openness-Lag1\"]].copy()\n",
    "openness.rename(columns={\"Global Trade Openness-Lag1\": \"Openness_annual\"}, inplace=True)\n",
    "openness[\"Year\"] = pd.to_datetime(openness[\"Time\"].astype(str), errors=\"coerce\").dt.year\n",
    "openness = openness.drop(columns=[\"Time\"])\n",
    "\n",
    "monthly_open = []\n",
    "for year in [2024, 2025]:\n",
    "    months = pd.date_range(f\"{year}-01-01\", f\"{year}-12-31\", freq=\"MS\")\n",
    "    tmp = pd.DataFrame({\"Time_dt\": months})\n",
    "    tmp[\"Time\"] = tmp[\"Time_dt\"].dt.to_period(\"M\")\n",
    "    tmp = tmp.merge(openness[openness[\"Year\"] == year][[\"Country\", \"Openness_annual\"]], how=\"cross\")\n",
    "    monthly_open.append(tmp)\n",
    "\n",
    "openness_monthly = pd.concat(monthly_open, ignore_index=True)\n",
    "openness_monthly = openness_monthly[[\"Country\", \"Time\", \"Openness_annual\"]]\n",
    "openness_monthly = openness_monthly.rename(columns={\"Openness_annual\": \"Openness\"})\n",
    "\n",
    "#df_dep = stocks.rename(columns={\"Log Monthly Return\": \"y\"})\n",
    "df_dep = ipi.rename(columns={\"diff_IPI\": \"y\"})\n",
    "\n",
    "exp = exposure.rename(columns={\"Exposure\": \"Exposure_t\"}).sort_values([\"Country\", \"Time\"])\n",
    "exp[\"Exposure_t1\"] = exp.groupby(\"Country\")[\"Exposure_t\"].shift(1)\n",
    "\n",
    "exp = exp.merge(openness_monthly, on=[\"Country\", \"Time\"], how=\"left\")\n",
    "exp[\"Openness_t1\"] = exp.groupby(\"Country\")[\"Openness\"].shift(1)\n",
    "\n",
    "exp = exp.dropna(subset=[\"Exposure_t1\", \"Openness_t1\"])\n",
    "\n",
    "df = (\n",
    "    df_dep[[\"Country\", \"Time\", \"y\"]]\n",
    "    .merge(exp[[\"Country\", \"Time\", \"Exposure_t\", \"Exposure_t1\", \"Openness_t1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    "    .merge(controls[[\"Country\", \"Time\",\n",
    "                     \"HICP_lag1\",\n",
    "                     \"Unemployment_lag1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    ")\n",
    "\n",
    "df = df[(df[\"Time\"] >= pd.Period(\"2024-11\", \"M\")) &\n",
    "        (df[\"Time\"] <= pd.Period(\"2025-08\", \"M\"))].copy()\n",
    "\n",
    "df[\"Time_dt\"] = df[\"Time\"].dt.start_time\n",
    "df = df.set_index([\"Country\", \"Time_dt\"]).sort_index()\n",
    "df.drop(columns=[\"Time\"], inplace=True)\n",
    "\n",
    "open_mean = df[\"Openness_t1\"].mean()\n",
    "open_std  = df[\"Openness_t1\"].std(ddof=0)\n",
    "df[\"Open_std\"] = (df[\"Openness_t1\"] - open_mean) / open_std\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"HICP_lag1\": \"HICP\",\n",
    "    \"Unemployment_lag1\": \"Unemp\"\n",
    "})\n",
    "\n",
    "def twoway_within_transform(panel_df, cols):\n",
    "    \"\"\"\n",
    "    Double-demean columns (entity & time FE).\n",
    "    Returns a new DataFrame with *_wt (within-transformed) columns.\n",
    "    \"\"\"\n",
    "    out = panel_df.copy()\n",
    "    ent_means = out.groupby(level=0)[cols].transform(\"mean\")\n",
    "    time_means = out.groupby(level=1)[cols].transform(\"mean\")\n",
    "    overall_means = out[cols].mean()\n",
    "    wt = out[cols] - ent_means - time_means + overall_means\n",
    "    wt.columns = [c + \"_wt\" for c in cols]\n",
    "    return wt\n",
    "\n",
    "base_cols = [\"y\", \"Exposure_t\", \"Exposure_t1\", \"HICP\", \"Unemp\", \"Open_std\"]\n",
    "wt = twoway_within_transform(df, base_cols)\n",
    "for c in wt.columns:\n",
    "    df[c] = wt[c]\n",
    "\n",
    "def G_logistic(z, gamma, c):\n",
    "    return 1.0 / (1.0 + np.exp(-gamma * (z - c)))\n",
    "\n",
    "def build_X_within(gamma, c, work_df):\n",
    "    \"\"\"\n",
    "    Build within-transformed X for given (γ,c):\n",
    "      [ Exp_t_wt, Exp_t1_wt, (Exp_t*G)_wt, (Exp_t1*G)_wt, HICP_wt, Unemp_wt ]\n",
    "    \"\"\"\n",
    "    z = work_df[\"Open_std_wt\"].to_numpy()\n",
    "    G = G_logistic(z, gamma, c)\n",
    "    X = np.column_stack([\n",
    "        work_df[\"Exposure_t_wt\"].to_numpy(),\n",
    "        work_df[\"Exposure_t1_wt\"].to_numpy(),\n",
    "        work_df[\"Exposure_t_wt\"].to_numpy()  * G,\n",
    "        work_df[\"Exposure_t1_wt\"].to_numpy() * G,\n",
    "        work_df[\"HICP_wt\"].to_numpy(),\n",
    "        work_df[\"Unemp_wt\"].to_numpy(),\n",
    "    ])\n",
    "    return X\n",
    "\n",
    "y_wt = df[\"y_wt\"].to_numpy()\n",
    "\n",
    "def ssr_objective(theta):\n",
    "    gamma, c = theta\n",
    "    if gamma <= 0:\n",
    "        return 1e12 + (abs(gamma) + 1.0) * 1e12\n",
    "    X = build_X_within(gamma, c, df)\n",
    "    beta_hat, *_ = np.linalg.lstsq(X, y_wt, rcond=None)\n",
    "    resid = y_wt - X @ beta_hat\n",
    "    return float(resid @ resid)\n",
    "\n",
    "theta0 = np.array([1.0, 0.0])\n",
    "bounds = [(1e-3, 100.0), (-3.0, 3.0)]\n",
    "\n",
    "opt = minimize(ssr_objective, theta0, method=\"L-BFGS-B\", bounds=bounds)\n",
    "gamma_hat, c_hat_std = opt.x\n",
    "print(\"\\n=== PSTR (NLS) transition estimates ===\")\n",
    "print(f\"  gamma (smoothness): {gamma_hat: .4f}\")\n",
    "print(f\"  c (threshold, standardized): {c_hat_std: .4f}\")\n",
    "c_hat_orig = open_mean + open_std * c_hat_std\n",
    "print(f\"  c (threshold, ORIGINAL openness units): {c_hat_orig: .4f}\")\n",
    "\n",
    "G_hat = G_logistic(df[\"Open_std\"].to_numpy(), gamma_hat, c_hat_std)\n",
    "df[\"G_hat\"] = G_hat\n",
    "\n",
    "df[\"Exp_t_G\"]   = df[\"Exposure_t\"]  * df[\"G_hat\"]\n",
    "df[\"Exp_t1_G\"]  = df[\"Exposure_t1\"] * df[\"G_hat\"]\n",
    "\n",
    "exog_cols = [\"Exposure_t\", \"Exposure_t1\", \"Exp_t_G\", \"Exp_t1_G\", \"HICP\", \"Unemp\"]\n",
    "\n",
    "mod = PanelOLS(\n",
    "    dependent=df[\"y\"],\n",
    "    exog=df[exog_cols],\n",
    "    entity_effects=True,\n",
    "    time_effects=True,\n",
    ")\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(\"\\n=== PSTR Fixed-Effects (linear part) ===\")\n",
    "print(res)\n",
    "\n",
    "print(\"\\n=== MARGINAL EFFECTS OF TARIFF EXPOSURE (PSTR) ===\")\n",
    "open_levels = {\n",
    "    \"Low\":    df[\"Openness_t1\"].quantile(0.25),\n",
    "    \"Median\": df[\"Openness_t1\"].quantile(0.50),\n",
    "    \"High\":   df[\"Openness_t1\"].quantile(0.75),\n",
    "}\n",
    "\n",
    "alpha0 = res.params[\"Exposure_t\"]\n",
    "alpha1 = res.params[\"Exposure_t1\"]\n",
    "beta0  = res.params[\"Exp_t_G\"]\n",
    "beta1  = res.params[\"Exp_t1_G\"]\n",
    "V = res.cov\n",
    "\n",
    "for label, q_orig in open_levels.items():\n",
    "    z = (q_orig - open_mean) / open_std\n",
    "    Gq = G_logistic(z, gamma_hat, c_hat_std)\n",
    "\n",
    "    me_t = alpha0 + beta0 * Gq\n",
    "    var_t = (\n",
    "        V.loc[\"Exposure_t\", \"Exposure_t\"]\n",
    "        + 2*Gq*V.loc[\"Exposure_t\", \"Exp_t_G\"]\n",
    "        + (Gq**2)*V.loc[\"Exp_t_G\", \"Exp_t_G\"]\n",
    "    )\n",
    "    se_t = float(np.sqrt(var_t))\n",
    "\n",
    "    me_t1 = alpha1 + beta1 * Gq\n",
    "    var_t1 = (\n",
    "        V.loc[\"Exposure_t1\", \"Exposure_t1\"]\n",
    "        + 2*Gq*V.loc[\"Exposure_t1\", \"Exp_t1_G\"]\n",
    "        + (Gq**2)*V.loc[\"Exp_t1_G\", \"Exp_t1_G\"]\n",
    "    )\n",
    "    se_t1 = float(np.sqrt(var_t1))\n",
    "\n",
    "    cov_cross = (\n",
    "        V.loc[\"Exposure_t\", \"Exposure_t1\"]\n",
    "        + Gq*(V.loc[\"Exposure_t\", \"Exp_t1_G\"] + V.loc[\"Exp_t_G\", \"Exposure_t1\"])\n",
    "        + (Gq**2)*V.loc[\"Exp_t_G\", \"Exp_t1_G\"]\n",
    "    )\n",
    "    var_cum = var_t + var_t1 + 2*cov_cross\n",
    "    se_cum = float(np.sqrt(var_cum))\n",
    "    me_cum = me_t + me_t1\n",
    "\n",
    "    print(f\"\\n{label} Openness (orig={q_orig:.4f}, z={z:.3f}, G={Gq:.3f}):\")\n",
    "    print(f\"  ∂y/∂Exposure_t      : {me_t: .6f}  (se = {se_t: .6f})\")\n",
    "    print(f\"  ∂y/∂Exposure_(t-1)  : {me_t1:.6f}  (se = {se_t1:.6f})\")\n",
    "    print(f\"  Cumulative (0–1 mo) : {me_cum:.6f}  (se = {se_cum:.6f})\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PSTR (NLS) transition estimates ===\n",
      "  gamma (smoothness):  31.3052\n",
      "  c (threshold, standardized): -0.5959\n",
      "  c (threshold, ORIGINAL openness units):  98.2635\n",
      "\n",
      "=== PSTR Fixed-Effects (linear part) ===\n",
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                      y   R-squared:                        0.0407\n",
      "Estimator:                   PanelOLS   R-squared (Between):             -5.8818\n",
      "No. Observations:                 260   R-squared (Within):               0.0060\n",
      "Date:                Sat, Nov 08 2025   R-squared (Overall):             -0.3069\n",
      "Time:                        13:24:48   Log-likelihood                   -1088.2\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      1.5473\n",
      "Entities:                          26   P-value                           0.1640\n",
      "Avg Obs:                      10.0000   Distribution:                   F(6,219)\n",
      "Min Obs:                      10.0000                                           \n",
      "Max Obs:                      10.0000   F-statistic (robust):             2.1631\n",
      "                                        P-value                           0.0477\n",
      "Time periods:                      10   Distribution:                   F(6,219)\n",
      "Avg Obs:                       26.000                                           \n",
      "Min Obs:                       26.000                                           \n",
      "Max Obs:                       26.000                                           \n",
      "                                                                                \n",
      "                              Parameter Estimates                              \n",
      "===============================================================================\n",
      "             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------\n",
      "Exposure_t      0.3889     1.1459     0.3394     0.7347     -1.8696      2.6474\n",
      "Exposure_t1    -0.3198     1.3789    -0.2319     0.8168     -3.0375      2.3978\n",
      "Exp_t_G        -0.6837     1.0357    -0.6602     0.5098     -2.7249      1.3575\n",
      "Exp_t1_G       -1.7166     1.3945    -1.2310     0.2196     -4.4649      1.0317\n",
      "HICP            3.2445     2.2987     1.4114     0.1595     -1.2859      7.7749\n",
      "Unemp           0.9855     3.5378     0.2786     0.7808     -5.9869      7.9580\n",
      "===============================================================================\n",
      "\n",
      "F-test for Poolability: 3.5405\n",
      "P-value: 0.0000\n",
      "Distribution: F(34,219)\n",
      "\n",
      "Included effects: Entity, Time\n",
      "\n",
      "=== MARGINAL EFFECTS OF TARIFF EXPOSURE (PSTR) ===\n",
      "\n",
      "Low Openness (orig=91.1410, z=-0.698, G=0.039):\n",
      "  ∂y/∂Exposure_t      :  0.361911  (se =  1.110161)\n",
      "  ∂y/∂Exposure_(t-1)  : -0.387601  (se = 1.332489)\n",
      "  Cumulative (0–1 mo) : -0.025690  (se = 1.622437)\n",
      "\n",
      "Median Openness (orig=130.2234, z=-0.138, G=1.000):\n",
      "  ∂y/∂Exposure_t      : -0.294817  (se =  0.546933)\n",
      "  ∂y/∂Exposure_(t-1)  : -2.036429  (se = 0.762223)\n",
      "  Cumulative (0–1 mo) : -2.331246  (se = 0.738897)\n",
      "\n",
      "High Openness (orig=158.4529, z=0.266, G=1.000):\n",
      "  ∂y/∂Exposure_t      : -0.294818  (se =  0.546933)\n",
      "  ∂y/∂Exposure_(t-1)  : -2.036430  (se = 0.762223)\n",
      "  Cumulative (0–1 mo) : -2.331248  (se = 0.738897)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8) Extended Specification — PSTR Model with Smooth Transition by the proportion of Export with EU in the EU total intra market Export\n",
    "\n",
    "We now allow the effect of tariff exposure to vary **smoothly** with the level of trade openness toward EU partner as a mesure of the resilience and the integration in the EU market.\n",
    "Instead of assuming a linear interaction, we introduce a **logistic transition function** that captures gradual changes in the impact of exposure as openness increases.\n",
    "\n",
    "The logistic transition function is defined as:\n",
    "\n",
    "$$\n",
    "G\\!\\left(\\text{Resilience}_{i,t-1}^{EU};\\gamma,c\\right)\n",
    "= \\frac{1}{1 + \\exp\\!\\big[-\\gamma\\big(\\text{Resilience}_{i,t-1}^{EU} - c\\big)\\big]}.\n",
    "$$\n",
    "\n",
    "The corresponding PSTR regression is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{i,t} &= \\mu_i + \\lambda_t\n",
    "+ \\alpha_0\\,\\text{Exposure}_{i,t}\n",
    "+ \\alpha_1\\,\\text{Exposure}_{i,t-1} \\\\\n",
    "&\\quad + \\big(\\beta_0\\,\\text{Exposure}_{i,t} + \\beta_1\\,\\text{Exposure}_{i,t-1}\\big)\n",
    "\\,G\\!\\left(\\text{Resilience}_{i,t-1}^{EU};\\gamma,c\\right)\n",
    "+ \\Gamma' Z_{i,t}\n",
    "+ \\varepsilon_{i,t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $y_{i,t}$ — Outcome variable (e.g. Industrial Production YoY for country *i* in month *t*)\n",
    "- $\\text{Exposure}_{i,t}$ — Effective tariff exposure in month *t*\n",
    "- $\\text{Exposure}_{i,t-1}$ — One-month lag of exposure\n",
    "- $\\text{Resilience}_{i,t-1}^{EU}$ — Lagged trade openness index (annual, mapped to months)\n",
    "- $G(\\text{Resilience}_{i,t-1}^{EU};\\gamma,c)$ — Logistic transition function with:\n",
    "  - $c$: threshold (location) where $G=0.5$\n",
    "  - $\\gamma$: smoothness parameter controlling how sharp the transition is\n",
    "- $Z_{i,t}$ — Monthly domestic controls (HICP YoY, Δ unemployment)\n",
    "- $\\mu_i$ — Country fixed effects\n",
    "- $\\lambda_t$ — Month fixed effects\n",
    "- $\\varepsilon_{i,t}$ — Error term clustered by country\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation**\n",
    "\n",
    "- $\\alpha_0$, $\\alpha_1$ — Baseline exposure effects when openness is low ($G \\approx 0$)\n",
    "- $\\beta_0$, $\\beta_1$ — Incremental effects as openness increases ($G \\to 1$)\n",
    "- **Marginal effects of exposure:**\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t}}\n",
    "  = \\alpha_0 + \\beta_0\\,G(\\text{Resilience}_{i,t-1}^{EU};\\gamma,c),\n",
    "  $$\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t-1}}\n",
    "  = \\alpha_1 + \\beta_1\\,G(\\text{Resilience}_{i,t-1}^{EU};\\gamma,c).\n",
    "  $$\n",
    "- **Cumulative short-run effect (0–1 month):**\n",
    "  $$\n",
    "  (\\alpha_0 + \\alpha_1) + (\\beta_0 + \\beta_1)\\,G(\\text{Resilience}_{i,t-1}^{EU};\\gamma,c).\n",
    "  $$\n",
    "- When $\\gamma$ is large, $G(\\cdot)$ approximates a sharp threshold model; when small, the transition is smooth.\n",
    "\n",
    "---\n",
    "\n",
    "### **Estimation Details**\n",
    "\n",
    "- **Estimator:** Nonlinear least squares with two-way (country and month) fixed effects\n",
    "- **Frequency:** Monthly (2024-10 → 2025-09)\n",
    "- **Standard Errors:** Clustered by country\n",
    "- **Sample:** EU countries only\n",
    "- **Controls:** Domestic macro variables (HICP YoY, unemployment)\n",
    "- **Pre-processing:** Standardize openness before estimation; report the threshold $c$ in original units after transformation\n",
    "\n",
    "---\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "This model identifies whether the **effect of U.S. tariff shocks on economic outcomes** depends on how resilient / integrated each country is to international trade with Eu partner.\n",
    "The logistic transition function captures a **nonlinear response** — for example, more resilient / integrated economies may only become significantly affected **after** crossing a critical openness threshold.\n"
   ],
   "id": "dfd763bf30e19f0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:24:57.689871Z",
     "start_time": "2025-11-08T12:24:57.544921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================\n",
    "# PSTR REGRESSION — FULLY WORKING\n",
    "# ================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.optimize import minimize\n",
    "from linearmodels.panel import PanelOLS\n",
    "\n",
    "# -------------------------------\n",
    "# 1. LOAD & CONVERT TIME\n",
    "# -------------------------------\n",
    "BASE = Path.cwd() / \"data\"\n",
    "ipi = pd.read_csv(BASE / \"dependent_variable\" / \"IndustrialProductionIndex_df.csv\")\n",
    "stocks = pd.read_csv(BASE / \"dependent_variable\" / \"StockIndex_df.csv\")\n",
    "exposure = pd.read_csv(BASE / \"independent_variable\" / \"CountryTariffExposure_df.csv\")\n",
    "controls = pd.read_csv(BASE / \"control_variable\" / \"CountryControls_df.csv\")\n",
    "resilience = pd.read_csv(BASE / \"transition_variable\" / \"EU_partner_index_df.csv\")\n",
    "\n",
    "# Convert ALL Time columns to Period[M]\n",
    "for df in (ipi, stocks, exposure, controls, resilience):\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\").dt.to_period(\"M\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. PREPARE DEPENDENT VARIABLE\n",
    "# -------------------------------\n",
    "#df_dep = stocks.rename(columns={\"Log Monthly Return\": \"y\"})[[\"Country\", \"Time\", \"y\"]]\n",
    "df_dep = ipi.rename(columns={\"diff_IPI\": \"y\"})\n",
    "\n",
    "# -------------------------------\n",
    "# 3. PREPARE EXPOSURE + LAG\n",
    "# -------------------------------\n",
    "exp = exposure.rename(columns={\"Exposure\": \"Exposure_t\"})\n",
    "exp = exp.sort_values([\"Country\", \"Time\"]).reset_index(drop=True)\n",
    "exp[\"Exposure_t1\"] = exp.groupby(\"Country\")[\"Exposure_t\"].shift(1)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. MONTHLY RESILIENCE (no spreading!)\n",
    "# -------------------------------\n",
    "resilience_monthly = (\n",
    "    resilience[[\"Country\", \"Time\", \"OBS_VALUE_Lagged1\"]]\n",
    "    .rename(columns={\"OBS_VALUE_Lagged1\": \"resilience\"})\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# Merge current resilience\n",
    "exp = exp.merge(resilience_monthly, on=[\"Country\", \"Time\"], how=\"left\")\n",
    "\n",
    "# Lag resilience\n",
    "exp[\"resilience_t1\"] = exp.groupby(\"Country\")[\"resilience\"].shift(1)\n",
    "\n",
    "# Drop rows where lags are missing\n",
    "exp = exp.dropna(subset=[\"Exposure_t1\", \"resilience_t1\"]).reset_index(drop=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. BUILD FINAL PANEL\n",
    "# -------------------------------\n",
    "df = (\n",
    "    df_dep\n",
    "    .merge(exp[[\"Country\", \"Time\", \"Exposure_t\", \"Exposure_t1\", \"resilience_t1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    "    .merge(controls[[\"Country\", \"Time\",\n",
    "                     \"HICP_lag1\",\n",
    "                     \"Unemployment_lag1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    ")\n",
    "\n",
    "# Time window\n",
    "df = df[(df[\"Time\"] >= \"2024-11\") & (df[\"Time\"] <= \"2025-08\")].copy()\n",
    "\n",
    "# Standardize resilience for PSTR\n",
    "open_mean = df[\"resilience_t1\"].mean()\n",
    "open_std = df[\"resilience_t1\"].std(ddof=0)\n",
    "df[\"Open_std\"] = (df[\"resilience_t1\"] - open_mean) / open_std\n",
    "\n",
    "# Rename controls\n",
    "df = df.rename(columns={\n",
    "    \"HICP_lag1\": \"HICP\",\n",
    "    \"Unemployment_lag1\": \"Unemp\"\n",
    "})\n",
    "\n",
    "# Set index for PanelOLS\n",
    "df[\"Time_dt\"] = df[\"Time\"].dt.start_time\n",
    "df = df.set_index([\"Country\", \"Time_dt\"]).sort_index()\n",
    "\n",
    "# -------------------------------\n",
    "# 6. TWO-WAY WITHIN TRANSFORM\n",
    "# -------------------------------\n",
    "def twoway_within(df, cols):\n",
    "    ent = df.groupby(level=0)[cols].transform(\"mean\")\n",
    "    tim = df.groupby(level=1)[cols].transform(\"mean\")\n",
    "    overall = df[cols].mean()\n",
    "    return df[cols] - ent - tim + overall\n",
    "\n",
    "base_cols = [\"y\", \"Exposure_t\", \"Exposure_t1\", \"HICP\", \"Unemp\", \"Open_std\"]\n",
    "wt = twoway_within(df, base_cols)\n",
    "wt.columns = [c + \"_wt\" for c in wt.columns]   # <-- fixed typo: \"*wt\" → \"_wt\"\n",
    "df = pd.concat([df, wt], axis=1)\n",
    "\n",
    "# -------------------------------\n",
    "# 7. PSTR: ESTIMATE γ and c\n",
    "# -------------------------------\n",
    "def G_logistic(z, gamma, c):\n",
    "    return 1.0 / (1.0 + np.exp(-gamma * (z - c)))\n",
    "\n",
    "def build_X(gamma, c, work):\n",
    "    z = work[\"Open_std_wt\"].to_numpy()\n",
    "    G = G_logistic(z, gamma, c)\n",
    "    X = np.column_stack([\n",
    "        work[\"Exposure_t_wt\"],\n",
    "        work[\"Exposure_t1_wt\"],\n",
    "        work[\"Exposure_t_wt\"] * G,\n",
    "        work[\"Exposure_t1_wt\"] * G,\n",
    "        work[\"HICP_wt\"],\n",
    "        work[\"Unemp_wt\"]\n",
    "    ])\n",
    "    return X\n",
    "\n",
    "y_wt = df[\"y_wt\"].to_numpy()\n",
    "\n",
    "def ssr(theta):\n",
    "    gamma, c = theta\n",
    "    if gamma <= 0:\n",
    "        return 1e12\n",
    "    X = build_X(gamma, c, df)\n",
    "    beta, *_ = np.linalg.lstsq(X, y_wt, rcond=None)   # <-- fixed: ** → *_\n",
    "    return float((y_wt - X @ beta) @ (y_wt - X @ beta))\n",
    "\n",
    "opt = minimize(ssr, x0=[1.0, 0.0], bounds=[(0.1, 100), (-3, 3)], method=\"L-BFGS-B\")\n",
    "gamma_hat, c_hat_std = opt.x\n",
    "c_hat = open_mean + open_std * c_hat_std\n",
    "\n",
    "print(\"\\nPSTR TRANSITION ESTIMATES\")\n",
    "print(f\"γ (smoothness) = {gamma_hat: .3f}\")\n",
    "print(f\"c (threshold, original units) = {c_hat: .4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8. FINAL LINEAR MODEL WITH G(z)\n",
    "# -------------------------------\n",
    "z = df[\"Open_std\"].to_numpy()\n",
    "G = G_logistic(z, gamma_hat, c_hat_std)\n",
    "df[\"G\"] = G\n",
    "df[\"Exp_t_G\"] = df[\"Exposure_t\"] * G\n",
    "df[\"Exp_t1_G\"] = df[\"Exposure_t1\"] * G\n",
    "\n",
    "exog = df[[\"Exposure_t\", \"Exposure_t1\", \"Exp_t_G\", \"Exp_t1_G\", \"HICP\", \"Unemp\"]]\n",
    "mod = PanelOLS(dependent=df[\"y\"], exog=exog, entity_effects=True, time_effects=True)\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(\"\\nPSTR LINEAR PART\")\n",
    "print(res)\n",
    "\n",
    "# -------------------------------\n",
    "# 9. MARGINAL EFFECTS\n",
    "# -------------------------------\n",
    "alpha0 = res.params[\"Exposure_t\"]\n",
    "alpha1 = res.params[\"Exposure_t1\"]\n",
    "beta0  = res.params[\"Exp_t_G\"]\n",
    "beta1  = res.params[\"Exp_t1_G\"]\n",
    "V      = res.cov\n",
    "\n",
    "levels = {\n",
    "    \"Low\":     df[\"resilience_t1\"].quantile(0.25),\n",
    "    \"Median\":  df[\"resilience_t1\"].quantile(0.50),\n",
    "    \"High\":    df[\"resilience_t1\"].quantile(0.75)\n",
    "}\n",
    "\n",
    "print(\"\\nMARGINAL EFFECTS\")\n",
    "for name, val in levels.items():\n",
    "    zq = (val - open_mean) / open_std\n",
    "    Gq = G_logistic(zq, gamma_hat, c_hat_std)\n",
    "    me_t   = alpha0 + beta0 * Gq\n",
    "    me_t1  = alpha1 + beta1 * Gq\n",
    "    me_cum = me_t  + me_t1\n",
    "\n",
    "    var_t = (V.loc[\"Exposure_t\",\"Exposure_t\"] +\n",
    "             2*Gq*V.loc[\"Exposure_t\",\"Exp_t_G\"] +\n",
    "             Gq**2*V.loc[\"Exp_t_G\",\"Exp_t_G\"])\n",
    "\n",
    "    var_t1 = (V.loc[\"Exposure_t1\",\"Exposure_t1\"] +\n",
    "              2*Gq*V.loc[\"Exposure_t1\",\"Exp_t1_G\"] +\n",
    "              Gq**2*V.loc[\"Exp_t1_G\",\"Exp_t1_G\"])\n",
    "\n",
    "    cov_cross = (V.loc[\"Exposure_t\",\"Exposure_t1\"] +\n",
    "                 Gq*(V.loc[\"Exposure_t\",\"Exp_t1_G\"] + V.loc[\"Exp_t_G\",\"Exposure_t1\"]) +\n",
    "                 Gq**2*V.loc[\"Exp_t_G\",\"Exp_t1_G\"])\n",
    "\n",
    "    var_cum = var_t + var_t1 + 2*cov_cross\n",
    "\n",
    "    print(f\"\\n{name} resilience ({val:.3f}) → G(z) = {Gq:.3f}\")\n",
    "    print(f\" ∂y/∂Exp_t = {me_t: .5f} (se = {np.sqrt(var_t):.5f})\")\n",
    "    print(f\" ∂y/∂Exp_(t-1) = {me_t1:.5f} (se = {np.sqrt(var_t1):.5f})\")\n",
    "    print(f\" Cumulative = {me_cum:.5f} (se = {np.sqrt(var_cum):.5f})\")"
   ],
   "id": "dfe1c01391fbe9ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PSTR TRANSITION ESTIMATES\n",
      "γ (smoothness) =  2.653\n",
      "c (threshold, original units) =  0.1822\n",
      "\n",
      "PSTR LINEAR PART\n",
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                      y   R-squared:                        0.0473\n",
      "Estimator:                   PanelOLS   R-squared (Between):             -5.5509\n",
      "No. Observations:                 208   R-squared (Within):              -0.0052\n",
      "Date:                Sat, Nov 08 2025   R-squared (Overall):             -0.1528\n",
      "Time:                        13:24:57   Log-likelihood                   -870.50\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      1.3993\n",
      "Entities:                          26   P-value                           0.2176\n",
      "Avg Obs:                       8.0000   Distribution:                   F(6,169)\n",
      "Min Obs:                       8.0000                                           \n",
      "Max Obs:                       8.0000   F-statistic (robust):             3.0367\n",
      "                                        P-value                           0.0076\n",
      "Time periods:                       8   Distribution:                   F(6,169)\n",
      "Avg Obs:                       26.000                                           \n",
      "Min Obs:                       26.000                                           \n",
      "Max Obs:                       26.000                                           \n",
      "                                                                                \n",
      "                              Parameter Estimates                              \n",
      "===============================================================================\n",
      "             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------\n",
      "Exposure_t     -0.4034     0.6681    -0.6038     0.5468     -1.7223      0.9155\n",
      "Exposure_t1    -2.1476     0.7049    -3.0465     0.0027     -3.5392     -0.7560\n",
      "Exp_t_G        -0.5493     0.8366    -0.6566     0.5123     -2.2008      1.1022\n",
      "Exp_t1_G        1.7346     0.9096     1.9070     0.0582     -0.0611      3.5303\n",
      "HICP            2.9779     3.1255     0.9528     0.3421     -3.1922      9.1481\n",
      "Unemp          -1.9451     3.3301    -0.5841     0.5599     -8.5191      4.6289\n",
      "===============================================================================\n",
      "\n",
      "F-test for Poolability: 3.0580\n",
      "P-value: 0.0000\n",
      "Distribution: F(32,169)\n",
      "\n",
      "Included effects: Entity, Time\n",
      "\n",
      "MARGINAL EFFECTS\n",
      "\n",
      "Low resilience (0.006) → G(z) = 0.000\n",
      " ∂y/∂Exp_t = -0.40343 (se = 0.66809)\n",
      " ∂y/∂Exp_(t-1) = -2.14745 (se = 0.70491)\n",
      " Cumulative = -2.55088 (se = 0.79537)\n",
      "\n",
      "Median resilience (0.018) → G(z) = 0.000\n",
      " ∂y/∂Exp_t = -0.40346 (se = 0.66809)\n",
      " ∂y/∂Exp_(t-1) = -2.14734 (se = 0.70488)\n",
      " Cumulative = -2.55081 (se = 0.79538)\n",
      "\n",
      "High resilience (0.060) → G(z) = 0.001\n",
      " ∂y/∂Exp_t = -0.40408 (se = 0.66795)\n",
      " ∂y/∂Exp_(t-1) = -2.14540 (se = 0.70441)\n",
      " Cumulative = -2.54948 (se = 0.79546)\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
