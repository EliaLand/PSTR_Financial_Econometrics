{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61504a36e2851576",
   "metadata": {},
   "source": [
    "### **1) REQUIREMENTS SETUP**### **1) REQUIREMENTS SETUP**# **Regression data preparation and modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44496c0061df41f5",
   "metadata": {},
   "source": [
    "### **1) REQUIREMENTS SETUP**"
   ]
  },
  {
   "cell_type": "code",
   "id": "43fef67b9d502783",
   "metadata": {},
   "source": [
    "# !pip install -r requirements.txt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9cf220addcc024f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T13:11:30.191976Z",
     "start_time": "2025-11-08T13:11:27.779870Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from linearmodels.panel import PanelOLS\n",
    "from scipy.optimize import minimize"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "339d8fa8bee2b4f7",
   "metadata": {},
   "source": [
    "### **2) MODULES IMPORT**"
   ]
  },
  {
   "cell_type": "code",
   "id": "ebc963da9885ca8",
   "metadata": {},
   "source": [
    "# None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "469c6becfd846866",
   "metadata": {},
   "source": [
    "### **3) DATA Prep**"
   ]
  },
  {
   "cell_type": "code",
   "id": "3fee59366384e1e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T13:11:30.450577Z",
     "start_time": "2025-11-08T13:11:30.203946Z"
    }
   },
   "source": [
    "# Normalization of all the data used in the regression over comparable timeframe / format\n",
    "data_fetcher_path = Path.cwd().parent / \"data_fetcher\"\n",
    "dep_IPI = pd.read_csv(data_fetcher_path/\"aggregate_df/EURO_indprod_dependent_df.csv\")\n",
    "dep_Stocks = pd.read_csv(data_fetcher_path/\"aggregate_df/EURO_stock_dependent_df.csv\")\n",
    "\n",
    "#Other (!!! I change the path to trade openness 1 from EURO_trade... to trade_openness_ ...)\n",
    "exposure_df = pd.read_csv(data_fetcher_path / \"country_tariff_exposure.csv\")\n",
    "openness_df = pd.read_csv(data_fetcher_path/\"aggregate_df/trade_openness_annual_regime_df.csv\")\n",
    "controls_df = pd.read_csv(data_fetcher_path/\"aggregate_df/country_specific_test_df.csv\")\n",
    "wb_openness_df = pd.read_csv(data_fetcher_path/\"aggregate_df/wb_trade_openness_annual_regime_df.csv\")\n",
    "transition_df = pd.read_csv(data_fetcher_path/\"aggregate_df/Export_Intra_EU2.csv\")\n",
    "\n",
    "\n",
    "# === OFFICIAL EU COUNTRIES ONLY ===\n",
    "eu_country_map = {\n",
    "    \"Austria\": \"AT\", \"Belgium\": \"BE\", \"Bulgaria\": \"BG\", \"Croatia\": \"HR\",\n",
    "    \"Cyprus\": \"CY\", \"Czechia (Czech Republic)\": \"CZ\", \"Czechia\": \"CZ\",\n",
    "    \"Denmark\": \"DK\", \"Estonia\": \"EE\", \"Finland\": \"FI\", \"France\": \"FR\",\n",
    "    \"Germany\": \"DE\", \"Greece\": \"GR\", \"Hungary\": \"HU\", \"Ireland\": \"IE\",\n",
    "    \"Italy\": \"IT\", \"Latvia\": \"LV\", \"Lithuania\": \"LT\", \"Luxembourg\": \"LU\",\n",
    "    \"Malta\": \"MT\", \"Netherlands\": \"NL\", \"Poland\": \"PL\", \"Portugal\": \"PT\",\n",
    "    \"Romania\": \"RO\", \"Slovakia\": \"SK\", \"Slovenia\": \"SI\", \"Spain\": \"ES\",\n",
    "    \"Sweden\": \"SE\"\n",
    "}\n",
    "EU_ISO_CODES = set(eu_country_map.values())\n",
    "\n",
    "def keep_only_eu(df, country_col='Country'):\n",
    "    if country_col not in df.columns:\n",
    "        return df\n",
    "    before = len(df)\n",
    "    df = df[df[country_col].isin(EU_ISO_CODES)].copy()\n",
    "    after = len(df)\n",
    "    dropped = before - after\n",
    "    if dropped:\n",
    "        print(f\"Dropped {dropped:,} non-EU rows → {after:,} EU rows kept\")\n",
    "    return df\n",
    "\n",
    "# APPLY: Keep only EU countries\n",
    "dep_IPI = keep_only_eu(dep_IPI)\n",
    "dep_Stocks = keep_only_eu(dep_Stocks)\n",
    "exposure_df = keep_only_eu(exposure_df)\n",
    "openness_df = keep_only_eu(openness_df)\n",
    "controls_df = keep_only_eu(controls_df)\n",
    "transition_df = keep_only_eu(transition_df)\n",
    "wb_openness_df = keep_only_eu(wb_openness_df)\n",
    "\n",
    "\n",
    "print(f\"\\nKept only 27 EU countries: {sorted(EU_ISO_CODES)}\\n\")\n",
    "\n",
    "\n",
    "start_date = '2024-11'\n",
    "end_date = '2025-08'\n",
    "\n",
    "# ================================\n",
    "# IPI: Full Lagged First Difference (MAXIMUM COVERAGE)\n",
    "# ================================\n",
    "\n",
    "# 1. Start with FULL data (no date filter yet)\n",
    "cols = ['Country', 'Level 1 Index', 'Time', 'Indprod Index Value (I21)']\n",
    "dep_IPI_full = dep_IPI[cols].copy()\n",
    "\n",
    "# 2. Ensure numeric\n",
    "dep_IPI_full['Indprod Index Value (I21)'] = pd.to_numeric(\n",
    "    dep_IPI_full['Indprod Index Value (I21)'], errors='coerce'\n",
    ")\n",
    "\n",
    "# 3. Collapse B/C → \"B+C\", drop D\n",
    "dep_IPI_full['Level 1 Index'] = (\n",
    "    dep_IPI_full['Level 1 Index']\n",
    "    .astype(str).str.strip()\n",
    "    .replace({'B': 'B+C', 'C': 'B+C', 'D': np.nan})\n",
    ")\n",
    "dep_IPI_full = dep_IPI_full.dropna(subset=['Level 1 Index'])\n",
    "\n",
    "# 4. Aggregate (sum) over Country, Time, Level 1 Index\n",
    "dep_IPI_agg = (\n",
    "    dep_IPI_full\n",
    "    .groupby(['Country', 'Time', 'Level 1 Index'], as_index=False)\n",
    "    ['Indprod Index Value (I21)']\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# 5. Convert Time to Period and sort\n",
    "dep_IPI_agg['Time_period'] = pd.to_datetime(dep_IPI_agg['Time']).dt.to_period('M')\n",
    "dep_IPI_agg = dep_IPI_agg.sort_values(['Country', 'Level 1 Index', 'Time_period'])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. COMPUTE DIFF + LAG ON FULL DATA (KEY STEP!)\n",
    "# ------------------------------------------------------------------\n",
    "dep_IPI_agg['diff_IPI'] = (\n",
    "    dep_IPI_agg\n",
    "    .groupby(['Country', 'Level 1 Index'])['Indprod Index Value (I21)']\n",
    "    .diff()\n",
    ")\n",
    "\n",
    "dep_IPI_agg['lagged_diff_IPI'] = (\n",
    "    dep_IPI_agg\n",
    "    .groupby(['Country', 'Level 1 Index'])['diff_IPI']\n",
    "    .shift(1)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7. NOW FILTER TO YOUR ANALYSIS WINDOW\n",
    "# ------------------------------------------------------------------\n",
    "mask = (\n",
    "    (dep_IPI_agg['Time_period'] >= pd.Period(start_date, 'M')) &\n",
    "    (dep_IPI_agg['Time_period'] <= pd.Period(end_date, 'M'))\n",
    ")\n",
    "dep_IPI_final = dep_IPI_agg.loc[mask].copy()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 8. Final cleanup & save\n",
    "# ------------------------------------------------------------------\n",
    "final_cols = [\n",
    "    'Country', 'Level 1 Index', 'Time',\n",
    "    'Indprod Index Value (I21)',  # current level\n",
    "    'diff_IPI',                   # ΔIPI_t\n",
    "    'lagged_diff_IPI'             # ΔIPI_{t-1} ← FULLY POPULATED\n",
    "]\n",
    "dep_IPI_final = dep_IPI_final[final_cols]\n",
    "\n",
    "Path('data/dependent_variable').mkdir(parents=True, exist_ok=True)\n",
    "dep_IPI_final.to_csv(\n",
    "    'data/dependent_variable/IndustrialProductionIndex_df.csv',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Saved: IndustrialProductionIndex_df.csv\")\n",
    "print(f\"  → Analysis window: {start_date} to {end_date}\")\n",
    "print(f\"  → Valid lagged differences: {dep_IPI_final['lagged_diff_IPI'].notna().sum():,}\")\n",
    "print(f\"  → First month in window has lag: {dep_IPI_final.iloc[0]['lagged_diff_IPI'] is not pd.NA}\")\n",
    "\n",
    "# Stocks Dependent\n",
    "stock_period = pd.to_datetime(dep_Stocks['Time'], errors='coerce').dt.to_period('M')\n",
    "stock_mask = (stock_period >= pd.Period(start_date, 'M')) & (stock_period <= pd.Period(end_date, 'M'))\n",
    "stock_cols = ['Country', 'Stock Index', 'Time', 'Log Monthly Return', 'Volume']\n",
    "dep_Stocks_filtered = dep_Stocks.loc[stock_mask, stock_cols].copy()\n",
    "dep_Stocks_filtered = dep_Stocks_filtered.sort_values(['Country', 'Stock Index', 'Time']).reset_index(drop=True)\n",
    "dep_Stocks_filtered.to_csv('data/dependent_variable/StockIndex_df.csv', index=False)\n",
    "\n",
    "# Tariff(i,t) Independent\n",
    "\n",
    "# 1. Round publication dates to month (same as before)\n",
    "dt = pd.to_datetime(exposure_df['Publication_Date'], errors='coerce')\n",
    "month_start = dt.dt.to_period('M').dt.start_time\n",
    "next_month_start = (dt.dt.to_period('M') + 1).dt.start_time\n",
    "delta_to_start = (dt - month_start).dt.days\n",
    "delta_to_next = (next_month_start - dt).dt.days\n",
    "rounded_month_start = pd.to_datetime(\n",
    "    np.where(delta_to_start <= delta_to_next, month_start, next_month_start)\n",
    ")\n",
    "\n",
    "exposure_out = exposure_df.copy()\n",
    "exposure_out['Time_dt'] = rounded_month_start\n",
    "exposure_out['Time'] = exposure_out['Time_dt'].dt.strftime('%Y-%m')\n",
    "exposure_out = exposure_out[['Country', 'Time', 'Exposure']].copy()\n",
    "\n",
    "# 2. Define full panel: all countries × all months (2024-10 to 2025-08)\n",
    "#     → 2024-10 needed for lag of 2024-11\n",
    "all_countries = sorted(exposure_out['Country'].unique())\n",
    "all_months = pd.date_range('2024-10', '2025-08', freq='MS').strftime('%Y-%m').tolist()\n",
    "\n",
    "full_index = pd.MultiIndex.from_product([all_countries, all_months], names=['Country', 'Time'])\n",
    "full_panel = pd.DataFrame(index=full_index).reset_index()\n",
    "\n",
    "# 3. Merge observed shocks, fill missing with 0\n",
    "exposure_full = full_panel.merge(exposure_out, on=['Country', 'Time'], how='left')\n",
    "exposure_full['Exposure'] = exposure_full['Exposure'].fillna(0)\n",
    "\n",
    "# 4. Sort and save\n",
    "exposure_full = exposure_full.sort_values(['Country', 'Time']).reset_index(drop=True)\n",
    "Path('data/independent_variable').mkdir(parents=True, exist_ok=True)\n",
    "exposure_full.to_csv('data/independent_variable/CountryTariffExposure_df.csv', index=False)\n",
    "\n",
    "# Openess(i,t) Independent\n",
    "time_raw = openness_df['Time'].astype(str).str.strip()\n",
    "year_num = pd.to_numeric(time_raw, errors='coerce')\n",
    "year_dt = pd.to_datetime(time_raw, errors='coerce').dt.year\n",
    "year = year_num.fillna(year_dt)\n",
    "mask = year.isin([2024, 2025])\n",
    "openness_out = openness_df.loc[mask].copy()\n",
    "openness_out['Time'] = year.loc[mask].astype('Int64').astype(str)\n",
    "openness_out = openness_out.sort_values(['Country', 'Time']).reset_index(drop=True)\n",
    "openness_out.to_csv('data/transition_variable/TradeOpennessAnnual_df.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# wb_openess(i,t)\n",
    "# Step 1: Clean and convert Time to numeric year\n",
    "wb_time_raw = wb_openness_df['Time'].astype(str).str.strip()\n",
    "wb_year_num = pd.to_numeric(wb_time_raw, errors='coerce')\n",
    "wb_year_dt = pd.to_datetime(wb_time_raw, errors='coerce').dt.year\n",
    "wb_year = wb_year_num.fillna(wb_year_dt)\n",
    "# Assign cleaned year back\n",
    "wb_openness_df['Time'] = wb_year\n",
    "# Step 2: Create 2025 entries with 0 openness for all countries\n",
    "countries = wb_openness_df['Country'].unique()\n",
    "year_2025_df = pd.DataFrame({\n",
    "    'Country': countries,\n",
    "    'Time': 2025,\n",
    "    'Global Trade Openness (%GDP)': 0,\n",
    "    'Global Trade Openness-Lag1': pd.NA  # Will be filled after lagging\n",
    "})\n",
    "# Append 2025 data\n",
    "wb_openness_extended = pd.concat([wb_openness_df, year_2025_df], ignore_index=True)\n",
    "# Step 3: Sort by Country and Time to prepare for lagging\n",
    "wb_openness_extended = wb_openness_extended.sort_values(['Country', 'Time']).reset_index(drop=True)\n",
    "# Step 4: Create lag (Global Trade Openness-Lag1) — shift within each country\n",
    "wb_openness_extended['Global Trade Openness-Lag1'] = (\n",
    "    wb_openness_extended.groupby('Country')['Global Trade Openness (%GDP)']\n",
    "    .shift(1)\n",
    ")\n",
    "# Step 5: Filter only 2023 and 2024\n",
    "wb_mask = wb_openness_extended['Time'].isin([2024, 2025])\n",
    "wb_openness_out = wb_openness_extended.loc[wb_mask].copy()\n",
    "# Step 6: Format Time as string (Int64 -> str)\n",
    "wb_openness_out['Time'] = wb_openness_out['Time'].astype('Int64').astype(str)\n",
    "# Step 7: Final sort and save\n",
    "wb_openness_out = wb_openness_out.sort_values(['Country', 'Time']).reset_index(drop=True)\n",
    "wb_openness_out.to_csv('data/transition_variable/WBTradeOpennessAnnual_df.csv', index=False)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Transition Variable + LAG (CORRECT & WORKING)\n",
    "# ================================\n",
    "cols = [\n",
    "    'STRUCTURE','STRUCTURE_ID','STRUCTURE_NAME','freq','Frequency',\n",
    "    'Country','REPORTER','partner','PARTNER','product','PRODUCT',\n",
    "    'flow','FLOW','indicators','INDICATORS','Time','TIME_PERIOD',\n",
    "    'OBS_VALUE','Observation Value'\n",
    "]\n",
    "\n",
    "df_full = transition_df[cols].copy()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) Prepare time & numeric columns  (unchanged)\n",
    "# ------------------------------------------------------------------\n",
    "df_full['Time_period'] = pd.to_datetime(\n",
    "    df_full['Time'], errors='coerce'\n",
    ").dt.to_period('M')\n",
    "\n",
    "df_full['OBS_VALUE'] = pd.to_numeric(df_full['OBS_VALUE'], errors='coerce')\n",
    "\n",
    "df_full = df_full.sort_values(['Country', 'Time_period']).reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2) LAG (on original level, using FULL data)  (unchanged)\n",
    "# ------------------------------------------------------------------\n",
    "df_full['OBS_VALUE_Lagged1'] = df_full.groupby('Country')['OBS_VALUE'].shift(1)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3) Compute MONTHLY TOTALS on FULL data, then convert to proportions\n",
    "#    (this is the block you asked about — it goes HERE, BEFORE filtering)\n",
    "# ------------------------------------------------------------------\n",
    "monthly_totals_full = df_full.groupby('Time_period')['OBS_VALUE'].sum()\n",
    "\n",
    "df_full['monthly_total_current'] = df_full['Time_period'].map(monthly_totals_full)\n",
    "df_full['monthly_total_lagged']  = df_full['Time_period'].map(monthly_totals_full.shift(1))\n",
    "\n",
    "# Convert both to proportions\n",
    "df_full['OBS_VALUE'] = df_full['OBS_VALUE'] / df_full['monthly_total_current']\n",
    "df_full['OBS_VALUE_Lagged1'] = df_full['OBS_VALUE_Lagged1'] / df_full['monthly_total_lagged']\n",
    "\n",
    "# (Optional) If you prefer to avoid infs when a month total is zero:\n",
    "# df_full.replace([float('inf'), -float('inf')], pd.NA, inplace=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4) Filter by date window (AFTER proportions are computed)\n",
    "# ------------------------------------------------------------------\n",
    "mask = (\n",
    "    (df_full['Time_period'] >= pd.Period(start_date, 'M')) &\n",
    "    (df_full['Time_period'] <= pd.Period(end_date, 'M'))\n",
    ")\n",
    "\n",
    "transition_df_filtered = (\n",
    "    df_full.loc[mask].copy()\n",
    ")\n",
    "\n",
    "# Clean up helper columns and final ordering\n",
    "transition_df_filtered = (\n",
    "    transition_df_filtered\n",
    "        .drop(columns=['Time_period', 'monthly_total_current', 'monthly_total_lagged'])\n",
    "        .sort_values(['Country', 'Time'])\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5) Save\n",
    "# ------------------------------------------------------------------\n",
    "from pathlib import Path\n",
    "Path('data/transition_variable').mkdir(parents=True, exist_ok=True)\n",
    "transition_df_filtered.to_csv(\n",
    "    'data/transition_variable/EU_partner_index_df.csv', index=False\n",
    ")\n",
    "\n",
    "print(\"Lag added using pre-period data!\")\n",
    "print(f\"Valid lags: {transition_df_filtered['OBS_VALUE_Lagged1'].notna().sum():,}\")\n",
    "print(\"File saved: EU_partner_index_df.csv  (both OBS_VALUE and OBS_VALUE_Lagged1 are proportions of their respective month's total)\")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Controls (i,t) – LAGGED HICP & LAGGED ΔUnemployment\n",
    "# ================================\n",
    "\n",
    "controls_cols = [\n",
    "    'Country',\n",
    "    'Time',\n",
    "    'GDP (Million USD)',\n",
    "    'HICP (%, annual rate of change)',\n",
    "    'Unemployment Rate (%pop in LF)'\n",
    "]\n",
    "\n",
    "controls_full = controls_df[controls_cols].copy()\n",
    "\n",
    "# 1. Convert Time to datetime (same as before)\n",
    "controls_full['Time_dt'] = pd.to_datetime(controls_full['Time'], errors='coerce')\n",
    "controls_full = controls_full.sort_values(['Country', 'Time_dt'])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. FIRST DIFFERENCE UNEMPLOYMENT (still needed for the lag)\n",
    "# ------------------------------------------------------------------\n",
    "controls_full['ΔUnemployment'] = (\n",
    "    controls_full.groupby('Country')['Unemployment Rate (%pop in LF)'].diff()\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. CREATE LAG-1 FOR BOTH VARIABLES (within country)\n",
    "# ------------------------------------------------------------------\n",
    "controls_full['HICP_lag1'] = (\n",
    "    controls_full.groupby('Country')['HICP (%, annual rate of change)'].shift(1)\n",
    ")\n",
    "\n",
    "controls_full['Unemployment_lag1'] = (\n",
    "    controls_full.groupby('Country')['ΔUnemployment'].shift(1)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. FILTER TO ANALYSIS WINDOW (2024-11 → 2025-08)\n",
    "# ------------------------------------------------------------------\n",
    "controls_period = controls_full['Time_dt'].dt.to_period('M')\n",
    "controls_mask = (\n",
    "    (controls_period >= pd.Period(start_date, 'M')) &\n",
    "    (controls_period <= pd.Period(end_date, 'M'))\n",
    ")\n",
    "\n",
    "controls_out = controls_full.loc[controls_mask, [\n",
    "    'Country',\n",
    "    'Time_dt',\n",
    "    'GDP (Million USD)',\n",
    "    'HICP_lag1',               # <-- lagged HICP\n",
    "    'Unemployment_lag1'       # <-- lagged ΔUnemployment\n",
    "]].copy()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. FORMAT TIME COLUMN AND CLEAN UP\n",
    "# ------------------------------------------------------------------\n",
    "controls_out['Time'] = controls_out['Time_dt'].dt.strftime('%Y-%m')\n",
    "controls_out = controls_out.drop(columns=['Time_dt'])\n",
    "\n",
    "# final column order for the CSV\n",
    "controls_out = controls_out[[\n",
    "    'Country',\n",
    "    'Time',\n",
    "    'GDP (Million USD)',\n",
    "    'HICP_lag1',\n",
    "    'Unemployment_lag1'\n",
    "]]\n",
    "\n",
    "controls_out = controls_out.sort_values(['Country', 'Time']).reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. SAVE\n",
    "# ------------------------------------------------------------------\n",
    "Path('data/control_variable').mkdir(parents=True, exist_ok=True)\n",
    "controls_out.to_csv('data/control_variable/CountryControls_df.csv', index=False)\n",
    "\n",
    "print(\"\\nControls saved with:\")\n",
    "print(\"  • HICP_lag1  = HICP(t-1)\")\n",
    "print(\"  • ΔUnemployment_lag1 = ΔUnemployment(t-1)\")\n",
    "print(f\"  • Window: {start_date} → {end_date}\")\n",
    "print(f\"  • Valid HICP lags: {controls_out['HICP_lag1'].notna().sum():,}\")\n",
    "print(f\"  • Valid ΔUnemp lags: {controls_out['Unemployment_lag1'].notna().sum():,}\\n\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 924 non-EU rows → 25,870 EU rows kept\n",
      "Dropped 6 non-EU rows → 156 EU rows kept\n",
      "Dropped 1,707 non-EU rows → 11,035 EU rows kept\n",
      "Dropped 688 non-EU rows → 1,169 EU rows kept\n",
      "\n",
      "Kept only 27 EU countries: ['AT', 'BE', 'BG', 'CY', 'CZ', 'DE', 'DK', 'EE', 'ES', 'FI', 'FR', 'GR', 'HR', 'HU', 'IE', 'IT', 'LT', 'LU', 'LV', 'MT', 'NL', 'PL', 'PT', 'RO', 'SE', 'SI', 'SK']\n",
      "\n",
      "Saved: IndustrialProductionIndex_df.csv\n",
      "  → Analysis window: 2024-11 to 2025-08\n",
      "  → Valid lagged differences: 260\n",
      "  → First month in window has lag: True\n",
      "Lag added using pre-period data!\n",
      "Valid lags: 251\n",
      "File saved: EU_partner_index_df.csv  (both OBS_VALUE and OBS_VALUE_Lagged1 are proportions of their respective month's total)\n",
      "\n",
      "Controls saved with:\n",
      "  • HICP_lag1  = HICP(t-1)\n",
      "  • ΔUnemployment_lag1 = ΔUnemployment(t-1)\n",
      "  • Window: 2024-11 → 2025-08\n",
      "  • Valid HICP lags: 260\n",
      "  • Valid ΔUnemp lags: 260\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "f07007353f08b543",
   "metadata": {},
   "source": [
    "## 4) Baseline Simple OLS regressions\n",
    "\n",
    "We estimate the **short-run effect** of U.S. tariff exposure on monthly macroeconomic outcomes (Industrial Production Index (B+C), Stocks Index Return, FX change).\n",
    "The model includes **country** and **month fixed effects** to control for unobserved, time-invariant country characteristics and global shocks.\n",
    "\n",
    "$$\n",
    "y_{i,t} = \\mu_i + \\lambda_t\n",
    "+ \\alpha_0\\,\\text{Exposure}_{i,t}\n",
    "+ \\alpha_1\\,\\text{Exposure}_{i,t-1}\n",
    "+ \\Gamma' Z_{i,t}\n",
    "+ \\varepsilon_{i,t}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $y_{i,t}$ — Outcome variable (Industrial Production Index (B+C) YoY for country *i* in month *t*, Stocks Index for country *i* in month *t*\n",
    "- $\\text{Exposure}_{i,t}$ — Country *i*’s effective tariff exposure in month *t*\n",
    "- $\\text{Exposure}_{i,t-1}$ — One-month lag of tariff exposure (captures delayed reaction)\n",
    "- $Z_{i,t}$ — Vector of monthly country-specific control variables (HICP YoY%, Δ unemployment)\n",
    "- $\\mu_i$ — Country fixed effects (absorbing structural country heterogeneity)\n",
    "- $\\lambda_t$ — Month fixed effects (absorbing global macro shocks)\n",
    "- $\\varepsilon_{i,t}$ — Idiosyncratic error term, clustered at the country level\n",
    "\n",
    "---\n",
    "\n",
    "### **Estimation Details**\n",
    "\n",
    "- **Estimator:** OLS with two-way (country and month) fixed effects\n",
    "- **Frequency:** Monthly (2024-10 → 2025-08)\n",
    "- **Standard Errors:** Clustered by country\n",
    "- **Sample:** EU countries only, using *effective* tariff exposure measure\n",
    "- **Controls:** Domestic macro variables (HICP YoY%, Δ unemployment)\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters of Interest**\n",
    "\n",
    "- $\\alpha_0$ — Contemporaneous effect of tariff exposure\n",
    "- $\\alpha_1$ — One-month-lagged effect\n",
    "- $\\alpha_0 + \\alpha_1$ — Cumulative 0–1-month effect (interpreted as the total short-run impact)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9274b65bc773f87b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T13:13:03.077652Z",
     "start_time": "2025-11-08T13:13:01.958066Z"
    }
   },
   "source": [
    "BASE = Path.cwd() / \"data\"\n",
    "\n",
    "ipi      = pd.read_csv(BASE / \"dependent_variable\" / \"IndustrialProductionIndex_df.csv\")\n",
    "stocks   = pd.read_csv(BASE / \"dependent_variable\" / \"StockIndex_df.csv\")\n",
    "exposure = pd.read_csv(BASE / \"independent_variable\" / \"CountryTariffExposure_df.csv\")\n",
    "controls = pd.read_csv(BASE / \"control_variable\" / \"CountryControls_df.csv\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Convert Time → Period[M] for every file\n",
    "# -------------------------------------------------\n",
    "for df in (ipi, stocks, exposure, controls):\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\").dt.to_period(\"M\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Choose dependent variable (IPI diff)\n",
    "# -------------------------------------------------\n",
    "df_dep = ipi.rename(columns={\"diff_IPI\": \"y\"})\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Prepare exposure + lag (t and t-1)\n",
    "# -------------------------------------------------\n",
    "exp = exposure.rename(columns={\"Exposure\": \"Exposure_t\"})\n",
    "exp = exp.sort_values([\"Country\", \"Time\"])\n",
    "exp[\"Exposure_t1\"] = exp.groupby(\"Country\")[\"Exposure_t\"].shift(1)\n",
    "exp = exp.dropna(subset=[\"Exposure_t1\"])          # drop first month per country\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Merge ONLY the variables you want\n",
    "# -------------------------------------------------\n",
    "# → we **skip** the controls merge entirely\n",
    "df = (\n",
    "    df_dep[[\"Country\", \"Time\", \"y\"]]\n",
    "    .merge(exp[[\"Country\", \"Time\", \"Exposure_t\", \"Exposure_t1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    "    # <-- NO controls merge here\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Restrict to analysis window\n",
    "# -------------------------------------------------\n",
    "df = df[\n",
    "    (df[\"Time\"] >= pd.Period(\"2024-11\", \"M\")) &\n",
    "    (df[\"Time\"] <= pd.Period(\"2025-08\", \"M\"))\n",
    "]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Index for PanelOLS\n",
    "# -------------------------------------------------\n",
    "df[\"Time_dt\"] = df[\"Time\"].dt.start_time\n",
    "df = df.set_index([\"Country\", \"Time_dt\"])\n",
    "df = df.drop(columns=[\"Time\"])   # optional cleanup\n",
    "\n",
    "print(\"Months in final panel:\", sorted(df.index.get_level_values(1).unique()))\n",
    "print(\"Obs per country (min/avg/max):\",\n",
    "      df.groupby(level=0).size().min(),\n",
    "      df.groupby(level=0).size().mean().round(1),\n",
    "      df.groupby(level=0).size().max())\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Two-way FE regression **without** HICP/Unemp\n",
    "# -------------------------------------------------\n",
    "exog_vars = [\"Exposure_t\", \"Exposure_t1\"]   # <-- ONLY exposure vars\n",
    "\n",
    "mod = PanelOLS(\n",
    "    dependent=df[\"y\"],\n",
    "    exog=df[exog_vars],\n",
    "    entity_effects=True,   # μ_i\n",
    "    time_effects=True,     # λ_t\n",
    ")\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(res)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months in final panel: [Timestamp('2024-11-01 00:00:00'), Timestamp('2024-12-01 00:00:00'), Timestamp('2025-01-01 00:00:00'), Timestamp('2025-02-01 00:00:00'), Timestamp('2025-03-01 00:00:00'), Timestamp('2025-04-01 00:00:00'), Timestamp('2025-05-01 00:00:00'), Timestamp('2025-06-01 00:00:00'), Timestamp('2025-07-01 00:00:00'), Timestamp('2025-08-01 00:00:00')]\n",
      "Obs per country (min/avg/max): 10 10.0 10\n",
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                      y   R-squared:                        0.0272\n",
      "Estimator:                   PanelOLS   R-squared (Between):              0.2840\n",
      "No. Observations:                 260   R-squared (Within):              -0.0303\n",
      "Date:                Sat, Nov 08 2025   R-squared (Overall):             -0.0136\n",
      "Time:                        14:13:02   Log-likelihood                   -1090.0\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      3.1120\n",
      "Entities:                          26   P-value                           0.0465\n",
      "Avg Obs:                      10.0000   Distribution:                   F(2,223)\n",
      "Min Obs:                      10.0000                                           \n",
      "Max Obs:                      10.0000   F-statistic (robust):             5.6056\n",
      "                                        P-value                           0.0042\n",
      "Time periods:                      10   Distribution:                   F(2,223)\n",
      "Avg Obs:                       26.000                                           \n",
      "Min Obs:                       26.000                                           \n",
      "Max Obs:                       26.000                                           \n",
      "                                                                                \n",
      "                              Parameter Estimates                              \n",
      "===============================================================================\n",
      "             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------\n",
      "Exposure_t     -0.2125     0.5477    -0.3879     0.6984     -1.2918      0.8669\n",
      "Exposure_t1    -1.8920     0.6550    -2.8886     0.0043     -3.1827     -0.6012\n",
      "===============================================================================\n",
      "\n",
      "F-test for Poolability: 3.6470\n",
      "P-value: 0.0000\n",
      "Distribution: F(34,223)\n",
      "\n",
      "Included effects: Entity, Time\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "c04c7b31db23f8e1",
   "metadata": {},
   "source": [
    "## 5) Extended Specification — Linear Heterogeneity with Trade Openness Interaction\n",
    "\n",
    "To allow the impact of tariff exposure to vary across countries with different levels of trade openness,\n",
    "we extend the baseline specification by interacting exposure with lagged openness.\n",
    "This captures whether **more open economies** react differently to tariff shocks.\n",
    "\n",
    "$$\n",
    "y_{i,t} = \\mu_i + \\lambda_t\n",
    "+ \\alpha_0\\,\\text{Exposure}_{i,t}\n",
    "+ \\alpha_1\\,\\text{Exposure}_{i,t-1}\n",
    "+ \\beta_0\\,(\\text{Exposure}_{i,t} \\times \\text{Openness}_{i,t-1}^{US})\n",
    "+ \\beta_1\\,(\\text{Exposure}_{i,t-1} \\times \\text{Openness}_{i,t-1}^{US})\n",
    "+ \\Gamma' Z_{i,t}\n",
    "+ \\varepsilon_{i,t}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $y_{i,t}$ — Outcome variable (e.g. Industrial Production YoY for country *i* in month *t*)\n",
    "- $\\text{Exposure}_{i,t}$ — Effective tariff exposure in month *t*\n",
    "- $\\text{Exposure}_{i,t-1}$ — One-month lag of exposure\n",
    "- $\\text{Openness}_{i,t-1}^{US}$ — Lagged trade openness index relative to the US (annual, mapped to months)\n",
    "- $(\\text{Exposure}_{i,t} \\times \\text{Openness}_{i,t-1}^{US})$ — Interaction term capturing heterogeneous exposure effects\n",
    "- $Z_{i,t}$ — Monthly domestic controls (HICP YoY, Δ unemployment)\n",
    "- $\\mu_i$ — Country fixed effects\n",
    "- $\\lambda_t$ — Month fixed effects\n",
    "- $\\varepsilon_{i,t}$ — Error term clustered by country\n",
    "\n",
    "\n",
    "### **Interpretation**\n",
    "\n",
    "- $\\alpha_0$, $\\alpha_1$ — Baseline (average) effects of exposure at zero openness\n",
    "- $\\beta_0$, $\\beta_1$ — Marginal change in the exposure effect as openness increases\n",
    "- **Marginal effect of exposure:**\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t}}\n",
    "  = \\alpha_0 + \\beta_0\\,\\text{Openness}_{i,t-1}^{US}\n",
    "  $$\n",
    "  and\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t-1}}\n",
    "  = \\alpha_1 + \\beta_1\\,\\text{Openness}_{i,t-1}^{US}\n",
    "  $$\n",
    "- Report **cumulative marginal effect** $(\\alpha_0+\\alpha_1) + (\\beta_0+\\beta_1)\\text{Openness}_{i,t-1}^{US}$ evaluated at low, median, and high openness levels.\n",
    "\n",
    "---\n",
    "\n",
    "### **Estimation Details**\n",
    "\n",
    "- **Estimator:** OLS with two-way (country and month) fixed effects\n",
    "- **Frequency:** Monthly (2024-10 → 2025-09)\n",
    "- **Standard Errors:** Clustered by country\n",
    "- **Sample:** EU countries only\n",
    "- **Controls:** Domestic macro variables (HICP YoY, unemployment)\n",
    "\n",
    "---\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "This model tests whether the **sensitivity to U.S. tariff shocks** depends on how open a country's economy is to the US.\n",
    "A positive $\\beta_0$ or $\\beta_1$ implies that **more open economies are more affected** by tariff changes,\n",
    "while a negative coefficient indicates **buffering or diversification effects** from openness.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "85dc37f43bcfbf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T13:13:26.047796Z",
     "start_time": "2025-11-08T13:13:25.078249Z"
    }
   },
   "source": [
    "# ================================\n",
    "# Traditional Trade Openness + Interaction (NO HICP / Unemployment)\n",
    "# ================================\n",
    "\n",
    "BASE = Path.cwd() / \"data\"\n",
    "\n",
    "ipi      = pd.read_csv(BASE / \"dependent_variable\" / \"IndustrialProductionIndex_df.csv\")\n",
    "stocks   = pd.read_csv(BASE / \"dependent_variable\" / \"StockIndex_df.csv\")\n",
    "exposure = pd.read_csv(BASE / \"independent_variable\" / \"CountryTariffExposure_df.csv\")\n",
    "controls = pd.read_csv(BASE / \"control_variable\" / \"CountryControls_df.csv\")   # still read, but never used\n",
    "openness = pd.read_csv(BASE / \"transition_variable\" / \"TradeOpennessAnnual_df.csv\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Convert Time → Period[M] (only for the files we actually use)\n",
    "# -------------------------------------------------\n",
    "for df in (ipi, stocks, exposure):\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\").dt.to_period(\"M\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Prepare annual openness → monthly panel\n",
    "# -------------------------------------------------\n",
    "openness = openness[[\"Country\", \"Time\", \"Trade_Openness_pct_GDP\"]].copy()\n",
    "openness.rename(columns={\"Trade_Openness_pct_GDP\": \"Openness_annual\"}, inplace=True)\n",
    "openness[\"Year\"] = pd.to_datetime(openness[\"Time\"].astype(str), errors=\"coerce\").dt.year\n",
    "openness = openness.drop(columns=[\"Time\"])\n",
    "\n",
    "monthly_open = []\n",
    "for year in [2024, 2025]:\n",
    "    months = pd.date_range(f\"{year}-01-01\", f\"{year}-12-31\", freq=\"MS\")\n",
    "    temp   = pd.DataFrame({\"Time_dt\": months})\n",
    "    temp[\"Time\"] = temp[\"Time_dt\"].dt.to_period(\"M\")\n",
    "    temp = temp.merge(openness[openness[\"Year\"] == year], how=\"cross\")\n",
    "    monthly_open.append(temp)\n",
    "\n",
    "openness_monthly = pd.concat(monthly_open, ignore_index=True)\n",
    "openness_monthly = openness_monthly[[\"Country\", \"Time\", \"Openness_annual\"]]\n",
    "openness_monthly = openness_monthly.rename(columns={\"Openness_annual\": \"Openness\"})\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Dependent variable\n",
    "# -------------------------------------------------\n",
    "df_dep = ipi.rename(columns={\"diff_IPI\": \"y\"})          # <-- IPI YoY diff\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Exposure + lag + openness + interaction\n",
    "# -------------------------------------------------\n",
    "exp = exposure.rename(columns={\"Exposure\": \"Exposure_t\"})\n",
    "exp = exp.sort_values([\"Country\", \"Time\"])\n",
    "exp[\"Exposure_t1\"] = exp.groupby(\"Country\")[\"Exposure_t\"].shift(1)\n",
    "\n",
    "# merge openness (monthly)\n",
    "exp = exp.merge(openness_monthly, on=[\"Country\", \"Time\"], how=\"left\")\n",
    "exp[\"Openness_t1\"] = exp.groupby(\"Country\")[\"Openness\"].shift(1)\n",
    "\n",
    "# drop rows that lose the lag (first month per country)\n",
    "exp = exp.dropna(subset=[\"Exposure_t1\", \"Openness_t1\"])\n",
    "\n",
    "# interaction terms\n",
    "exp[\"Exp_t_x_Open_t1\"]   = exp[\"Exposure_t\"]  * exp[\"Openness_t1\"]\n",
    "exp[\"Exp_t1_x_Open_t1\"]  = exp[\"Exposure_t1\"] * exp[\"Openness_t1\"]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Build final panel – **NO CONTROLS MERGE**\n",
    "# -------------------------------------------------\n",
    "df = (\n",
    "    df_dep[[\"Country\", \"Time\", \"y\"]]\n",
    "    .merge(exp[[\"Country\", \"Time\",\n",
    "                \"Exposure_t\", \"Exposure_t1\",\n",
    "                \"Exp_t_x_Open_t1\", \"Exp_t1_x_Open_t1\",\n",
    "                \"Openness_t1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    "    # ←←←  controls merge removed\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Restrict to analysis window\n",
    "# -------------------------------------------------\n",
    "df = df[\n",
    "    (df[\"Time\"] >= pd.Period(\"2024-11\", \"M\")) &\n",
    "    (df[\"Time\"] <= pd.Period(\"2025-08\", \"M\"))\n",
    "]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Index for PanelOLS\n",
    "# -------------------------------------------------\n",
    "df[\"Time_dt\"] = df[\"Time\"].dt.start_time\n",
    "df = df.set_index([\"Country\", \"Time_dt\"])\n",
    "df = df.drop(columns=[\"Time\"])\n",
    "\n",
    "print(\"Months in final panel:\", sorted(df.index.get_level_values(1).unique()))\n",
    "print(\"Obs per country (min/avg/max):\",\n",
    "      df.groupby(level=0).size().min(),\n",
    "      df.groupby(level=0).size().mean().round(1),\n",
    "      df.groupby(level=0).size().max())\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 8. Regression – **only exposure & openness interaction**\n",
    "# -------------------------------------------------\n",
    "exog_vars = [\n",
    "    \"Exposure_t\", \"Exposure_t1\",\n",
    "    \"Exp_t_x_Open_t1\", \"Exp_t1_x_Open_t1\",\n",
    "    \"Openness_t1\"\n",
    "]                                   # ←←← HICP & Unemployment removed\n",
    "\n",
    "mod = PanelOLS(\n",
    "    dependent=df[\"y\"],\n",
    "    exog=df[exog_vars],\n",
    "    entity_effects=True,   # country FE\n",
    "    time_effects=True,     # month FE\n",
    ")\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(res)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 9. Marginal effects of tariff exposure at different openness levels\n",
    "# -------------------------------------------------\n",
    "print(\"\\n=== MARGINAL EFFECTS OF TARIFF EXPOSURE ===\")\n",
    "open_levels = {\n",
    "    \"Low\":     df[\"Openness_t1\"].quantile(0.25),\n",
    "    \"Median\":  df[\"Openness_t1\"].median(),\n",
    "    \"High\":    df[\"Openness_t1\"].quantile(0.75)\n",
    "}\n",
    "\n",
    "for label, q in open_levels.items():\n",
    "    # Contemporaneous effect\n",
    "    me_t  = res.params[\"Exposure_t\"] + res.params[\"Exp_t_x_Open_t1\"] * q\n",
    "    var_t = (res.cov.loc[\"Exposure_t\",\"Exposure_t\"] +\n",
    "             2*q*res.cov.loc[\"Exposure_t\",\"Exp_t_x_Open_t1\"] +\n",
    "             q**2*res.cov.loc[\"Exp_t_x_Open_t1\",\"Exp_t_x_Open_t1\"])\n",
    "    se_t  = np.sqrt(var_t)\n",
    "\n",
    "    # Lagged effect\n",
    "    me_t1 = res.params[\"Exposure_t1\"] + res.params[\"Exp_t1_x_Open_t1\"] * q\n",
    "    var_t1 = (res.cov.loc[\"Exposure_t1\",\"Exposure_t1\"] +\n",
    "              2*q*res.cov.loc[\"Exposure_t1\",\"Exp_t1_x_Open_t1\"] +\n",
    "              q**2*res.cov.loc[\"Exp_t1_x_Open_t1\",\"Exp_t1_x_Open_t1\"])\n",
    "    se_t1 = np.sqrt(var_t1)\n",
    "\n",
    "    # Cumulative (contemporaneous + lagged)\n",
    "    cov_cross = (res.cov.loc[\"Exposure_t\",\"Exposure_t1\"] +\n",
    "                 q*(res.cov.loc[\"Exposure_t\",\"Exp_t1_x_Open_t1\"] +\n",
    "                    res.cov.loc[\"Exp_t_x_Open_t1\",\"Exposure_t1\"]) +\n",
    "                 q**2*res.cov.loc[\"Exp_t_x_Open_t1\",\"Exp_t1_x_Open_t1\"])\n",
    "    var_cum = var_t + var_t1 + 2*cov_cross\n",
    "    se_cum  = np.sqrt(var_cum)\n",
    "    me_cum  = me_t + me_t1\n",
    "\n",
    "    print(f\"\\n{label} Openness ({q:.4f}):\")\n",
    "    print(f\"  Contemporaneous : {me_t: .5f} (se = {se_t: .5f})\")\n",
    "    print(f\"  Lagged          : {me_t1:.5f} (se = {se_t1:.5f})\")\n",
    "    print(f\"  Cumulative      : {me_cum:.5f} (se = {se_cum:.5f})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months in final panel: [Timestamp('2024-11-01 00:00:00'), Timestamp('2024-12-01 00:00:00'), Timestamp('2025-01-01 00:00:00'), Timestamp('2025-02-01 00:00:00'), Timestamp('2025-03-01 00:00:00'), Timestamp('2025-04-01 00:00:00'), Timestamp('2025-05-01 00:00:00'), Timestamp('2025-06-01 00:00:00'), Timestamp('2025-07-01 00:00:00'), Timestamp('2025-08-01 00:00:00')]\n",
      "Obs per country (min/avg/max): 10 10.0 10\n",
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                      y   R-squared:                        0.0330\n",
      "Estimator:                   PanelOLS   R-squared (Between):             -0.4980\n",
      "No. Observations:                 260   R-squared (Within):              -0.0221\n",
      "Date:                Sat, Nov 08 2025   R-squared (Overall):             -0.0474\n",
      "Time:                        14:13:25   Log-likelihood                   -1089.2\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      1.5002\n",
      "Entities:                          26   P-value                           0.1908\n",
      "Avg Obs:                      10.0000   Distribution:                   F(5,220)\n",
      "Min Obs:                      10.0000                                           \n",
      "Max Obs:                      10.0000   F-statistic (robust):             6.3976\n",
      "                                        P-value                           0.0000\n",
      "Time periods:                      10   Distribution:                   F(5,220)\n",
      "Avg Obs:                       26.000                                           \n",
      "Min Obs:                       26.000                                           \n",
      "Max Obs:                       26.000                                           \n",
      "                                                                                \n",
      "                                Parameter Estimates                                 \n",
      "====================================================================================\n",
      "                  Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------\n",
      "Exposure_t           1.1773     1.5446     0.7622     0.4468     -1.8667      4.2213\n",
      "Exposure_t1         -3.0446     2.2526    -1.3516     0.1779     -7.4840      1.3949\n",
      "Exp_t_x_Open_t1     -0.3839     0.3452    -1.1120     0.2674     -1.0643      0.2965\n",
      "Exp_t1_x_Open_t1     0.2744     0.4670     0.5877     0.5574     -0.6459      1.1947\n",
      "Openness_t1         -1.0069     0.5137    -1.9600     0.0513     -2.0194      0.0055\n",
      "====================================================================================\n",
      "\n",
      "F-test for Poolability: 3.4610\n",
      "P-value: 0.0000\n",
      "Distribution: F(34,220)\n",
      "\n",
      "Included effects: Entity, Time\n",
      "\n",
      "=== MARGINAL EFFECTS OF TARIFF EXPOSURE ===\n",
      "\n",
      "Low Openness (1.3166):\n",
      "  Contemporaneous :  0.67182 (se =  1.11448)\n",
      "  Lagged          : -2.68326 (se = 1.65648)\n",
      "  Cumulative      : -2.01143 (se = 2.17107)\n",
      "\n",
      "Median Openness (2.2212):\n",
      "  Contemporaneous :  0.32456 (se =  0.83418)\n",
      "  Lagged          : -2.43502 (se = 1.25740)\n",
      "  Cumulative      : -2.11047 (se = 1.64209)\n",
      "\n",
      "High Openness (2.9337):\n",
      "  Contemporaneous :  0.05105 (se =  0.63480)\n",
      "  Lagged          : -2.23951 (se = 0.95727)\n",
      "  Cumulative      : -2.18847 (se = 1.23541)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "28b5813d75cfd754",
   "metadata": {},
   "source": [
    "## 6) Extended Specification — PSTR Model with Smooth Transition by Trade Openness\n",
    "\n",
    "We now allow the effect of tariff exposure to vary **smoothly** with the level of trade openness with the US.\n",
    "Instead of assuming a linear interaction, we introduce a **logistic transition function** that captures gradual changes in the impact of exposure as openness increases.\n",
    "\n",
    "The logistic transition function is defined as:\n",
    "\n",
    "$$\n",
    "G\\!\\left(\\text{Openness}_{i,t-1}^{US};\\gamma,c\\right)\n",
    "= \\frac{1}{1 + \\exp\\!\\big[-\\gamma\\big(\\text{Openness}_{i,t-1}^{US} - c\\big)\\big]}.\n",
    "$$\n",
    "\n",
    "The corresponding PSTR regression is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{i,t} &= \\mu_i + \\lambda_t\n",
    "+ \\alpha_0\\,\\text{Exposure}_{i,t}\n",
    "+ \\alpha_1\\,\\text{Exposure}_{i,t-1} \\\\\n",
    "&\\quad + \\big(\\beta_0\\,\\text{Exposure}_{i,t} + \\beta_1\\,\\text{Exposure}_{i,t-1}\\big)\n",
    "\\,G\\!\\left(\\text{Openness}_{i,t-1}^{US};\\gamma,c\\right)\n",
    "+ \\Gamma' Z_{i,t}\n",
    "+ \\varepsilon_{i,t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $y_{i,t}$ — Outcome variable (e.g. Industrial Production YoY for country *i* in month *t*)\n",
    "- $\\text{Exposure}_{i,t}$ — Effective tariff exposure in month *t*\n",
    "- $\\text{Exposure}_{i,t-1}$ — One-month lag of exposure\n",
    "- $\\text{Openness}_{i,t-1}^{US}$ — Lagged trade openness index (annual, mapped to months)\n",
    "- $G(\\text{Openness}_{i,t-1}^{US};\\gamma,c)$ — Logistic transition function with:\n",
    "  - $c$: threshold (location) where $G=0.5$\n",
    "  - $\\gamma$: smoothness parameter controlling how sharp the transition is\n",
    "- $Z_{i,t}$ — Monthly domestic controls (HICP YoY, Δ unemployment)\n",
    "- $\\mu_i$ — Country fixed effects\n",
    "- $\\lambda_t$ — Month fixed effects\n",
    "- $\\varepsilon_{i,t}$ — Error term clustered by country\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation**\n",
    "\n",
    "- $\\alpha_0$, $\\alpha_1$ — Baseline exposure effects when openness is low ($G \\approx 0$)\n",
    "- $\\beta_0$, $\\beta_1$ — Incremental effects as openness increases ($G \\to 1$)\n",
    "- **Marginal effects of exposure:**\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t}}\n",
    "  = \\alpha_0 + \\beta_0\\,G(\\text{Openness}_{i,t-1}^{US};\\gamma,c),\n",
    "  $$\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t-1}}\n",
    "  = \\alpha_1 + \\beta_1\\,G(\\text{Openness}_{i,t-1}^{US};\\gamma,c).\n",
    "  $$\n",
    "- **Cumulative short-run effect (0–1 month):**\n",
    "  $$\n",
    "  (\\alpha_0 + \\alpha_1) + (\\beta_0 + \\beta_1)\\,G(\\text{Openness}_{i,t-1}^{US};\\gamma,c).\n",
    "  $$\n",
    "- When $\\gamma$ is large, $G(\\cdot)$ approximates a sharp threshold model; when small, the transition is smooth.\n",
    "\n",
    "---\n",
    "\n",
    "### **Estimation Details**\n",
    "\n",
    "- **Estimator:** Nonlinear least squares with two-way (country and month) fixed effects\n",
    "- **Frequency:** Monthly (2024-10 → 2025-09)\n",
    "- **Standard Errors:** Clustered by country\n",
    "- **Sample:** EU countries only\n",
    "- **Controls:** Domestic macro variables (HICP YoY, unemployment)\n",
    "- **Pre-processing:** Standardize openness before estimation; report the threshold $c$ in original units after transformation\n",
    "\n",
    "---\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "This model identifies whether the **effect of U.S. tariff shocks on economic outcomes** depends on how open each country is to trade with the US.\n",
    "The logistic transition function captures a **nonlinear response** — for example, more open economies may only become significantly affected **after** crossing a critical openness threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0bc38c25a7789a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T13:15:26.173820Z",
     "start_time": "2025-11-08T13:15:24.646895Z"
    }
   },
   "source": [
    "# ================================\n",
    "# PSTR with Traditional Trade Openness – NO HICP / Unemployment\n",
    "# ================================\n",
    "\n",
    "BASE = Path.cwd() / \"data\"\n",
    "\n",
    "ipi      = pd.read_csv(BASE / \"dependent_variable\" / \"IndustrialProductionIndex_df.csv\")\n",
    "stocks   = pd.read_csv(BASE / \"dependent_variable\" / \"StockIndex_df.csv\")\n",
    "exposure = pd.read_csv(BASE / \"independent_variable\" / \"CountryTariffExposure_df.csv\")\n",
    "controls = pd.read_csv(BASE / \"control_variable\" / \"CountryControls_df.csv\")   # read but never used\n",
    "openness = pd.read_csv(BASE / \"transition_variable\" / \"TradeOpennessAnnual_df.csv\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Convert Time → Period[M] (only for files we use)\n",
    "# -------------------------------------------------\n",
    "for df in (ipi, stocks, exposure):\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\").dt.to_period(\"M\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Prepare annual openness (lagged) → monthly panel\n",
    "# -------------------------------------------------\n",
    "openness = openness[[\"Country\", \"Time\", \"Openness_Lag1\"]].copy()\n",
    "openness.rename(columns={\"Openness_Lag1\": \"Openness_annual\"}, inplace=True)\n",
    "openness[\"Year\"] = pd.to_datetime(openness[\"Time\"].astype(str), errors=\"coerce\").dt.year\n",
    "openness = openness.drop(columns=[\"Time\"])\n",
    "\n",
    "monthly_open = []\n",
    "for year in [2024, 2025]:\n",
    "    months = pd.date_range(f\"{year}-01-01\", f\"{year}-12-31\", freq=\"MS\")\n",
    "    tmp    = pd.DataFrame({\"Time_dt\": months})\n",
    "    tmp[\"Time\"] = tmp[\"Time_dt\"].dt.to_period(\"M\")\n",
    "    tmp = tmp.merge(openness[openness[\"Year\"] == year][[\"Country\", \"Openness_annual\"]],\n",
    "                    how=\"cross\")\n",
    "    monthly_open.append(tmp)\n",
    "\n",
    "openness_monthly = pd.concat(monthly_open, ignore_index=True)\n",
    "openness_monthly = openness_monthly[[\"Country\", \"Time\", \"Openness_annual\"]]\n",
    "openness_monthly = openness_monthly.rename(columns={\"Openness_annual\": \"Openness\"})\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Dependent variable\n",
    "# -------------------------------------------------\n",
    "df_dep = ipi.rename(columns={\"diff_IPI\": \"y\"})          # IPI YoY diff\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Exposure + lag + openness + lag\n",
    "# -------------------------------------------------\n",
    "exp = exposure.rename(columns={\"Exposure\": \"Exposure_t\"})\n",
    "exp = exp.sort_values([\"Country\", \"Time\"])\n",
    "exp[\"Exposure_t1\"] = exp.groupby(\"Country\")[\"Exposure_t\"].shift(1)\n",
    "\n",
    "# merge monthly openness\n",
    "exp = exp.merge(openness_monthly, on=[\"Country\", \"Time\"], how=\"left\")\n",
    "exp[\"Openness_t1\"] = exp.groupby(\"Country\")[\"Openness\"].shift(1)\n",
    "\n",
    "# drop first month per country (no lag)\n",
    "exp = exp.dropna(subset=[\"Exposure_t1\", \"Openness_t1\"])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Build panel – **NO CONTROLS MERGE**\n",
    "# -------------------------------------------------\n",
    "df = (\n",
    "    df_dep[[\"Country\", \"Time\", \"y\"]]\n",
    "    .merge(exp[[\"Country\", \"Time\",\n",
    "                \"Exposure_t\", \"Exposure_t1\",\n",
    "                \"Openness_t1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    "    # ←←←  controls merge removed\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Restrict to analysis window\n",
    "# -------------------------------------------------\n",
    "df = df[\n",
    "    (df[\"Time\"] >= pd.Period(\"2024-11\", \"M\")) &\n",
    "    (df[\"Time\"] <= pd.Period(\"2025-08\", \"M\"))\n",
    "].copy()\n",
    "\n",
    "df[\"Time_dt\"] = df[\"Time\"].dt.start_time\n",
    "df = df.set_index([\"Country\", \"Time_dt\"]).sort_index()\n",
    "df.drop(columns=[\"Time\"], inplace=True)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Standardize lagged openness (for PSTR threshold)\n",
    "# -------------------------------------------------\n",
    "open_mean = df[\"Openness_t1\"].mean()\n",
    "open_std  = df[\"Openness_t1\"].std(ddof=0)\n",
    "df[\"Open_std\"] = (df[\"Openness_t1\"] - open_mean) / open_std\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 8. Two-way within-transform (entity + time FE)\n",
    "# -------------------------------------------------\n",
    "def twoway_within_transform(panel_df, cols):\n",
    "    \"\"\"Double-demean columns. Returns *_wt columns.\"\"\"\n",
    "    out = panel_df.copy()\n",
    "    ent_means   = out.groupby(level=0)[cols].transform(\"mean\")\n",
    "    time_means  = out.groupby(level=1)[cols].transform(\"mean\")\n",
    "    overall_means = out[cols].mean()\n",
    "    wt = out[cols] - ent_means - time_means + overall_means\n",
    "    wt.columns = [c + \"_wt\" for c in cols]\n",
    "    return wt\n",
    "\n",
    "# ←←←  ONLY variables we keep\n",
    "base_cols = [\"y\", \"Exposure_t\", \"Exposure_t1\", \"Open_std\"]\n",
    "wt = twoway_within_transform(df, base_cols)\n",
    "for c in wt.columns:\n",
    "    df[c] = wt[c]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 9. PSTR logistic transition function\n",
    "# -------------------------------------------------\n",
    "def G_logistic(z, gamma, c):\n",
    "    return 1.0 / (1.0 + np.exp(-gamma * (z - c)))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 10. Build within-transformed X matrix (NLS step)\n",
    "# -------------------------------------------------\n",
    "def build_X_within(gamma, c, work_df):\n",
    "    z = work_df[\"Open_std_wt\"].to_numpy()\n",
    "    G = G_logistic(z, gamma, c)\n",
    "    X = np.column_stack([\n",
    "        work_df[\"Exposure_t_wt\"].to_numpy(),\n",
    "        work_df[\"Exposure_t1_wt\"].to_numpy(),\n",
    "        work_df[\"Exposure_t_wt\"].to_numpy() * G,   # (Exp_t * G)_wt\n",
    "        work_df[\"Exposure_t1_wt\"].to_numpy() * G,  # (Exp_t1 * G)_wt\n",
    "    ])\n",
    "    return X\n",
    "\n",
    "y_wt = df[\"y_wt\"].to_numpy()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 11. NLS: minimize SSR over (γ, c)\n",
    "# -------------------------------------------------\n",
    "def ssr_objective(theta):\n",
    "    gamma, c = theta\n",
    "    if gamma <= 0:\n",
    "        return 1e12 + (abs(gamma) + 1.0) * 1e12\n",
    "    X = build_X_within(gamma, c, df)\n",
    "    beta_hat, *_ = np.linalg.lstsq(X, y_wt, rcond=None)\n",
    "    resid = y_wt - X @ beta_hat\n",
    "    return float(resid @ resid)\n",
    "\n",
    "theta0 = np.array([1.0, 0.0])\n",
    "bounds = [(1e-3, 100.0), (-3.0, 3.0)]\n",
    "opt = minimize(ssr_objective, theta0, method=\"L-BFGS-B\", bounds=bounds)\n",
    "gamma_hat, c_hat_std = opt.x\n",
    "\n",
    "print(\"\\n=== PSTR (NLS) transition estimates ===\")\n",
    "print(f\" gamma (smoothness): {gamma_hat: .4f}\")\n",
    "print(f\" c (threshold, standardized): {c_hat_std: .4f}\")\n",
    "c_hat_orig = open_mean + open_std * c_hat_std\n",
    "print(f\" c (threshold, ORIGINAL openness units): {c_hat_orig: .4f}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 12. Construct final G_hat on original scale\n",
    "# -------------------------------------------------\n",
    "G_hat = G_logistic(df[\"Open_std\"].to_numpy(), gamma_hat, c_hat_std)\n",
    "df[\"G_hat\"] = G_hat\n",
    "df[\"Exp_t_G\"]  = df[\"Exposure_t\"]  * df[\"G_hat\"]\n",
    "df[\"Exp_t1_G\"] = df[\"Exposure_t1\"] * df[\"G_hat\"]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 13. Final PanelOLS (two-way FE) – **NO HICP / Unemp**\n",
    "# -------------------------------------------------\n",
    "exog_cols = [\"Exposure_t\", \"Exposure_t1\", \"Exp_t_G\", \"Exp_t1_G\"]\n",
    "mod = PanelOLS(\n",
    "    dependent=df[\"y\"],\n",
    "    exog=df[exog_cols],\n",
    "    entity_effects=True,\n",
    "    time_effects=True,\n",
    ")\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(\"\\n=== PSTR Fixed-Effects (linear part) ===\")\n",
    "print(res)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 14. Marginal effects at different openness levels\n",
    "# -------------------------------------------------\n",
    "print(\"\\n=== MARGINAL EFFECTS OF TARIFF EXPOSURE (PSTR) ===\")\n",
    "open_levels = {\n",
    "    \"Low\":     df[\"Openness_t1\"].quantile(0.25),\n",
    "    \"Median\":  df[\"Openness_t1\"].quantile(0.50),\n",
    "    \"High\":    df[\"Openness_t1\"].quantile(0.75),\n",
    "}\n",
    "\n",
    "alpha0 = res.params[\"Exposure_t\"]\n",
    "alpha1 = res.params[\"Exposure_t1\"]\n",
    "beta0  = res.params[\"Exp_t_G\"]\n",
    "beta1  = res.params[\"Exp_t1_G\"]\n",
    "V = res.cov\n",
    "\n",
    "for label, q_orig in open_levels.items():\n",
    "    z  = (q_orig - open_mean) / open_std\n",
    "    Gq = G_logistic(z, gamma_hat, c_hat_std)\n",
    "\n",
    "    # Contemporaneous\n",
    "    me_t  = alpha0 + beta0 * Gq\n",
    "    var_t = (V.loc[\"Exposure_t\",\"Exposure_t\"] +\n",
    "             2*Gq*V.loc[\"Exposure_t\",\"Exp_t_G\"] +\n",
    "             Gq**2*V.loc[\"Exp_t_G\",\"Exp_t_G\"])\n",
    "    se_t  = float(np.sqrt(var_t))\n",
    "\n",
    "    # Lagged\n",
    "    me_t1 = alpha1 + beta1 * Gq\n",
    "    var_t1 = (V.loc[\"Exposure_t1\",\"Exposure_t1\"] +\n",
    "              2*Gq*V.loc[\"Exposure_t1\",\"Exp_t1_G\"] +\n",
    "              Gq**2*V.loc[\"Exp_t1_G\",\"Exp_t1_G\"])\n",
    "    se_t1 = float(np.sqrt(var_t1))\n",
    "\n",
    "    # Cumulative\n",
    "    cov_cross = (V.loc[\"Exposure_t\",\"Exposure_t1\"] +\n",
    "                 Gq*(V.loc[\"Exposure_t\",\"Exp_t1_G\"] +\n",
    "                     V.loc[\"Exp_t_G\",\"Exposure_t1\"]) +\n",
    "                 Gq**2*V.loc[\"Exp_t_G\",\"Exp_t1_G\"])\n",
    "    var_cum = var_t + var_t1 + 2*cov_cross\n",
    "    se_cum  = float(np.sqrt(var_cum))\n",
    "    me_cum  = me_t + me_t1\n",
    "\n",
    "    print(f\"\\n{label} Openness (orig={q_orig:.4f}, z={z:.3f}, G={Gq:.3f}):\")\n",
    "    print(f\"  ∂y/∂Exposure_t      : {me_t: .6f} (se = {se_t: .6f})\")\n",
    "    print(f\"  ∂y/∂Exposure_(t-1)  : {me_t1:.6f} (se = {se_t1:.6f})\")\n",
    "    print(f\"  Cumulative (0–1 mo) : {me_cum:.6f} (se = {se_cum:.6f})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PSTR (NLS) transition estimates ===\n",
      " gamma (smoothness):  11.5068\n",
      " c (threshold, standardized): -1.5679\n",
      " c (threshold, ORIGINAL openness units): -1.5641\n",
      "\n",
      "=== PSTR Fixed-Effects (linear part) ===\n",
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                      y   R-squared:                        0.0298\n",
      "Estimator:                   PanelOLS   R-squared (Between):              0.2331\n",
      "No. Observations:                 260   R-squared (Within):              -0.0264\n",
      "Date:                Sat, Nov 08 2025   R-squared (Overall):             -0.0126\n",
      "Time:                        14:15:26   Log-likelihood                   -1089.7\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      1.6947\n",
      "Entities:                          26   P-value                           0.1522\n",
      "Avg Obs:                      10.0000   Distribution:                   F(4,221)\n",
      "Min Obs:                      10.0000                                           \n",
      "Max Obs:                      10.0000   F-statistic (robust):             3.3622\n",
      "                                        P-value                           0.0107\n",
      "Time periods:                      10   Distribution:                   F(4,221)\n",
      "Avg Obs:                       26.000                                           \n",
      "Min Obs:                       26.000                                           \n",
      "Max Obs:                       26.000                                           \n",
      "                                                                                \n",
      "                              Parameter Estimates                              \n",
      "===============================================================================\n",
      "             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------\n",
      "Exposure_t     -2878.3     6329.8    -0.4547     0.6497  -1.535e+04      9596.1\n",
      "Exposure_t1     7617.6     5640.4     1.3506     0.1782     -3498.2   1.873e+04\n",
      "Exp_t_G         2878.2     6329.8     0.4547     0.6498     -9596.2   1.535e+04\n",
      "Exp_t1_G       -7619.5     5640.7    -1.3508     0.1781  -1.874e+04      3496.8\n",
      "===============================================================================\n",
      "\n",
      "F-test for Poolability: 3.6362\n",
      "P-value: 0.0000\n",
      "Distribution: F(34,221)\n",
      "\n",
      "Included effects: Entity, Time\n",
      "\n",
      "=== MARGINAL EFFECTS OF TARIFF EXPOSURE (PSTR) ===\n",
      "\n",
      "Low Openness (orig=1.6912, z=-0.538, G=1.000):\n",
      "  ∂y/∂Exposure_t      : -0.175771 (se =  0.585326)\n",
      "  ∂y/∂Exposure_(t-1)  : -1.870850 (se = 0.663785)\n",
      "  Cumulative (0–1 mo) : -2.046621 (se = 0.642056)\n",
      "\n",
      "Median Openness (orig=2.5673, z=-0.261, G=1.000):\n",
      "  ∂y/∂Exposure_t      : -0.156112 (se =  0.583508)\n",
      "  ∂y/∂Exposure_(t-1)  : -1.922893 (se = 0.679127)\n",
      "  Cumulative (0–1 mo) : -2.079005 (se = 0.632580)\n",
      "\n",
      "High Openness (orig=3.6993, z=0.097, G=1.000):\n",
      "  ∂y/∂Exposure_t      : -0.155281 (se =  0.583502)\n",
      "  ∂y/∂Exposure_(t-1)  : -1.925092 (se = 0.679816)\n",
      "  Cumulative (0–1 mo) : -2.080374 (se = 0.632234)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7) Extended Specification — PSTR Model with Smooth Transition by Trade Openness\n",
    "\n",
    "We now allow the effect of tariff exposure to vary **smoothly** with the level of trade openness given by the World Bank representing the global openess of a country.\n",
    "Instead of assuming a linear interaction, we introduce a **logistic transition function** that captures gradual changes in the impact of exposure as openness increases.\n",
    "\n",
    "The logistic transition function is defined as:\n",
    "\n",
    "$$\n",
    "G\\!\\left(\\text{Openness}_{i,t-1}^{WB};\\gamma,c\\right)\n",
    "= \\frac{1}{1 + \\exp\\!\\big[-\\gamma\\big(\\text{Openness}_{i,t-1}^{WB} - c\\big)\\big]}.\n",
    "$$\n",
    "\n",
    "The corresponding PSTR regression is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{i,t} &= \\mu_i + \\lambda_t\n",
    "+ \\alpha_0\\,\\text{Exposure}_{i,t}\n",
    "+ \\alpha_1\\,\\text{Exposure}_{i,t-1} \\\\\n",
    "&\\quad + \\big(\\beta_0\\,\\text{Exposure}_{i,t} + \\beta_1\\,\\text{Exposure}_{i,t-1}\\big)\n",
    "\\,G\\!\\left(\\text{Openness}_{i,t-1}^{WB};\\gamma,c\\right)\n",
    "+ \\Gamma' Z_{i,t}\n",
    "+ \\varepsilon_{i,t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $y_{i,t}$ — Outcome variable (e.g. Industrial Production YoY for country *i* in month *t*)\n",
    "- $\\text{Exposure}_{i,t}$ — Effective tariff exposure in month *t*\n",
    "- $\\text{Exposure}_{i,t-1}$ — One-month lag of exposure\n",
    "- $\\text{Openness}_{i,t-1}^{WB}$ — Lagged trade openness index (annual, mapped to months)\n",
    "- $G(\\text{Openness}_{i,t-1}^{WB};\\gamma,c)$ — Logistic transition function with:\n",
    "  - $c$: threshold (location) where $G=0.5$\n",
    "  - $\\gamma$: smoothness parameter controlling how sharp the transition is\n",
    "- $Z_{i,t}$ — Monthly domestic controls (HICP YoY, Δ unemployment)\n",
    "- $\\mu_i$ — Country fixed effects\n",
    "- $\\lambda_t$ — Month fixed effects\n",
    "- $\\varepsilon_{i,t}$ — Error term clustered by country\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation**\n",
    "\n",
    "- $\\alpha_0$, $\\alpha_1$ — Baseline exposure effects when openness is low ($G \\approx 0$)\n",
    "- $\\beta_0$, $\\beta_1$ — Incremental effects as openness increases ($G \\to 1$)\n",
    "- **Marginal effects of exposure:**\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t}}\n",
    "  = \\alpha_0 + \\beta_0\\,G(\\text{Openness}_{i,t-1}^{WB};\\gamma,c),\n",
    "  $$\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t-1}}\n",
    "  = \\alpha_1 + \\beta_1\\,G(\\text{Openness}_{i,t-1}^{WB};\\gamma,c).\n",
    "  $$\n",
    "- **Cumulative short-run effect (0–1 month):**\n",
    "  $$\n",
    "  (\\alpha_0 + \\alpha_1) + (\\beta_0 + \\beta_1)\\,G(\\text{Openness}_{i,t-1}^{WB};\\gamma,c).\n",
    "  $$\n",
    "- When $\\gamma$ is large, $G(\\cdot)$ approximates a sharp threshold model; when small, the transition is smooth.\n",
    "\n",
    "---\n",
    "\n",
    "### **Estimation Details**\n",
    "\n",
    "- **Estimator:** Nonlinear least squares with two-way (country and month) fixed effects\n",
    "- **Frequency:** Monthly (2024-10 → 2025-09)\n",
    "- **Standard Errors:** Clustered by country\n",
    "- **Sample:** EU countries only\n",
    "- **Controls:** Domestic macro variables (HICP YoY, unemployment)\n",
    "- **Pre-processing:** Standardize openness before estimation; report the threshold $c$ in original units after transformation\n",
    "\n",
    "---\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "This model identifies whether the **effect of U.S. tariff shocks on economic outcomes** depends on how open each country is to international trade.\n",
    "The logistic transition function captures a **nonlinear response** — for example, more open economies may only become significantly affected **after** crossing a critical openness threshold.\n"
   ],
   "id": "b3cf359c3bd16b51"
  },
  {
   "cell_type": "code",
   "id": "f9c7f859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T13:16:42.283388Z",
     "start_time": "2025-11-08T13:16:41.993408Z"
    }
   },
   "source": [
    "# ================================\n",
    "# PSTR with WB Global Trade Openness – NO HICP / Unemployment\n",
    "# ================================\n",
    "\n",
    "BASE = Path.cwd() / \"data\"\n",
    "\n",
    "ipi      = pd.read_csv(BASE / \"dependent_variable\" / \"IndustrialProductionIndex_df.csv\")\n",
    "stocks   = pd.read_csv(BASE / \"dependent_variable\" / \"StockIndex_df.csv\")\n",
    "exposure = pd.read_csv(BASE / \"independent_variable\" / \"CountryTariffExposure_df.csv\")\n",
    "controls = pd.read_csv(BASE / \"control_variable\" / \"CountryControls_df.csv\")   # read but never used\n",
    "openness = pd.read_csv(BASE / \"transition_variable\" / \"WBTradeOpennessAnnual_df.csv\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Convert Time → Period[M] (only for files we use)\n",
    "# -------------------------------------------------\n",
    "for df in (ipi, stocks, exposure):\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\").dt.to_period(\"M\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Prepare WB annual openness (lagged) → monthly panel\n",
    "# -------------------------------------------------\n",
    "openness = openness[[\"Country\", \"Time\", \"Global Trade Openness-Lag1\"]].copy()\n",
    "openness.rename(columns={\"Global Trade Openness-Lag1\": \"Openness_annual\"}, inplace=True)\n",
    "openness[\"Year\"] = pd.to_datetime(openness[\"Time\"].astype(str), errors=\"coerce\").dt.year\n",
    "openness = openness.drop(columns=[\"Time\"])\n",
    "\n",
    "monthly_open = []\n",
    "for year in [2024, 2025]:\n",
    "    months = pd.date_range(f\"{year}-01-01\", f\"{year}-12-31\", freq=\"MS\")\n",
    "    tmp    = pd.DataFrame({\"Time_dt\": months})\n",
    "    tmp[\"Time\"] = tmp[\"Time_dt\"].dt.to_period(\"M\")\n",
    "    tmp = tmp.merge(openness[openness[\"Year\"] == year][[\"Country\", \"Openness_annual\"]],\n",
    "                    how=\"cross\")\n",
    "    monthly_open.append(tmp)\n",
    "\n",
    "openness_monthly = pd.concat(monthly_open, ignore_index=True)\n",
    "openness_monthly = openness_monthly[[\"Country\", \"Time\", \"Openness_annual\"]]\n",
    "openness_monthly = openness_monthly.rename(columns={\"Openness_annual\": \"Openness\"})\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Dependent variable\n",
    "# -------------------------------------------------\n",
    "df_dep = ipi.rename(columns={\"diff_IPI\": \"y\"})          # IPI YoY diff\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Exposure + lag + openness + lag\n",
    "# -------------------------------------------------\n",
    "exp = exposure.rename(columns={\"Exposure\": \"Exposure_t\"})\n",
    "exp = exp.sort_values([\"Country\", \"Time\"])\n",
    "exp[\"Exposure_t1\"] = exp.groupby(\"Country\")[\"Exposure_t\"].shift(1)\n",
    "\n",
    "# merge monthly openness\n",
    "exp = exp.merge(openness_monthly, on=[\"Country\", \"Time\"], how=\"left\")\n",
    "exp[\"Openness_t1\"] = exp.groupby(\"Country\")[\"Openness\"].shift(1)\n",
    "\n",
    "# drop first month per country (no lag)\n",
    "exp = exp.dropna(subset=[\"Exposure_t1\", \"Openness_t1\"])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Build panel – **NO CONTROLS MERGE**\n",
    "# -------------------------------------------------\n",
    "df = (\n",
    "    df_dep[[\"Country\", \"Time\", \"y\"]]\n",
    "    .merge(exp[[\"Country\", \"Time\",\n",
    "                \"Exposure_t\", \"Exposure_t1\",\n",
    "                \"Openness_t1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    "    # ←←←  controls merge removed\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Restrict to analysis window\n",
    "# -------------------------------------------------\n",
    "df = df[\n",
    "    (df[\"Time\"] >= pd.Period(\"2024-11\", \"M\")) &\n",
    "    (df[\"Time\"] <= pd.Period(\"2025-08\", \"M\"))\n",
    "].copy()\n",
    "\n",
    "df[\"Time_dt\"] = df[\"Time\"].dt.start_time\n",
    "df = df.set_index([\"Country\", \"Time_dt\"]).sort_index()\n",
    "df.drop(columns=[\"Time\"], inplace=True)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Standardize lagged openness (for PSTR threshold)\n",
    "# -------------------------------------------------\n",
    "open_mean = df[\"Openness_t1\"].mean()\n",
    "open_std  = df[\"Openness_t1\"].std(ddof=0)\n",
    "df[\"Open_std\"] = (df[\"Openness_t1\"] - open_mean) / open_std\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 8. Two-way within-transform (entity + time FE)\n",
    "# -------------------------------------------------\n",
    "def twoway_within_transform(panel_df, cols):\n",
    "    \"\"\"Double-demean columns. Returns *_wt columns.\"\"\"\n",
    "    out = panel_df.copy()\n",
    "    ent_means   = out.groupby(level=0)[cols].transform(\"mean\")\n",
    "    time_means  = out.groupby(level=1)[cols].transform(\"mean\")\n",
    "    overall_means = out[cols].mean()\n",
    "    wt = out[cols] - ent_means - time_means + overall_means\n",
    "    wt.columns = [c + \"_wt\" for c in cols]\n",
    "    return wt\n",
    "\n",
    "# ←←←  ONLY variables we keep\n",
    "base_cols = [\"y\", \"Exposure_t\", \"Exposure_t1\", \"Open_std\"]\n",
    "wt = twoway_within_transform(df, base_cols)\n",
    "for c in wt.columns:\n",
    "    df[c] = wt[c]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 9. PSTR logistic transition function\n",
    "# -------------------------------------------------\n",
    "def G_logistic(z, gamma, c):\n",
    "    return 1.0 / (1.0 + np.exp(-gamma * (z - c)))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 10. Build within-transformed X matrix (NLS step)\n",
    "# -------------------------------------------------\n",
    "def build_X_within(gamma, c, work_df):\n",
    "    z = work_df[\"Open_std_wt\"].to_numpy()\n",
    "    G = G_logistic(z, gamma, c)\n",
    "    X = np.column_stack([\n",
    "        work_df[\"Exposure_t_wt\"].to_numpy(),\n",
    "        work_df[\"Exposure_t1_wt\"].to_numpy(),\n",
    "        work_df[\"Exposure_t_wt\"].to_numpy() * G,   # (Exp_t * G)_wt\n",
    "        work_df[\"Exposure_t1_wt\"].to_numpy() * G,  # (Exp_t1 * G)_wt\n",
    "    ])\n",
    "    return X\n",
    "\n",
    "y_wt = df[\"y_wt\"].to_numpy()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 11. NLS: minimize SSR over (γ, c)\n",
    "# -------------------------------------------------\n",
    "def ssr_objective(theta):\n",
    "    gamma, c = theta\n",
    "    if gamma <= 0:\n",
    "        return 1e12 + (abs(gamma) + 1.0) * 1e12\n",
    "    X = build_X_within(gamma, c, df)\n",
    "    beta_hat, *_ = np.linalg.lstsq(X, y_wt, rcond=None)\n",
    "    resid = y_wt - X @ beta_hat\n",
    "    return float(resid @ resid)\n",
    "\n",
    "theta0 = np.array([1.0, 0.0])\n",
    "bounds = [(1e-3, 100.0), (-3.0, 3.0)]\n",
    "opt = minimize(ssr_objective, theta0, method=\"L-BFGS-B\", bounds=bounds)\n",
    "gamma_hat, c_hat_std = opt.x\n",
    "\n",
    "print(\"\\n=== PSTR (NLS) transition estimates ===\")\n",
    "print(f\" gamma (smoothness): {gamma_hat: .4f}\")\n",
    "print(f\" c (threshold, standardized): {c_hat_std: .4f}\")\n",
    "c_hat_orig = open_mean + open_std * c_hat_std\n",
    "print(f\" c (threshold, ORIGINAL openness units): {c_hat_orig: .4f}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 12. Construct final G_hat on original scale\n",
    "# -------------------------------------------------\n",
    "G_hat = G_logistic(df[\"Open_std\"].to_numpy(), gamma_hat, c_hat_std)\n",
    "df[\"G_hat\"] = G_hat\n",
    "df[\"Exp_t_G\"]  = df[\"Exposure_t\"]  * df[\"G_hat\"]\n",
    "df[\"Exp_t1_G\"] = df[\"Exposure_t1\"] * df[\"G_hat\"]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 13. Final PanelOLS (two-way FE) – **NO HICP / Unemp**\n",
    "# -------------------------------------------------\n",
    "exog_cols = [\"Exposure_t\", \"Exposure_t1\", \"Exp_t_G\", \"Exp_t1_G\"]\n",
    "mod = PanelOLS(\n",
    "    dependent=df[\"y\"],\n",
    "    exog=df[exog_cols],\n",
    "    entity_effects=True,\n",
    "    time_effects=True,\n",
    ")\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(\"\\n=== PSTR Fixed-Effects (linear part) ===\")\n",
    "print(res)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 14. Marginal effects at different openness levels\n",
    "# -------------------------------------------------\n",
    "print(\"\\n=== MARGINAL EFFECTS OF TARIFF EXPOSURE (PSTR) ===\")\n",
    "open_levels = {\n",
    "    \"Low\":     df[\"Openness_t1\"].quantile(0.25),\n",
    "    \"Median\":  df[\"Openness_t1\"].quantile(0.50),\n",
    "    \"High\":    df[\"Openness_t1\"].quantile(0.75),\n",
    "}\n",
    "\n",
    "alpha0 = res.params[\"Exposure_t\"]\n",
    "alpha1 = res.params[\"Exposure_t1\"]\n",
    "beta0  = res.params[\"Exp_t_G\"]\n",
    "beta1  = res.params[\"Exp_t1_G\"]\n",
    "V = res.cov\n",
    "\n",
    "for label, q_orig in open_levels.items():\n",
    "    z  = (q_orig - open_mean) / open_std\n",
    "    Gq = G_logistic(z, gamma_hat, c_hat_std)\n",
    "\n",
    "    # Contemporaneous\n",
    "    me_t  = alpha0 + beta0 * Gq\n",
    "    var_t = (V.loc[\"Exposure_t\",\"Exposure_t\"] +\n",
    "             2*Gq*V.loc[\"Exposure_t\",\"Exp_t_G\"] +\n",
    "             Gq**2*V.loc[\"Exp_t_G\",\"Exp_t_G\"])\n",
    "    se_t  = float(np.sqrt(var_t))\n",
    "\n",
    "    # Lagged\n",
    "    me_t1 = alpha1 + beta1 * Gq\n",
    "    var_t1 = (V.loc[\"Exposure_t1\",\"Exposure_t1\"] +\n",
    "              2*Gq*V.loc[\"Exposure_t1\",\"Exp_t1_G\"] +\n",
    "              Gq**2*V.loc[\"Exp_t1_G\",\"Exp_t1_G\"])\n",
    "    se_t1 = float(np.sqrt(var_t1))\n",
    "\n",
    "    # Cumulative\n",
    "    cov_cross = (V.loc[\"Exposure_t\",\"Exposure_t1\"] +\n",
    "                 Gq*(V.loc[\"Exposure_t\",\"Exp_t1_G\"] +\n",
    "                     V.loc[\"Exp_t_G\",\"Exposure_t1\"]) +\n",
    "                 Gq**2*V.loc[\"Exp_t_G\",\"Exp_t1_G\"])\n",
    "    var_cum = var_t + var_t1 + 2*cov_cross\n",
    "    se_cum  = float(np.sqrt(var_cum))\n",
    "    me_cum  = me_t + me_t1\n",
    "\n",
    "    print(f\"\\n{label} Openness (orig={q_orig:.4f}, z={z:.3f}, G={Gq:.3f}):\")\n",
    "    print(f\"  ∂y/∂Exposure_t      : {me_t: .6f} (se = {se_t: .6f})\")\n",
    "    print(f\"  ∂y/∂Exposure_(t-1)  : {me_t1:.6f} (se = {se_t1:.6f})\")\n",
    "    print(f\"  Cumulative (0–1 mo) : {me_cum:.6f} (se = {se_cum:.6f})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PSTR (NLS) transition estimates ===\n",
      " gamma (smoothness):  3.6925\n",
      " c (threshold, standardized):  2.9187\n",
      " c (threshold, ORIGINAL openness units):  343.7827\n",
      "\n",
      "=== PSTR Fixed-Effects (linear part) ===\n",
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                      y   R-squared:                        0.0274\n",
      "Estimator:                   PanelOLS   R-squared (Between):              0.2656\n",
      "No. Observations:                 260   R-squared (Within):              -0.0297\n",
      "Date:                Sat, Nov 08 2025   R-squared (Overall):             -0.0141\n",
      "Time:                        14:16:42   Log-likelihood                   -1090.0\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      1.5548\n",
      "Entities:                          26   P-value                           0.1875\n",
      "Avg Obs:                      10.0000   Distribution:                   F(4,221)\n",
      "Min Obs:                      10.0000                                           \n",
      "Max Obs:                      10.0000   F-statistic (robust):             4.7060\n",
      "                                        P-value                           0.0012\n",
      "Time periods:                      10   Distribution:                   F(4,221)\n",
      "Avg Obs:                       26.000                                           \n",
      "Min Obs:                       26.000                                           \n",
      "Max Obs:                       26.000                                           \n",
      "                                                                                \n",
      "                              Parameter Estimates                              \n",
      "===============================================================================\n",
      "             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------\n",
      "Exposure_t     -0.2465     0.5491    -0.4490     0.6539     -1.3288      0.8357\n",
      "Exposure_t1    -1.9044     0.6954    -2.7384     0.0067     -3.2750     -0.5339\n",
      "Exp_t_G         0.5680     0.4985     1.1392     0.2558     -0.4145      1.5505\n",
      "Exp_t1_G        0.1841     0.7360     0.2501     0.8027     -1.2663      1.6345\n",
      "===============================================================================\n",
      "\n",
      "F-test for Poolability: 3.6080\n",
      "P-value: 0.0000\n",
      "Distribution: F(34,221)\n",
      "\n",
      "Included effects: Entity, Time\n",
      "\n",
      "=== MARGINAL EFFECTS OF TARIFF EXPOSURE (PSTR) ===\n",
      "\n",
      "Low Openness (orig=91.1410, z=-0.698, G=0.000):\n",
      "  ∂y/∂Exposure_t      : -0.246548 (se =  0.549145)\n",
      "  ∂y/∂Exposure_(t-1)  : -1.904421 (se = 0.695447)\n",
      "  Cumulative (0–1 mo) : -2.150969 (se = 0.676092)\n",
      "\n",
      "Median Openness (orig=130.2234, z=-0.138, G=0.000):\n",
      "  ∂y/∂Exposure_t      : -0.246542 (se =  0.549142)\n",
      "  ∂y/∂Exposure_(t-1)  : -1.904419 (se = 0.695441)\n",
      "  Cumulative (0–1 mo) : -2.150961 (se = 0.676089)\n",
      "\n",
      "High Openness (orig=158.4529, z=0.266, G=0.000):\n",
      "  ∂y/∂Exposure_t      : -0.246518 (se =  0.549131)\n",
      "  ∂y/∂Exposure_(t-1)  : -1.904411 (se = 0.695417)\n",
      "  Cumulative (0–1 mo) : -2.150929 (se = 0.676076)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8) Extended Specification — PSTR Model with Smooth Transition by the proportion of Export with EU in the EU total intra market Export\n",
    "\n",
    "We now allow the effect of tariff exposure to vary **smoothly** with the level of trade openness toward EU partner as a mesure of the resilience and the integration in the EU market.\n",
    "Instead of assuming a linear interaction, we introduce a **logistic transition function** that captures gradual changes in the impact of exposure as openness increases.\n",
    "\n",
    "The logistic transition function is defined as:\n",
    "\n",
    "$$\n",
    "G\\!\\left(\\text{Resilience}_{i,t-1}^{EU};\\gamma,c\\right)\n",
    "= \\frac{1}{1 + \\exp\\!\\big[-\\gamma\\big(\\text{Resilience}_{i,t-1}^{EU} - c\\big)\\big]}.\n",
    "$$\n",
    "\n",
    "The corresponding PSTR regression is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{i,t} &= \\mu_i + \\lambda_t\n",
    "+ \\alpha_0\\,\\text{Exposure}_{i,t}\n",
    "+ \\alpha_1\\,\\text{Exposure}_{i,t-1} \\\\\n",
    "&\\quad + \\big(\\beta_0\\,\\text{Exposure}_{i,t} + \\beta_1\\,\\text{Exposure}_{i,t-1}\\big)\n",
    "\\,G\\!\\left(\\text{Resilience}_{i,t-1}^{EU};\\gamma,c\\right)\n",
    "+ \\Gamma' Z_{i,t}\n",
    "+ \\varepsilon_{i,t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $y_{i,t}$ — Outcome variable (e.g. Industrial Production YoY for country *i* in month *t*)\n",
    "- $\\text{Exposure}_{i,t}$ — Effective tariff exposure in month *t*\n",
    "- $\\text{Exposure}_{i,t-1}$ — One-month lag of exposure\n",
    "- $\\text{Resilience}_{i,t-1}^{EU}$ — Lagged trade openness index (annual, mapped to months)\n",
    "- $G(\\text{Resilience}_{i,t-1}^{EU};\\gamma,c)$ — Logistic transition function with:\n",
    "  - $c$: threshold (location) where $G=0.5$\n",
    "  - $\\gamma$: smoothness parameter controlling how sharp the transition is\n",
    "- $Z_{i,t}$ — Monthly domestic controls (HICP YoY, Δ unemployment)\n",
    "- $\\mu_i$ — Country fixed effects\n",
    "- $\\lambda_t$ — Month fixed effects\n",
    "- $\\varepsilon_{i,t}$ — Error term clustered by country\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation**\n",
    "\n",
    "- $\\alpha_0$, $\\alpha_1$ — Baseline exposure effects when openness is low ($G \\approx 0$)\n",
    "- $\\beta_0$, $\\beta_1$ — Incremental effects as openness increases ($G \\to 1$)\n",
    "- **Marginal effects of exposure:**\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t}}\n",
    "  = \\alpha_0 + \\beta_0\\,G(\\text{Resilience}_{i,t-1}^{EU};\\gamma,c),\n",
    "  $$\n",
    "  $$\n",
    "  \\frac{\\partial y_{i,t}}{\\partial \\text{Exposure}_{i,t-1}}\n",
    "  = \\alpha_1 + \\beta_1\\,G(\\text{Resilience}_{i,t-1}^{EU};\\gamma,c).\n",
    "  $$\n",
    "- **Cumulative short-run effect (0–1 month):**\n",
    "  $$\n",
    "  (\\alpha_0 + \\alpha_1) + (\\beta_0 + \\beta_1)\\,G(\\text{Resilience}_{i,t-1}^{EU};\\gamma,c).\n",
    "  $$\n",
    "- When $\\gamma$ is large, $G(\\cdot)$ approximates a sharp threshold model; when small, the transition is smooth.\n",
    "\n",
    "---\n",
    "\n",
    "### **Estimation Details**\n",
    "\n",
    "- **Estimator:** Nonlinear least squares with two-way (country and month) fixed effects\n",
    "- **Frequency:** Monthly (2024-10 → 2025-09)\n",
    "- **Standard Errors:** Clustered by country\n",
    "- **Sample:** EU countries only\n",
    "- **Controls:** Domestic macro variables (HICP YoY, unemployment)\n",
    "- **Pre-processing:** Standardize openness before estimation; report the threshold $c$ in original units after transformation\n",
    "\n",
    "---\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "This model identifies whether the **effect of U.S. tariff shocks on economic outcomes** depends on how resilient / integrated each country is to international trade with Eu partner.\n",
    "The logistic transition function captures a **nonlinear response** — for example, more resilient / integrated economies may only become significantly affected **after** crossing a critical openness threshold.\n"
   ],
   "id": "dfd763bf30e19f0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T13:18:01.935733Z",
     "start_time": "2025-11-08T13:18:01.779333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================\n",
    "# PSTR REGRESSION — FULLY WORKING (NO HICP / Unemployment)\n",
    "# ================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.optimize import minimize\n",
    "from linearmodels.panel import PanelOLS\n",
    "\n",
    "# -------------------------------\n",
    "# 1. LOAD & CONVERT TIME\n",
    "# -------------------------------\n",
    "BASE = Path.cwd() / \"data\"\n",
    "\n",
    "ipi        = pd.read_csv(BASE / \"dependent_variable\" / \"IndustrialProductionIndex_df.csv\")\n",
    "stocks     = pd.read_csv(BASE / \"dependent_variable\" / \"StockIndex_df.csv\")\n",
    "exposure   = pd.read_csv(BASE / \"independent_variable\" / \"CountryTariffExposure_df.csv\")\n",
    "controls   = pd.read_csv(BASE / \"control_variable\" / \"CountryControls_df.csv\")   # read but never used\n",
    "resilience = pd.read_csv(BASE / \"transition_variable\" / \"EU_partner_index_df.csv\")\n",
    "\n",
    "# Convert ALL Time columns to Period[M]\n",
    "for df in (ipi, stocks, exposure, resilience):\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\").dt.to_period(\"M\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. PREPARE DEPENDENT VARIABLE\n",
    "# -------------------------------\n",
    "df_dep = ipi.rename(columns={\"diff_IPI\": \"y\"})   # IPI YoY diff\n",
    "\n",
    "# -------------------------------\n",
    "# 3. PREPARE EXPOSURE + LAG\n",
    "# -------------------------------\n",
    "exp = exposure.rename(columns={\"Exposure\": \"Exposure_t\"})\n",
    "exp = exp.sort_values([\"Country\", \"Time\"]).reset_index(drop=True)\n",
    "exp[\"Exposure_t1\"] = exp.groupby(\"Country\")[\"Exposure_t\"].shift(1)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. MONTHLY RESILIENCE (lagged, no spreading)\n",
    "# -------------------------------\n",
    "resilience_monthly = (\n",
    "    resilience[[\"Country\", \"Time\", \"OBS_VALUE_Lagged1\"]]\n",
    "    .rename(columns={\"OBS_VALUE_Lagged1\": \"resilience\"})\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# Merge current resilience\n",
    "exp = exp.merge(resilience_monthly, on=[\"Country\", \"Time\"], how=\"left\")\n",
    "\n",
    "# Lag resilience\n",
    "exp[\"resilience_t1\"] = exp.groupby(\"Country\")[\"resilience\"].shift(1)\n",
    "\n",
    "# Drop rows where lags are missing\n",
    "exp = exp.dropna(subset=[\"Exposure_t1\", \"resilience_t1\"]).reset_index(drop=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. BUILD FINAL PANEL — NO CONTROLS MERGE\n",
    "# -------------------------------\n",
    "df = (\n",
    "    df_dep\n",
    "    .merge(exp[[\"Country\", \"Time\", \"Exposure_t\", \"Exposure_t1\", \"resilience_t1\"]],\n",
    "           on=[\"Country\", \"Time\"], how=\"inner\")\n",
    "    # ←←←  controls merge removed\n",
    ")\n",
    "\n",
    "# Time window\n",
    "df = df[(df[\"Time\"] >= \"2024-11\") & (df[\"Time\"] <= \"2025-08\")].copy()\n",
    "\n",
    "# Standardize resilience for PSTR\n",
    "open_mean = df[\"resilience_t1\"].mean()\n",
    "open_std  = df[\"resilience_t1\"].std(ddof=0)\n",
    "df[\"Open_std\"] = (df[\"resilience_t1\"] - open_mean) / open_std\n",
    "\n",
    "# Set index for PanelOLS\n",
    "df[\"Time_dt\"] = df[\"Time\"].dt.start_time\n",
    "df = df.set_index([\"Country\", \"Time_dt\"]).sort_index()\n",
    "\n",
    "# -------------------------------\n",
    "# 6. TWO-WAY WITHIN TRANSFORM\n",
    "# -------------------------------\n",
    "def twoway_within(df, cols):\n",
    "    ent     = df.groupby(level=0)[cols].transform(\"mean\")\n",
    "    tim     = df.groupby(level=1)[cols].transform(\"mean\")\n",
    "    overall = df[cols].mean()\n",
    "    return df[cols] - ent - tim + overall\n",
    "\n",
    "# ←←←  ONLY variables we keep\n",
    "base_cols = [\"y\", \"Exposure_t\", \"Exposure_t1\", \"Open_std\"]\n",
    "wt = twoway_within(df, base_cols)\n",
    "wt.columns = [c + \"_wt\" for c in wt.columns]\n",
    "df = pd.concat([df, wt], axis=1)\n",
    "\n",
    "# -------------------------------\n",
    "# 7. PSTR: ESTIMATE γ and c\n",
    "# -------------------------------\n",
    "def G_logistic(z, gamma, c):\n",
    "    return 1.0 / (1.0 + np.exp(-gamma * (z - c)))\n",
    "\n",
    "def build_X(gamma, c, work):\n",
    "    z = work[\"Open_std_wt\"].to_numpy()\n",
    "    G = G_logistic(z, gamma, c)\n",
    "    X = np.column_stack([\n",
    "        work[\"Exposure_t_wt\"],\n",
    "        work[\"Exposure_t1_wt\"],\n",
    "        work[\"Exposure_t_wt\"] * G,     # (Exp_t * G)_wt\n",
    "        work[\"Exposure_t1_wt\"] * G,    # (Exp_t1 * G)_wt\n",
    "    ])\n",
    "    return X\n",
    "\n",
    "y_wt = df[\"y_wt\"].to_numpy()\n",
    "\n",
    "def ssr(theta):\n",
    "    gamma, c = theta\n",
    "    if gamma <= 0:\n",
    "        return 1e12\n",
    "    X = build_X(gamma, c, df)\n",
    "    beta, *_ = np.linalg.lstsq(X, y_wt, rcond=None)\n",
    "    return float((y_wt - X @ beta) @ (y_wt - X @ beta))\n",
    "\n",
    "opt = minimize(ssr, x0=[1.0, 0.0], bounds=[(0.1, 100), (-3, 3)], method=\"L-BFGS-B\")\n",
    "gamma_hat, c_hat_std = opt.x\n",
    "c_hat = open_mean + open_std * c_hat_std\n",
    "\n",
    "print(\"\\nPSTR TRANSITION ESTIMATES\")\n",
    "print(f\"γ (smoothness) = {gamma_hat: .3f}\")\n",
    "print(f\"c (threshold, original units) = {c_hat: .4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8. FINAL LINEAR MODEL WITH G(z)\n",
    "# -------------------------------\n",
    "z = df[\"Open_std\"].to_numpy()\n",
    "G = G_logistic(z, gamma_hat, c_hat_std)\n",
    "df[\"G\"] = G\n",
    "df[\"Exp_t_G\"]  = df[\"Exposure_t\"]  * G\n",
    "df[\"Exp_t1_G\"] = df[\"Exposure_t1\"] * G\n",
    "\n",
    "exog = df[[\"Exposure_t\", \"Exposure_t1\", \"Exp_t_G\", \"Exp_t1_G\"]]   # ←←← no HICP/Unemp\n",
    "mod = PanelOLS(dependent=df[\"y\"], exog=exog, entity_effects=True, time_effects=True)\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(\"\\nPSTR LINEAR PART\")\n",
    "print(res)\n",
    "\n",
    "# -------------------------------\n",
    "# 9. MARGINAL EFFECTS\n",
    "# -------------------------------\n",
    "alpha0 = res.params[\"Exposure_t\"]\n",
    "alpha1 = res.params[\"Exposure_t1\"]\n",
    "beta0  = res.params[\"Exp_t_G\"]\n",
    "beta1  = res.params[\"Exp_t1_G\"]\n",
    "V = res.cov\n",
    "\n",
    "levels = {\n",
    "    \"Low\":     df[\"resilience_t1\"].quantile(0.25),\n",
    "    \"Median\":  df[\"resilience_t1\"].quantile(0.50),\n",
    "    \"High\":    df[\"resilience_t1\"].quantile(0.75)\n",
    "}\n",
    "\n",
    "print(\"\\nMARGINAL EFFECTS\")\n",
    "for name, val in levels.items():\n",
    "    zq = (val - open_mean) / open_std\n",
    "    Gq = G_logistic(zq, gamma_hat, c_hat_std)\n",
    "\n",
    "    me_t   = alpha0 + beta0 * Gq\n",
    "    me_t1  = alpha1 + beta1 * Gq\n",
    "    me_cum = me_t + me_t1\n",
    "\n",
    "    var_t = (V.loc[\"Exposure_t\",\"Exposure_t\"] +\n",
    "             2*Gq*V.loc[\"Exposure_t\",\"Exp_t_G\"] +\n",
    "             Gq**2*V.loc[\"Exp_t_G\",\"Exp_t_G\"])\n",
    "\n",
    "    var_t1 = (V.loc[\"Exposure_t1\",\"Exposure_t1\"] +\n",
    "              2*Gq*V.loc[\"Exposure_t1\",\"Exp_t1_G\"] +\n",
    "              Gq**2*V.loc[\"Exp_t1_G\",\"Exp_t1_G\"])\n",
    "\n",
    "    cov_cross = (V.loc[\"Exposure_t\",\"Exposure_t1\"] +\n",
    "                 Gq*(V.loc[\"Exposure_t\",\"Exp_t1_G\"] +\n",
    "                     V.loc[\"Exp_t_G\",\"Exposure_t1\"]) +\n",
    "                 Gq**2*V.loc[\"Exp_t_G\",\"Exp_t1_G\"])\n",
    "\n",
    "    var_cum = var_t + var_t1 + 2*cov_cross\n",
    "\n",
    "    print(f\"\\n{name} resilience ({val:.3f}) → G(z) = {Gq:.3f}\")\n",
    "    print(f\"  ∂y/∂Exp_t      = {me_t: .5f} (se = {np.sqrt(var_t):.5f})\")\n",
    "    print(f\"  ∂y/∂Exp_(t-1)  = {me_t1:.5f} (se = {np.sqrt(var_t1):.5f})\")\n",
    "    print(f\"  Cumulative     = {me_cum:.5f} (se = {np.sqrt(var_cum):.5f})\")"
   ],
   "id": "dfe1c01391fbe9ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PSTR TRANSITION ESTIMATES\n",
      "γ (smoothness) =  7.078\n",
      "c (threshold, original units) =  0.1831\n",
      "\n",
      "PSTR LINEAR PART\n",
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                      y   R-squared:                        0.0301\n",
      "Estimator:                   PanelOLS   R-squared (Between):              0.2478\n",
      "No. Observations:                 234   R-squared (Within):              -0.0221\n",
      "Date:                Sat, Nov 08 2025   R-squared (Overall):             -0.0131\n",
      "Time:                        14:18:01   Log-likelihood                   -986.89\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      1.5229\n",
      "Entities:                          26   P-value                           0.1970\n",
      "Avg Obs:                       9.0000   Distribution:                   F(4,196)\n",
      "Min Obs:                       9.0000                                           \n",
      "Max Obs:                       9.0000   F-statistic (robust):             4.1336\n",
      "                                        P-value                           0.0031\n",
      "Time periods:                       9   Distribution:                   F(4,196)\n",
      "Avg Obs:                       26.000                                           \n",
      "Min Obs:                       26.000                                           \n",
      "Max Obs:                       26.000                                           \n",
      "                                                                                \n",
      "                              Parameter Estimates                              \n",
      "===============================================================================\n",
      "             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------\n",
      "Exposure_t     -0.2415     0.5730    -0.4215     0.6739     -1.3716      0.8886\n",
      "Exposure_t1    -1.9756     0.6870    -2.8756     0.0045     -3.3304     -0.6207\n",
      "Exp_t_G         0.0391     0.5562     0.0703     0.9440     -1.0578      1.1360\n",
      "Exp_t1_G        2.0725     0.8019     2.5846     0.0105      0.4911      3.6539\n",
      "===============================================================================\n",
      "\n",
      "F-test for Poolability: 3.2601\n",
      "P-value: 0.0000\n",
      "Distribution: F(33,196)\n",
      "\n",
      "Included effects: Entity, Time\n",
      "\n",
      "MARGINAL EFFECTS\n",
      "\n",
      "Low resilience (0.006) → G(z) = 0.000\n",
      "  ∂y/∂Exp_t      = -0.24151 (se = 0.57304)\n",
      "  ∂y/∂Exp_(t-1)  = -1.97556 (se = 0.68700)\n",
      "  Cumulative     = -2.21708 (se = 0.66129)\n",
      "\n",
      "Median resilience (0.018) → G(z) = 0.000\n",
      "  ∂y/∂Exp_t      = -0.24151 (se = 0.57304)\n",
      "  ∂y/∂Exp_(t-1)  = -1.97556 (se = 0.68700)\n",
      "  Cumulative     = -2.21708 (se = 0.66129)\n",
      "\n",
      "High resilience (0.060) → G(z) = 0.000\n",
      "  ∂y/∂Exp_t      = -0.24151 (se = 0.57304)\n",
      "  ∂y/∂Exp_(t-1)  = -1.97556 (se = 0.68700)\n",
      "  Cumulative     = -2.21708 (se = 0.66129)\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
